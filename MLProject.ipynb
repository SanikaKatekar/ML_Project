{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff32aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sanikakatekar/miniforge3/envs/san_tf/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from sklearn import preprocessing\n",
    "from tensorflow_addons.layers import GroupNormalization\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Add\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "%matplotlib inline\n",
    "\n",
    "#Import Necessary packages\n",
    "#Helpful link for reference, using the CHILDESCorpusReader functions: \n",
    "# https://www.nltk.org/howto/childes.html\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus.reader import CHILDESCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878e1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/sanikakatekar/Desktop/Spring 2022/Machine Learning/Project/mlcsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d85bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving names to the columns\n",
    "data.columns = ['age', 'wordsPerSentence', 'realWordRatio', 'avgWordLength','nounRatio', 'verbRatio', 'adjectiveRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b93f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>wordsPerSentence</th>\n",
       "      <th>realWordRatio</th>\n",
       "      <th>avgWordLength</th>\n",
       "      <th>nounRatio</th>\n",
       "      <th>verbRatio</th>\n",
       "      <th>adjectiveRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.96078</td>\n",
       "      <td>3.78431</td>\n",
       "      <td>0.27451</td>\n",
       "      <td>0.05882</td>\n",
       "      <td>0.11765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.92000</td>\n",
       "      <td>3.96000</td>\n",
       "      <td>0.24000</td>\n",
       "      <td>0.08000</td>\n",
       "      <td>0.06000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.94737</td>\n",
       "      <td>4.35088</td>\n",
       "      <td>0.28070</td>\n",
       "      <td>0.07018</td>\n",
       "      <td>0.10526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.95833</td>\n",
       "      <td>3.81250</td>\n",
       "      <td>0.27083</td>\n",
       "      <td>0.02083</td>\n",
       "      <td>0.04167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.98701</td>\n",
       "      <td>3.74026</td>\n",
       "      <td>0.33766</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>0.09091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32347</th>\n",
       "      <td>97</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.97143</td>\n",
       "      <td>3.91429</td>\n",
       "      <td>0.47143</td>\n",
       "      <td>0.01429</td>\n",
       "      <td>0.04286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32348</th>\n",
       "      <td>97</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>3.68750</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.02083</td>\n",
       "      <td>0.04167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32349</th>\n",
       "      <td>97</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.96296</td>\n",
       "      <td>3.87037</td>\n",
       "      <td>0.42593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32350</th>\n",
       "      <td>97</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.96610</td>\n",
       "      <td>3.93220</td>\n",
       "      <td>0.45763</td>\n",
       "      <td>0.01695</td>\n",
       "      <td>0.05085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32351</th>\n",
       "      <td>97</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.94340</td>\n",
       "      <td>3.67925</td>\n",
       "      <td>0.39623</td>\n",
       "      <td>0.01887</td>\n",
       "      <td>0.05660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32352 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  wordsPerSentence  realWordRatio  avgWordLength  nounRatio  \\\n",
       "0        0              2.55        0.96078        3.78431    0.27451   \n",
       "1        0              2.50        0.92000        3.96000    0.24000   \n",
       "2        0              2.85        0.94737        4.35088    0.28070   \n",
       "3        0              2.40        0.95833        3.81250    0.27083   \n",
       "4        0              3.85        0.98701        3.74026    0.33766   \n",
       "...    ...               ...            ...            ...        ...   \n",
       "32347   97              3.50        0.97143        3.91429    0.47143   \n",
       "32348   97              2.40        0.93750        3.68750    0.37500   \n",
       "32349   97              2.70        0.96296        3.87037    0.42593   \n",
       "32350   97              2.95        0.96610        3.93220    0.45763   \n",
       "32351   97              2.65        0.94340        3.67925    0.39623   \n",
       "\n",
       "       verbRatio  adjectiveRatio  \n",
       "0        0.05882         0.11765  \n",
       "1        0.08000         0.06000  \n",
       "2        0.07018         0.10526  \n",
       "3        0.02083         0.04167  \n",
       "4        0.01299         0.09091  \n",
       "...          ...             ...  \n",
       "32347    0.01429         0.04286  \n",
       "32348    0.02083         0.04167  \n",
       "32349    0.00000         0.03704  \n",
       "32350    0.01695         0.05085  \n",
       "32351    0.01887         0.05660  \n",
       "\n",
       "[32352 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00ec989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>wordsPerSentence</th>\n",
       "      <th>realWordRatio</th>\n",
       "      <th>avgWordLength</th>\n",
       "      <th>nounRatio</th>\n",
       "      <th>verbRatio</th>\n",
       "      <th>adjectiveRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.23810</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>3.45000</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.95238</td>\n",
       "      <td>3.80952</td>\n",
       "      <td>0.23810</td>\n",
       "      <td>0.04762</td>\n",
       "      <td>0.04762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>3.90000</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.05000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29058</th>\n",
       "      <td>60</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.88525</td>\n",
       "      <td>3.81967</td>\n",
       "      <td>0.36066</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.04918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29059</th>\n",
       "      <td>60</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.93590</td>\n",
       "      <td>3.42308</td>\n",
       "      <td>0.51282</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.01282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>60</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.86111</td>\n",
       "      <td>3.63889</td>\n",
       "      <td>0.38889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061</th>\n",
       "      <td>60</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.09677</td>\n",
       "      <td>0.48387</td>\n",
       "      <td>0.09677</td>\n",
       "      <td>0.03226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29062</th>\n",
       "      <td>60</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>3.66667</td>\n",
       "      <td>0.45238</td>\n",
       "      <td>0.04762</td>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29063 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  wordsPerSentence  realWordRatio  avgWordLength  nounRatio  \\\n",
       "0       12              1.05        1.00000        3.23810    0.52381   \n",
       "1       12              1.00        0.90000        3.45000    0.65000   \n",
       "2       12              1.05        0.95238        3.80952    0.23810   \n",
       "3       12              1.00        0.80000        3.90000    0.15000   \n",
       "4       12              1.00        1.00000        3.05000    0.25000   \n",
       "...    ...               ...            ...            ...        ...   \n",
       "29058   60              3.05        0.88525        3.81967    0.36066   \n",
       "29059   60              3.90        0.93590        3.42308    0.51282   \n",
       "29060   60              3.60        0.86111        3.63889    0.38889   \n",
       "29061   60              1.55        1.00000        3.09677    0.48387   \n",
       "29062   60              2.10        0.85714        3.66667    0.45238   \n",
       "\n",
       "       verbRatio  adjectiveRatio  \n",
       "0        0.14286         0.00000  \n",
       "1        0.15000         0.00000  \n",
       "2        0.04762         0.04762  \n",
       "3        0.00000         0.00000  \n",
       "4        0.00000         0.00000  \n",
       "...          ...             ...  \n",
       "29058    0.01639         0.04918  \n",
       "29059    0.03846         0.01282  \n",
       "29060    0.00000         0.05556  \n",
       "29061    0.09677         0.03226  \n",
       "29062    0.04762         0.02381  \n",
       "\n",
       "[29063 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(data.index[data['age'] < 12]).reset_index(drop=True)\n",
    "data = data.drop(data.index[data['age'] > 60]).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e3722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = {0:\"0-9 yrs\", 1:\"10-19 yrs\", 2:\"20-29 yrs\", 3:\"30-39 yrs\", 4:\"40-49 yrs\", \n",
    "#            5:\"50-59 yrs\", 6:\"60-69 yrs\"}#, 7:\"70-79 yrs\"}#, 8:\"80-89 yrs\", 9:\"90-99 yrs\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a35fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = {0:\"8-14 yrs\", 1:\"14-22 yrs\", 2:\"22-32 yrs\", 3:\"32-44 yrs\", 4:\"44-66 yrs\", 5:\"66-99\"} \n",
    "# #            #5:\"50-59 yrs\", 6:\"60-69 yrs\"}#, 7:\"70-79 yrs\"}#, 8:\"80-89 yrs\", 9:\"90-99 yrs\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09868633",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0:\"12-20 yrs\", 1:\"20-28 yrs\", 2:\"28-38 yrs\", 3:\"38-48 yrs\", 4:\"48-60 yrs\"} \n",
    "# #            #5:\"50-59 yrs\", 6:\"60-69 yrs\"}#, 7:\"70-79 yrs\"}#, 8:\"80-89 yrs\", 9:\"90-99 yrs\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f9cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>wordsPerSentence</th>\n",
       "      <th>realWordRatio</th>\n",
       "      <th>avgWordLength</th>\n",
       "      <th>nounRatio</th>\n",
       "      <th>verbRatio</th>\n",
       "      <th>adjectiveRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.23810</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>3.45000</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.95238</td>\n",
       "      <td>3.80952</td>\n",
       "      <td>0.23810</td>\n",
       "      <td>0.04762</td>\n",
       "      <td>0.04762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>3.90000</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.05000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29058</th>\n",
       "      <td>4</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.88525</td>\n",
       "      <td>3.81967</td>\n",
       "      <td>0.36066</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.04918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29059</th>\n",
       "      <td>4</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.93590</td>\n",
       "      <td>3.42308</td>\n",
       "      <td>0.51282</td>\n",
       "      <td>0.03846</td>\n",
       "      <td>0.01282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>4</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.86111</td>\n",
       "      <td>3.63889</td>\n",
       "      <td>0.38889</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061</th>\n",
       "      <td>4</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.09677</td>\n",
       "      <td>0.48387</td>\n",
       "      <td>0.09677</td>\n",
       "      <td>0.03226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29062</th>\n",
       "      <td>4</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>3.66667</td>\n",
       "      <td>0.45238</td>\n",
       "      <td>0.04762</td>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29063 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  wordsPerSentence  realWordRatio  avgWordLength  nounRatio  \\\n",
       "0        0              1.05        1.00000        3.23810    0.52381   \n",
       "1        0              1.00        0.90000        3.45000    0.65000   \n",
       "2        0              1.05        0.95238        3.80952    0.23810   \n",
       "3        0              1.00        0.80000        3.90000    0.15000   \n",
       "4        0              1.00        1.00000        3.05000    0.25000   \n",
       "...    ...               ...            ...            ...        ...   \n",
       "29058    4              3.05        0.88525        3.81967    0.36066   \n",
       "29059    4              3.90        0.93590        3.42308    0.51282   \n",
       "29060    4              3.60        0.86111        3.63889    0.38889   \n",
       "29061    4              1.55        1.00000        3.09677    0.48387   \n",
       "29062    4              2.10        0.85714        3.66667    0.45238   \n",
       "\n",
       "       verbRatio  adjectiveRatio  \n",
       "0        0.14286         0.00000  \n",
       "1        0.15000         0.00000  \n",
       "2        0.04762         0.04762  \n",
       "3        0.00000         0.00000  \n",
       "4        0.00000         0.00000  \n",
       "...          ...             ...  \n",
       "29058    0.01639         0.04918  \n",
       "29059    0.03846         0.01282  \n",
       "29060    0.00000         0.05556  \n",
       "29061    0.09677         0.03226  \n",
       "29062    0.04762         0.02381  \n",
       "\n",
       "[29063 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, v in mapping.items():\n",
    "    r1, r2 = v.split(\" \")[0].split(\"-\")\n",
    "    data['age'] = np.where(data['age'].between(int(r1),int(r2)+1), k, data['age'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd99c53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "0    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: age, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "data.groupby('age').age.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76db2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "Y = data.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52b349e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.709201</td>\n",
       "      <td>0.967918</td>\n",
       "      <td>-1.021952</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>2.581525</td>\n",
       "      <td>-1.242898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.746525</td>\n",
       "      <td>-0.265468</td>\n",
       "      <td>-0.477404</td>\n",
       "      <td>2.049777</td>\n",
       "      <td>2.763886</td>\n",
       "      <td>-1.242898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.709201</td>\n",
       "      <td>0.380580</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>-1.389556</td>\n",
       "      <td>0.149025</td>\n",
       "      <td>-0.037052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.746525</td>\n",
       "      <td>-1.498854</td>\n",
       "      <td>0.679022</td>\n",
       "      <td>-2.125184</td>\n",
       "      <td>-1.067225</td>\n",
       "      <td>-1.242898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.746525</td>\n",
       "      <td>0.967918</td>\n",
       "      <td>-1.505338</td>\n",
       "      <td>-1.290191</td>\n",
       "      <td>-1.067225</td>\n",
       "      <td>-1.242898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29058</th>\n",
       "      <td>-0.216251</td>\n",
       "      <td>-0.447393</td>\n",
       "      <td>0.472587</td>\n",
       "      <td>-0.366189</td>\n",
       "      <td>-0.648612</td>\n",
       "      <td>0.002450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29059</th>\n",
       "      <td>0.418252</td>\n",
       "      <td>0.177318</td>\n",
       "      <td>-0.546584</td>\n",
       "      <td>0.904335</td>\n",
       "      <td>-0.084928</td>\n",
       "      <td>-0.918267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>0.194310</td>\n",
       "      <td>-0.745132</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>-0.130471</td>\n",
       "      <td>-1.067225</td>\n",
       "      <td>0.164006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061</th>\n",
       "      <td>-1.335964</td>\n",
       "      <td>0.967918</td>\n",
       "      <td>-1.385147</td>\n",
       "      <td>0.662605</td>\n",
       "      <td>1.404353</td>\n",
       "      <td>-0.426002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29062</th>\n",
       "      <td>-0.925402</td>\n",
       "      <td>-0.794097</td>\n",
       "      <td>0.079403</td>\n",
       "      <td>0.399666</td>\n",
       "      <td>0.149025</td>\n",
       "      <td>-0.639975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29063 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5\n",
       "0     -1.709201  0.967918 -1.021952  0.996101  2.581525 -1.242898\n",
       "1     -1.746525 -0.265468 -0.477404  2.049777  2.763886 -1.242898\n",
       "2     -1.709201  0.380580  0.446504 -1.389556  0.149025 -0.037052\n",
       "3     -1.746525 -1.498854  0.679022 -2.125184 -1.067225 -1.242898\n",
       "4     -1.746525  0.967918 -1.505338 -1.290191 -1.067225 -1.242898\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "29058 -0.216251 -0.447393  0.472587 -0.366189 -0.648612  0.002450\n",
       "29059  0.418252  0.177318 -0.546584  0.904335 -0.084928 -0.918267\n",
       "29060  0.194310 -0.745132  0.008013 -0.130471 -1.067225  0.164006\n",
       "29061 -1.335964  0.967918 -1.385147  0.662605  1.404353 -0.426002\n",
       "29062 -0.925402 -0.794097  0.079403  0.399666  0.149025 -0.639975\n",
       "\n",
       "[29063 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# standardization of dependent variables\n",
    "X = pd.DataFrame(preprocessing.scale(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb8008d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26156, 6)\n",
      "(2907, 6)\n",
      "(26156, 1)\n",
      "(2907, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1 , random_state=4)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac2f20e",
   "metadata": {},
   "source": [
    "### ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72605b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of labels/target column\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "737d17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model_input = Input(shape = (6,))\n",
    "    x = Dense(64,kernel_regularizer=l2(0.0001), activation = 'relu')(model_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(16,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(32,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     x = Dense(32,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "    x = Dense(8,kernel_regularizer=l2(0.0001), activation = 'relu')(x)\n",
    "    model_output = Dense(5, activation = 'softmax')(x)\n",
    "    model = Model(inputs = model_input, outputs = model_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26a380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                448       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,509\n",
      "Trainable params: 9,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f4de9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26156 samples, validate on 2907 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 18:36:46.430309: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-27 18:36:46.474098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-27 18:36:46.539126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-27 18:36:46.548293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26156/26156 [==============================] - 1s 30us/sample - loss: 1.5963 - acc: 0.2988 - val_loss: 1.5365 - val_acc: 0.3516\n",
      "Epoch 2/500\n",
      " 1024/26156 [>.............................] - ETA: 0s - loss: 1.5506 - acc: 0.3457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 18:36:47.183376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.5176 - acc: 0.3441 - val_loss: 1.4756 - val_acc: 0.3481\n",
      "Epoch 3/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.4748 - acc: 0.3483 - val_loss: 1.4398 - val_acc: 0.3495\n",
      "Epoch 4/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.4384 - acc: 0.3526 - val_loss: 1.4067 - val_acc: 0.3467\n",
      "Epoch 5/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.4024 - acc: 0.3537 - val_loss: 1.3655 - val_acc: 0.3492\n",
      "Epoch 6/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3768 - acc: 0.3650 - val_loss: 1.3414 - val_acc: 0.3873\n",
      "Epoch 7/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3598 - acc: 0.3752 - val_loss: 1.3351 - val_acc: 0.3846\n",
      "Epoch 8/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3525 - acc: 0.3792 - val_loss: 1.3276 - val_acc: 0.3915\n",
      "Epoch 9/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3443 - acc: 0.3850 - val_loss: 1.3260 - val_acc: 0.3925\n",
      "Epoch 10/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3408 - acc: 0.3863 - val_loss: 1.3259 - val_acc: 0.3887\n",
      "Epoch 11/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3388 - acc: 0.3856 - val_loss: 1.3198 - val_acc: 0.3908\n",
      "Epoch 12/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3357 - acc: 0.3887 - val_loss: 1.3166 - val_acc: 0.3928\n",
      "Epoch 13/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3338 - acc: 0.3907 - val_loss: 1.3147 - val_acc: 0.3939\n",
      "Epoch 14/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3292 - acc: 0.3933 - val_loss: 1.3153 - val_acc: 0.3897\n",
      "Epoch 15/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3303 - acc: 0.3922 - val_loss: 1.3135 - val_acc: 0.3922\n",
      "Epoch 16/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3264 - acc: 0.3939 - val_loss: 1.3120 - val_acc: 0.3935\n",
      "Epoch 17/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.3214 - acc: 0.3957 - val_loss: 1.3143 - val_acc: 0.3911\n",
      "Epoch 18/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3229 - acc: 0.3934 - val_loss: 1.3148 - val_acc: 0.3904\n",
      "Epoch 19/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3196 - acc: 0.3983 - val_loss: 1.3111 - val_acc: 0.3884\n",
      "Epoch 20/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3185 - acc: 0.3971 - val_loss: 1.3119 - val_acc: 0.3908\n",
      "Epoch 21/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3193 - acc: 0.3960 - val_loss: 1.3100 - val_acc: 0.3897\n",
      "Epoch 22/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3189 - acc: 0.3992 - val_loss: 1.3088 - val_acc: 0.3956\n",
      "Epoch 23/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3195 - acc: 0.3966 - val_loss: 1.3073 - val_acc: 0.3946\n",
      "Epoch 24/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3167 - acc: 0.3995 - val_loss: 1.3068 - val_acc: 0.3970\n",
      "Epoch 25/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3139 - acc: 0.4004 - val_loss: 1.3070 - val_acc: 0.3956\n",
      "Epoch 26/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3128 - acc: 0.4007 - val_loss: 1.3072 - val_acc: 0.3983\n",
      "Epoch 27/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3088 - acc: 0.4027 - val_loss: 1.3050 - val_acc: 0.3966\n",
      "Epoch 28/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3132 - acc: 0.4037 - val_loss: 1.3046 - val_acc: 0.4018\n",
      "Epoch 29/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3107 - acc: 0.4027 - val_loss: 1.3041 - val_acc: 0.3959\n",
      "Epoch 30/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3104 - acc: 0.4074 - val_loss: 1.3087 - val_acc: 0.3884\n",
      "Epoch 31/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3088 - acc: 0.4023 - val_loss: 1.3059 - val_acc: 0.3959\n",
      "Epoch 32/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3073 - acc: 0.4062 - val_loss: 1.3042 - val_acc: 0.4001\n",
      "Epoch 33/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3071 - acc: 0.4046 - val_loss: 1.3044 - val_acc: 0.3980\n",
      "Epoch 34/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3031 - acc: 0.4041 - val_loss: 1.3062 - val_acc: 0.4001\n",
      "Epoch 35/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3066 - acc: 0.4070 - val_loss: 1.3047 - val_acc: 0.4008\n",
      "Epoch 36/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3053 - acc: 0.4055 - val_loss: 1.3029 - val_acc: 0.3994\n",
      "Epoch 37/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3055 - acc: 0.4074 - val_loss: 1.3005 - val_acc: 0.3977\n",
      "Epoch 38/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3046 - acc: 0.4055 - val_loss: 1.3036 - val_acc: 0.4014\n",
      "Epoch 39/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3044 - acc: 0.4052 - val_loss: 1.3033 - val_acc: 0.4021\n",
      "Epoch 40/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3036 - acc: 0.4074 - val_loss: 1.2999 - val_acc: 0.4025\n",
      "Epoch 41/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3022 - acc: 0.4067 - val_loss: 1.2987 - val_acc: 0.4045\n",
      "Epoch 42/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.3036 - acc: 0.4076 - val_loss: 1.3029 - val_acc: 0.3994\n",
      "Epoch 43/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.3020 - acc: 0.4079 - val_loss: 1.3040 - val_acc: 0.3997\n",
      "Epoch 44/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.3016 - acc: 0.4085 - val_loss: 1.2992 - val_acc: 0.4049\n",
      "Epoch 45/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.3000 - acc: 0.4099 - val_loss: 1.3011 - val_acc: 0.4025\n",
      "Epoch 46/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2984 - acc: 0.4109 - val_loss: 1.3011 - val_acc: 0.4059\n",
      "Epoch 47/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2995 - acc: 0.4098 - val_loss: 1.3004 - val_acc: 0.4025\n",
      "Epoch 48/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2987 - acc: 0.4090 - val_loss: 1.3008 - val_acc: 0.4021\n",
      "Epoch 49/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2953 - acc: 0.4106 - val_loss: 1.3019 - val_acc: 0.4032\n",
      "Epoch 50/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2945 - acc: 0.4162 - val_loss: 1.2993 - val_acc: 0.4045\n",
      "Epoch 51/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2968 - acc: 0.4116 - val_loss: 1.3010 - val_acc: 0.4039\n",
      "Epoch 52/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2983 - acc: 0.4106 - val_loss: 1.3039 - val_acc: 0.4052\n",
      "Epoch 53/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2946 - acc: 0.4112 - val_loss: 1.2977 - val_acc: 0.4056\n",
      "Epoch 54/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2959 - acc: 0.4118 - val_loss: 1.2964 - val_acc: 0.4063\n",
      "Epoch 55/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2938 - acc: 0.4125 - val_loss: 1.2986 - val_acc: 0.4032\n",
      "Epoch 56/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2918 - acc: 0.4174 - val_loss: 1.2946 - val_acc: 0.4025\n",
      "Epoch 57/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2940 - acc: 0.4123 - val_loss: 1.2971 - val_acc: 0.4035\n",
      "Epoch 58/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2946 - acc: 0.4118 - val_loss: 1.2945 - val_acc: 0.4059\n",
      "Epoch 59/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2911 - acc: 0.4142 - val_loss: 1.2959 - val_acc: 0.4090\n",
      "Epoch 60/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2911 - acc: 0.4133 - val_loss: 1.2994 - val_acc: 0.4063\n",
      "Epoch 61/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2926 - acc: 0.4173 - val_loss: 1.2990 - val_acc: 0.4063\n",
      "Epoch 62/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2909 - acc: 0.4145 - val_loss: 1.2976 - val_acc: 0.4076\n",
      "Epoch 63/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2926 - acc: 0.4156 - val_loss: 1.2985 - val_acc: 0.4114\n",
      "Epoch 64/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2916 - acc: 0.4152 - val_loss: 1.2948 - val_acc: 0.4042\n",
      "Epoch 65/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2931 - acc: 0.4165 - val_loss: 1.2983 - val_acc: 0.4052\n",
      "Epoch 66/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2907 - acc: 0.4160 - val_loss: 1.2984 - val_acc: 0.4045\n",
      "Epoch 67/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2897 - acc: 0.4172 - val_loss: 1.2969 - val_acc: 0.4018\n",
      "Epoch 68/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2914 - acc: 0.4149 - val_loss: 1.3013 - val_acc: 0.3983\n",
      "Epoch 69/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2905 - acc: 0.4148 - val_loss: 1.2961 - val_acc: 0.4045\n",
      "Epoch 70/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2895 - acc: 0.4178 - val_loss: 1.2970 - val_acc: 0.3997\n",
      "Epoch 71/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2894 - acc: 0.4160 - val_loss: 1.2949 - val_acc: 0.4076\n",
      "Epoch 72/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2867 - acc: 0.4153 - val_loss: 1.3012 - val_acc: 0.4004\n",
      "Epoch 73/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2874 - acc: 0.4187 - val_loss: 1.2930 - val_acc: 0.4063\n",
      "Epoch 74/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2878 - acc: 0.4203 - val_loss: 1.2924 - val_acc: 0.4039\n",
      "Epoch 75/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2881 - acc: 0.4189 - val_loss: 1.2952 - val_acc: 0.4094\n",
      "Epoch 76/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2865 - acc: 0.4158 - val_loss: 1.2967 - val_acc: 0.4014\n",
      "Epoch 77/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2891 - acc: 0.4179 - val_loss: 1.2953 - val_acc: 0.4042\n",
      "Epoch 78/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2875 - acc: 0.4170 - val_loss: 1.3007 - val_acc: 0.4032\n",
      "Epoch 79/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2876 - acc: 0.4225 - val_loss: 1.2906 - val_acc: 0.4097\n",
      "Epoch 80/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2889 - acc: 0.4181 - val_loss: 1.2932 - val_acc: 0.4042\n",
      "Epoch 81/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2856 - acc: 0.4192 - val_loss: 1.2957 - val_acc: 0.4083\n",
      "Epoch 82/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2863 - acc: 0.4183 - val_loss: 1.2976 - val_acc: 0.4045\n",
      "Epoch 83/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2842 - acc: 0.4217 - val_loss: 1.2968 - val_acc: 0.4059\n",
      "Epoch 84/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2838 - acc: 0.4188 - val_loss: 1.2947 - val_acc: 0.4059\n",
      "Epoch 85/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2844 - acc: 0.4203 - val_loss: 1.2913 - val_acc: 0.4011\n",
      "Epoch 86/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2854 - acc: 0.4218 - val_loss: 1.2925 - val_acc: 0.4032\n",
      "Epoch 87/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2842 - acc: 0.4203 - val_loss: 1.2942 - val_acc: 0.4076\n",
      "Epoch 88/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2852 - acc: 0.4169 - val_loss: 1.2975 - val_acc: 0.4025\n",
      "Epoch 89/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2849 - acc: 0.4217 - val_loss: 1.2937 - val_acc: 0.4097\n",
      "Epoch 90/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2853 - acc: 0.4197 - val_loss: 1.2914 - val_acc: 0.4100\n",
      "Epoch 91/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2836 - acc: 0.4195 - val_loss: 1.2967 - val_acc: 0.4032\n",
      "Epoch 92/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2801 - acc: 0.4217 - val_loss: 1.2991 - val_acc: 0.3973\n",
      "Epoch 93/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2825 - acc: 0.4195 - val_loss: 1.2939 - val_acc: 0.4021\n",
      "Epoch 94/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2831 - acc: 0.4240 - val_loss: 1.2954 - val_acc: 0.4018\n",
      "Epoch 95/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2809 - acc: 0.4208 - val_loss: 1.2946 - val_acc: 0.4059\n",
      "Epoch 96/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2798 - acc: 0.4221 - val_loss: 1.2977 - val_acc: 0.4042\n",
      "Epoch 97/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2818 - acc: 0.4214 - val_loss: 1.2955 - val_acc: 0.4008\n",
      "Epoch 98/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2828 - acc: 0.4190 - val_loss: 1.2932 - val_acc: 0.4021\n",
      "Epoch 99/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2810 - acc: 0.4209 - val_loss: 1.2950 - val_acc: 0.4004\n",
      "Epoch 100/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2822 - acc: 0.4195 - val_loss: 1.2934 - val_acc: 0.4025\n",
      "Epoch 101/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2813 - acc: 0.4240 - val_loss: 1.2927 - val_acc: 0.3997\n",
      "Epoch 102/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2812 - acc: 0.4208 - val_loss: 1.2926 - val_acc: 0.4056\n",
      "Epoch 103/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2803 - acc: 0.4227 - val_loss: 1.2948 - val_acc: 0.4025\n",
      "Epoch 104/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2785 - acc: 0.4209 - val_loss: 1.2892 - val_acc: 0.4045\n",
      "Epoch 105/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2821 - acc: 0.4235 - val_loss: 1.2960 - val_acc: 0.4021\n",
      "Epoch 106/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2788 - acc: 0.4217 - val_loss: 1.2943 - val_acc: 0.3997\n",
      "Epoch 107/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2775 - acc: 0.4242 - val_loss: 1.2885 - val_acc: 0.4080\n",
      "Epoch 108/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2804 - acc: 0.4185 - val_loss: 1.2928 - val_acc: 0.4056\n",
      "Epoch 109/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2798 - acc: 0.4214 - val_loss: 1.2930 - val_acc: 0.4076\n",
      "Epoch 110/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2784 - acc: 0.4225 - val_loss: 1.2909 - val_acc: 0.4069\n",
      "Epoch 111/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2794 - acc: 0.4245 - val_loss: 1.2891 - val_acc: 0.4032\n",
      "Epoch 112/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2791 - acc: 0.4236 - val_loss: 1.2931 - val_acc: 0.4076\n",
      "Epoch 113/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2801 - acc: 0.4199 - val_loss: 1.2922 - val_acc: 0.4056\n",
      "Epoch 114/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2775 - acc: 0.4244 - val_loss: 1.2905 - val_acc: 0.4028\n",
      "Epoch 115/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2761 - acc: 0.4233 - val_loss: 1.2923 - val_acc: 0.4008\n",
      "Epoch 116/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2781 - acc: 0.4231 - val_loss: 1.2907 - val_acc: 0.3963\n",
      "Epoch 117/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2778 - acc: 0.4250 - val_loss: 1.2922 - val_acc: 0.4073\n",
      "Epoch 118/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2788 - acc: 0.4243 - val_loss: 1.2949 - val_acc: 0.4090\n",
      "Epoch 119/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2785 - acc: 0.4257 - val_loss: 1.2911 - val_acc: 0.4028\n",
      "Epoch 120/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2767 - acc: 0.4238 - val_loss: 1.2920 - val_acc: 0.4028\n",
      "Epoch 121/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2763 - acc: 0.4255 - val_loss: 1.2929 - val_acc: 0.4045\n",
      "Epoch 122/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2762 - acc: 0.4246 - val_loss: 1.2926 - val_acc: 0.3994\n",
      "Epoch 123/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2750 - acc: 0.4242 - val_loss: 1.2946 - val_acc: 0.4008\n",
      "Epoch 124/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2755 - acc: 0.4250 - val_loss: 1.2957 - val_acc: 0.4025\n",
      "Epoch 125/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2736 - acc: 0.4283 - val_loss: 1.2923 - val_acc: 0.3946\n",
      "Epoch 126/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2767 - acc: 0.4257 - val_loss: 1.2939 - val_acc: 0.4025\n",
      "Epoch 127/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2754 - acc: 0.4246 - val_loss: 1.2918 - val_acc: 0.4049\n",
      "Epoch 128/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2762 - acc: 0.4264 - val_loss: 1.2888 - val_acc: 0.4001\n",
      "Epoch 129/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2763 - acc: 0.4249 - val_loss: 1.2900 - val_acc: 0.4008\n",
      "Epoch 130/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2742 - acc: 0.4247 - val_loss: 1.2896 - val_acc: 0.4011\n",
      "Epoch 131/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2756 - acc: 0.4279 - val_loss: 1.2875 - val_acc: 0.4076\n",
      "Epoch 132/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2739 - acc: 0.4272 - val_loss: 1.2934 - val_acc: 0.3990\n",
      "Epoch 133/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2732 - acc: 0.4258 - val_loss: 1.2979 - val_acc: 0.3870\n",
      "Epoch 134/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2764 - acc: 0.4266 - val_loss: 1.2883 - val_acc: 0.4001\n",
      "Epoch 135/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2733 - acc: 0.4260 - val_loss: 1.2890 - val_acc: 0.4039\n",
      "Epoch 136/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2724 - acc: 0.4284 - val_loss: 1.2910 - val_acc: 0.4052\n",
      "Epoch 137/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2753 - acc: 0.4243 - val_loss: 1.2959 - val_acc: 0.3956\n",
      "Epoch 138/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2721 - acc: 0.4280 - val_loss: 1.2878 - val_acc: 0.4021\n",
      "Epoch 139/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2741 - acc: 0.4269 - val_loss: 1.2920 - val_acc: 0.4011\n",
      "Epoch 140/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2761 - acc: 0.4251 - val_loss: 1.2925 - val_acc: 0.3990\n",
      "Epoch 141/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2724 - acc: 0.4276 - val_loss: 1.2875 - val_acc: 0.4039\n",
      "Epoch 142/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2750 - acc: 0.4250 - val_loss: 1.2944 - val_acc: 0.3942\n",
      "Epoch 143/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2767 - acc: 0.4259 - val_loss: 1.2925 - val_acc: 0.4028\n",
      "Epoch 144/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2733 - acc: 0.4286 - val_loss: 1.2888 - val_acc: 0.4045\n",
      "Epoch 145/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2728 - acc: 0.4310 - val_loss: 1.2916 - val_acc: 0.4032\n",
      "Epoch 146/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2715 - acc: 0.4263 - val_loss: 1.2934 - val_acc: 0.3973\n",
      "Epoch 147/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2737 - acc: 0.4264 - val_loss: 1.2924 - val_acc: 0.4042\n",
      "Epoch 148/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2727 - acc: 0.4235 - val_loss: 1.2869 - val_acc: 0.4104\n",
      "Epoch 149/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2767 - acc: 0.4248 - val_loss: 1.2901 - val_acc: 0.3997\n",
      "Epoch 150/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2713 - acc: 0.4270 - val_loss: 1.2919 - val_acc: 0.4104\n",
      "Epoch 151/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2728 - acc: 0.4282 - val_loss: 1.2912 - val_acc: 0.3990\n",
      "Epoch 152/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2744 - acc: 0.4268 - val_loss: 1.2872 - val_acc: 0.4039\n",
      "Epoch 153/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2721 - acc: 0.4258 - val_loss: 1.2874 - val_acc: 0.4076\n",
      "Epoch 154/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2705 - acc: 0.4266 - val_loss: 1.2893 - val_acc: 0.4039\n",
      "Epoch 155/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2728 - acc: 0.4279 - val_loss: 1.2888 - val_acc: 0.4080\n",
      "Epoch 156/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2717 - acc: 0.4261 - val_loss: 1.2864 - val_acc: 0.4066\n",
      "Epoch 157/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2709 - acc: 0.4279 - val_loss: 1.2926 - val_acc: 0.4035\n",
      "Epoch 158/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2728 - acc: 0.4265 - val_loss: 1.2904 - val_acc: 0.4052\n",
      "Epoch 159/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2722 - acc: 0.4295 - val_loss: 1.2894 - val_acc: 0.4028\n",
      "Epoch 160/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2705 - acc: 0.4265 - val_loss: 1.2952 - val_acc: 0.4021\n",
      "Epoch 161/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2705 - acc: 0.4279 - val_loss: 1.2917 - val_acc: 0.4011\n",
      "Epoch 162/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2693 - acc: 0.4280 - val_loss: 1.2855 - val_acc: 0.4066\n",
      "Epoch 163/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2714 - acc: 0.4276 - val_loss: 1.2888 - val_acc: 0.4049\n",
      "Epoch 164/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2689 - acc: 0.4280 - val_loss: 1.2959 - val_acc: 0.3977\n",
      "Epoch 165/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2709 - acc: 0.4244 - val_loss: 1.2855 - val_acc: 0.4052\n",
      "Epoch 166/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2707 - acc: 0.4301 - val_loss: 1.2908 - val_acc: 0.4056\n",
      "Epoch 167/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2710 - acc: 0.4270 - val_loss: 1.2884 - val_acc: 0.4087\n",
      "Epoch 168/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2696 - acc: 0.4282 - val_loss: 1.2866 - val_acc: 0.4128\n",
      "Epoch 169/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2724 - acc: 0.4272 - val_loss: 1.2877 - val_acc: 0.4087\n",
      "Epoch 170/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2667 - acc: 0.4288 - val_loss: 1.2931 - val_acc: 0.4025\n",
      "Epoch 171/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2692 - acc: 0.4276 - val_loss: 1.2898 - val_acc: 0.3983\n",
      "Epoch 172/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2696 - acc: 0.4253 - val_loss: 1.2945 - val_acc: 0.4076\n",
      "Epoch 173/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2707 - acc: 0.4303 - val_loss: 1.2907 - val_acc: 0.4004\n",
      "Epoch 174/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2712 - acc: 0.4265 - val_loss: 1.2888 - val_acc: 0.4039\n",
      "Epoch 175/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2674 - acc: 0.4290 - val_loss: 1.2903 - val_acc: 0.4083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2688 - acc: 0.4316 - val_loss: 1.2907 - val_acc: 0.4039\n",
      "Epoch 177/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2674 - acc: 0.4314 - val_loss: 1.2914 - val_acc: 0.3994\n",
      "Epoch 178/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2703 - acc: 0.4285 - val_loss: 1.2897 - val_acc: 0.4032\n",
      "Epoch 179/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2702 - acc: 0.4272 - val_loss: 1.2935 - val_acc: 0.4045\n",
      "Epoch 180/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2694 - acc: 0.4288 - val_loss: 1.2863 - val_acc: 0.4066\n",
      "Epoch 181/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2672 - acc: 0.4290 - val_loss: 1.2862 - val_acc: 0.4083\n",
      "Epoch 182/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2671 - acc: 0.4284 - val_loss: 1.2936 - val_acc: 0.4018\n",
      "Epoch 183/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2694 - acc: 0.4277 - val_loss: 1.2874 - val_acc: 0.4049\n",
      "Epoch 184/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2709 - acc: 0.4277 - val_loss: 1.2944 - val_acc: 0.3980\n",
      "Epoch 185/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2663 - acc: 0.4300 - val_loss: 1.2865 - val_acc: 0.4052\n",
      "Epoch 186/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2697 - acc: 0.4299 - val_loss: 1.2902 - val_acc: 0.3953\n",
      "Epoch 187/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2661 - acc: 0.4310 - val_loss: 1.2934 - val_acc: 0.4028\n",
      "Epoch 188/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2669 - acc: 0.4326 - val_loss: 1.2847 - val_acc: 0.4059\n",
      "Epoch 189/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2701 - acc: 0.4270 - val_loss: 1.2963 - val_acc: 0.4049\n",
      "Epoch 190/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2670 - acc: 0.4305 - val_loss: 1.2891 - val_acc: 0.4090\n",
      "Epoch 191/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2654 - acc: 0.4312 - val_loss: 1.2886 - val_acc: 0.4039\n",
      "Epoch 192/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2673 - acc: 0.4326 - val_loss: 1.2879 - val_acc: 0.4049\n",
      "Epoch 193/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2681 - acc: 0.4313 - val_loss: 1.2918 - val_acc: 0.4073\n",
      "Epoch 194/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2683 - acc: 0.4304 - val_loss: 1.2889 - val_acc: 0.4069\n",
      "Epoch 195/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2667 - acc: 0.4285 - val_loss: 1.2922 - val_acc: 0.4090\n",
      "Epoch 196/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2663 - acc: 0.4300 - val_loss: 1.2884 - val_acc: 0.4028\n",
      "Epoch 197/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2699 - acc: 0.4305 - val_loss: 1.2877 - val_acc: 0.4025\n",
      "Epoch 198/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2673 - acc: 0.4303 - val_loss: 1.2897 - val_acc: 0.4035\n",
      "Epoch 199/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2648 - acc: 0.4321 - val_loss: 1.2881 - val_acc: 0.3973\n",
      "Epoch 200/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2634 - acc: 0.4327 - val_loss: 1.2922 - val_acc: 0.4004\n",
      "Epoch 201/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2673 - acc: 0.4315 - val_loss: 1.2879 - val_acc: 0.4042\n",
      "Epoch 202/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2661 - acc: 0.4311 - val_loss: 1.2877 - val_acc: 0.4063\n",
      "Epoch 203/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2671 - acc: 0.4300 - val_loss: 1.2941 - val_acc: 0.4107\n",
      "Epoch 204/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2668 - acc: 0.4306 - val_loss: 1.2927 - val_acc: 0.4028\n",
      "Epoch 205/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2690 - acc: 0.4289 - val_loss: 1.2872 - val_acc: 0.4035\n",
      "Epoch 206/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2654 - acc: 0.4292 - val_loss: 1.2868 - val_acc: 0.4066\n",
      "Epoch 207/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2663 - acc: 0.4311 - val_loss: 1.2879 - val_acc: 0.3966\n",
      "Epoch 208/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2680 - acc: 0.4290 - val_loss: 1.2876 - val_acc: 0.3973\n",
      "Epoch 209/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2653 - acc: 0.4336 - val_loss: 1.2887 - val_acc: 0.3949\n",
      "Epoch 210/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2644 - acc: 0.4304 - val_loss: 1.2908 - val_acc: 0.4066\n",
      "Epoch 211/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2650 - acc: 0.4311 - val_loss: 1.2878 - val_acc: 0.4063\n",
      "Epoch 212/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2665 - acc: 0.4307 - val_loss: 1.2900 - val_acc: 0.4021\n",
      "Epoch 213/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2646 - acc: 0.4322 - val_loss: 1.2907 - val_acc: 0.4035\n",
      "Epoch 214/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2660 - acc: 0.4323 - val_loss: 1.2906 - val_acc: 0.4008\n",
      "Epoch 215/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2668 - acc: 0.4329 - val_loss: 1.2892 - val_acc: 0.4059\n",
      "Epoch 216/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2672 - acc: 0.4287 - val_loss: 1.2933 - val_acc: 0.4004\n",
      "Epoch 217/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2643 - acc: 0.4328 - val_loss: 1.2881 - val_acc: 0.4063\n",
      "Epoch 218/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2638 - acc: 0.4333 - val_loss: 1.2852 - val_acc: 0.4097\n",
      "Epoch 219/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2681 - acc: 0.4307 - val_loss: 1.2838 - val_acc: 0.4025\n",
      "Epoch 220/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2668 - acc: 0.4321 - val_loss: 1.2903 - val_acc: 0.4042\n",
      "Epoch 221/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2635 - acc: 0.4363 - val_loss: 1.2879 - val_acc: 0.4035\n",
      "Epoch 222/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2652 - acc: 0.4323 - val_loss: 1.2883 - val_acc: 0.4011\n",
      "Epoch 223/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2637 - acc: 0.4329 - val_loss: 1.2846 - val_acc: 0.4032\n",
      "Epoch 224/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2638 - acc: 0.4351 - val_loss: 1.2893 - val_acc: 0.4039\n",
      "Epoch 225/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2671 - acc: 0.4293 - val_loss: 1.2843 - val_acc: 0.4083\n",
      "Epoch 226/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2661 - acc: 0.4317 - val_loss: 1.2835 - val_acc: 0.4118\n",
      "Epoch 227/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2640 - acc: 0.4330 - val_loss: 1.2849 - val_acc: 0.4004\n",
      "Epoch 228/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2646 - acc: 0.4326 - val_loss: 1.2853 - val_acc: 0.4039\n",
      "Epoch 229/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2645 - acc: 0.4349 - val_loss: 1.2919 - val_acc: 0.4063\n",
      "Epoch 230/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2665 - acc: 0.4298 - val_loss: 1.2873 - val_acc: 0.4018\n",
      "Epoch 231/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2626 - acc: 0.4315 - val_loss: 1.2901 - val_acc: 0.3983\n",
      "Epoch 232/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2673 - acc: 0.4314 - val_loss: 1.2861 - val_acc: 0.4008\n",
      "Epoch 233/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2663 - acc: 0.4314 - val_loss: 1.2863 - val_acc: 0.4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2623 - acc: 0.4332 - val_loss: 1.2869 - val_acc: 0.4056\n",
      "Epoch 235/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2640 - acc: 0.4346 - val_loss: 1.2917 - val_acc: 0.3908\n",
      "Epoch 236/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2631 - acc: 0.4330 - val_loss: 1.2872 - val_acc: 0.4014\n",
      "Epoch 237/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2633 - acc: 0.4325 - val_loss: 1.2872 - val_acc: 0.4018\n",
      "Epoch 238/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2632 - acc: 0.4358 - val_loss: 1.2871 - val_acc: 0.4042\n",
      "Epoch 239/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2656 - acc: 0.4306 - val_loss: 1.2863 - val_acc: 0.4063\n",
      "Epoch 240/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2609 - acc: 0.4339 - val_loss: 1.2897 - val_acc: 0.4039\n",
      "Epoch 241/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2631 - acc: 0.4310 - val_loss: 1.2828 - val_acc: 0.4066\n",
      "Epoch 242/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2622 - acc: 0.4339 - val_loss: 1.2869 - val_acc: 0.4128\n",
      "Epoch 243/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2634 - acc: 0.4354 - val_loss: 1.2900 - val_acc: 0.3994\n",
      "Epoch 244/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2637 - acc: 0.4323 - val_loss: 1.2819 - val_acc: 0.4083\n",
      "Epoch 245/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2633 - acc: 0.4342 - val_loss: 1.2869 - val_acc: 0.4028\n",
      "Epoch 246/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2634 - acc: 0.4338 - val_loss: 1.2870 - val_acc: 0.4090\n",
      "Epoch 247/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2636 - acc: 0.4324 - val_loss: 1.2875 - val_acc: 0.4018\n",
      "Epoch 248/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2625 - acc: 0.4346 - val_loss: 1.2841 - val_acc: 0.4059\n",
      "Epoch 249/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2628 - acc: 0.4335 - val_loss: 1.2841 - val_acc: 0.4104\n",
      "Epoch 250/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2618 - acc: 0.4354 - val_loss: 1.2892 - val_acc: 0.4056\n",
      "Epoch 251/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2630 - acc: 0.4329 - val_loss: 1.2878 - val_acc: 0.4118\n",
      "Epoch 252/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2623 - acc: 0.4377 - val_loss: 1.2854 - val_acc: 0.4100\n",
      "Epoch 253/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2618 - acc: 0.4370 - val_loss: 1.2908 - val_acc: 0.4097\n",
      "Epoch 254/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2618 - acc: 0.4336 - val_loss: 1.2878 - val_acc: 0.4052\n",
      "Epoch 255/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2627 - acc: 0.4339 - val_loss: 1.2883 - val_acc: 0.4035\n",
      "Epoch 256/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2637 - acc: 0.4322 - val_loss: 1.2865 - val_acc: 0.4073\n",
      "Epoch 257/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2632 - acc: 0.4355 - val_loss: 1.2854 - val_acc: 0.4052\n",
      "Epoch 258/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2629 - acc: 0.4338 - val_loss: 1.2915 - val_acc: 0.4097\n",
      "Epoch 259/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2612 - acc: 0.4353 - val_loss: 1.2887 - val_acc: 0.4018\n",
      "Epoch 260/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2605 - acc: 0.4347 - val_loss: 1.2922 - val_acc: 0.4104\n",
      "Epoch 261/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2625 - acc: 0.4362 - val_loss: 1.2857 - val_acc: 0.4094\n",
      "Epoch 262/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2659 - acc: 0.4360 - val_loss: 1.2864 - val_acc: 0.4069\n",
      "Epoch 263/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2638 - acc: 0.4325 - val_loss: 1.2894 - val_acc: 0.4090\n",
      "Epoch 264/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2618 - acc: 0.4342 - val_loss: 1.2907 - val_acc: 0.3994\n",
      "Epoch 265/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2621 - acc: 0.4347 - val_loss: 1.2854 - val_acc: 0.4121\n",
      "Epoch 266/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2624 - acc: 0.4332 - val_loss: 1.2862 - val_acc: 0.4052\n",
      "Epoch 267/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2626 - acc: 0.4334 - val_loss: 1.2857 - val_acc: 0.4114\n",
      "Epoch 268/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2607 - acc: 0.4335 - val_loss: 1.2917 - val_acc: 0.4008\n",
      "Epoch 269/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2632 - acc: 0.4341 - val_loss: 1.2858 - val_acc: 0.4083\n",
      "Epoch 270/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2631 - acc: 0.4341 - val_loss: 1.2961 - val_acc: 0.4049\n",
      "Epoch 271/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2623 - acc: 0.4357 - val_loss: 1.2864 - val_acc: 0.4052\n",
      "Epoch 272/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2630 - acc: 0.4338 - val_loss: 1.2827 - val_acc: 0.4104\n",
      "Epoch 273/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2610 - acc: 0.4381 - val_loss: 1.2859 - val_acc: 0.4076\n",
      "Epoch 274/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2622 - acc: 0.4334 - val_loss: 1.2884 - val_acc: 0.4107\n",
      "Epoch 275/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2612 - acc: 0.4342 - val_loss: 1.2892 - val_acc: 0.4059\n",
      "Epoch 276/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2618 - acc: 0.4326 - val_loss: 1.2851 - val_acc: 0.4104\n",
      "Epoch 277/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2623 - acc: 0.4373 - val_loss: 1.2902 - val_acc: 0.4094\n",
      "Epoch 278/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2608 - acc: 0.4344 - val_loss: 1.2932 - val_acc: 0.4039\n",
      "Epoch 279/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2631 - acc: 0.4339 - val_loss: 1.2894 - val_acc: 0.4087\n",
      "Epoch 280/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2586 - acc: 0.4375 - val_loss: 1.2940 - val_acc: 0.4042\n",
      "Epoch 281/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2620 - acc: 0.4348 - val_loss: 1.2825 - val_acc: 0.4145\n",
      "Epoch 282/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2640 - acc: 0.4332 - val_loss: 1.2862 - val_acc: 0.4104\n",
      "Epoch 283/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2602 - acc: 0.4350 - val_loss: 1.2907 - val_acc: 0.4107\n",
      "Epoch 284/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2622 - acc: 0.4332 - val_loss: 1.2846 - val_acc: 0.4094\n",
      "Epoch 285/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2591 - acc: 0.4334 - val_loss: 1.2836 - val_acc: 0.4149\n",
      "Epoch 286/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2621 - acc: 0.4369 - val_loss: 1.2934 - val_acc: 0.4021\n",
      "Epoch 287/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2630 - acc: 0.4345 - val_loss: 1.2838 - val_acc: 0.4114\n",
      "Epoch 288/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2598 - acc: 0.4335 - val_loss: 1.2882 - val_acc: 0.4066\n",
      "Epoch 289/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2617 - acc: 0.4321 - val_loss: 1.2838 - val_acc: 0.4080\n",
      "Epoch 290/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2604 - acc: 0.4366 - val_loss: 1.2867 - val_acc: 0.4076\n",
      "Epoch 291/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2600 - acc: 0.4362 - val_loss: 1.2854 - val_acc: 0.4069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2598 - acc: 0.4368 - val_loss: 1.2900 - val_acc: 0.4059\n",
      "Epoch 293/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2591 - acc: 0.4384 - val_loss: 1.2932 - val_acc: 0.4035\n",
      "Epoch 294/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2579 - acc: 0.4344 - val_loss: 1.2975 - val_acc: 0.4032\n",
      "Epoch 295/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2611 - acc: 0.4332 - val_loss: 1.2880 - val_acc: 0.4025\n",
      "Epoch 296/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2614 - acc: 0.4324 - val_loss: 1.2920 - val_acc: 0.3990\n",
      "Epoch 297/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2634 - acc: 0.4354 - val_loss: 1.2899 - val_acc: 0.4028\n",
      "Epoch 298/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2592 - acc: 0.4342 - val_loss: 1.2886 - val_acc: 0.4080\n",
      "Epoch 299/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2599 - acc: 0.4326 - val_loss: 1.2858 - val_acc: 0.4097\n",
      "Epoch 300/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2588 - acc: 0.4362 - val_loss: 1.2849 - val_acc: 0.4176\n",
      "Epoch 301/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2587 - acc: 0.4376 - val_loss: 1.2917 - val_acc: 0.4025\n",
      "Epoch 302/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2589 - acc: 0.4378 - val_loss: 1.2850 - val_acc: 0.4097\n",
      "Epoch 303/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2592 - acc: 0.4365 - val_loss: 1.2858 - val_acc: 0.4080\n",
      "Epoch 304/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2591 - acc: 0.4366 - val_loss: 1.2895 - val_acc: 0.4001\n",
      "Epoch 305/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2586 - acc: 0.4362 - val_loss: 1.2883 - val_acc: 0.4052\n",
      "Epoch 306/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2599 - acc: 0.4383 - val_loss: 1.2882 - val_acc: 0.4076\n",
      "Epoch 307/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2576 - acc: 0.4353 - val_loss: 1.2918 - val_acc: 0.4069\n",
      "Epoch 308/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2583 - acc: 0.4364 - val_loss: 1.2884 - val_acc: 0.4097\n",
      "Epoch 309/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2589 - acc: 0.4379 - val_loss: 1.2867 - val_acc: 0.4125\n",
      "Epoch 310/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2585 - acc: 0.4359 - val_loss: 1.2875 - val_acc: 0.4059\n",
      "Epoch 311/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2592 - acc: 0.4368 - val_loss: 1.2924 - val_acc: 0.3994\n",
      "Epoch 312/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2608 - acc: 0.4376 - val_loss: 1.2910 - val_acc: 0.4087\n",
      "Epoch 313/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2599 - acc: 0.4381 - val_loss: 1.2915 - val_acc: 0.4035\n",
      "Epoch 314/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2613 - acc: 0.4365 - val_loss: 1.2884 - val_acc: 0.4076\n",
      "Epoch 315/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2602 - acc: 0.4366 - val_loss: 1.2823 - val_acc: 0.4111\n",
      "Epoch 316/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2605 - acc: 0.4362 - val_loss: 1.2887 - val_acc: 0.4076\n",
      "Epoch 317/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2575 - acc: 0.4389 - val_loss: 1.2881 - val_acc: 0.4018\n",
      "Epoch 318/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2580 - acc: 0.4376 - val_loss: 1.2884 - val_acc: 0.4083\n",
      "Epoch 319/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2581 - acc: 0.4388 - val_loss: 1.2916 - val_acc: 0.4090\n",
      "Epoch 320/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2579 - acc: 0.4392 - val_loss: 1.2842 - val_acc: 0.4097\n",
      "Epoch 321/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2581 - acc: 0.4387 - val_loss: 1.2867 - val_acc: 0.4008\n",
      "Epoch 322/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2596 - acc: 0.4391 - val_loss: 1.2857 - val_acc: 0.4039\n",
      "Epoch 323/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2605 - acc: 0.4325 - val_loss: 1.2906 - val_acc: 0.4073\n",
      "Epoch 324/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2577 - acc: 0.4379 - val_loss: 1.2884 - val_acc: 0.4107\n",
      "Epoch 325/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2615 - acc: 0.4329 - val_loss: 1.2861 - val_acc: 0.4066\n",
      "Epoch 326/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2596 - acc: 0.4364 - val_loss: 1.2874 - val_acc: 0.4073\n",
      "Epoch 327/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2567 - acc: 0.4387 - val_loss: 1.2895 - val_acc: 0.4025\n",
      "Epoch 328/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2606 - acc: 0.4355 - val_loss: 1.2852 - val_acc: 0.4080\n",
      "Epoch 329/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2595 - acc: 0.4387 - val_loss: 1.2827 - val_acc: 0.4128\n",
      "Epoch 330/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2609 - acc: 0.4366 - val_loss: 1.2917 - val_acc: 0.4049\n",
      "Epoch 331/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2586 - acc: 0.4369 - val_loss: 1.2863 - val_acc: 0.4052\n",
      "Epoch 332/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2565 - acc: 0.4377 - val_loss: 1.2875 - val_acc: 0.4114\n",
      "Epoch 333/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2585 - acc: 0.4369 - val_loss: 1.2886 - val_acc: 0.4042\n",
      "Epoch 334/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2609 - acc: 0.4324 - val_loss: 1.2838 - val_acc: 0.4155\n",
      "Epoch 335/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2591 - acc: 0.4347 - val_loss: 1.2855 - val_acc: 0.4100\n",
      "Epoch 336/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2589 - acc: 0.4381 - val_loss: 1.2934 - val_acc: 0.4042\n",
      "Epoch 337/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2622 - acc: 0.4343 - val_loss: 1.2826 - val_acc: 0.4076\n",
      "Epoch 338/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2602 - acc: 0.4360 - val_loss: 1.2912 - val_acc: 0.4056\n",
      "Epoch 339/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2564 - acc: 0.4421 - val_loss: 1.2875 - val_acc: 0.4097\n",
      "Epoch 340/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2564 - acc: 0.4390 - val_loss: 1.2907 - val_acc: 0.4083\n",
      "Epoch 341/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2580 - acc: 0.4376 - val_loss: 1.2853 - val_acc: 0.4166\n",
      "Epoch 342/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2584 - acc: 0.4375 - val_loss: 1.2897 - val_acc: 0.4087\n",
      "Epoch 343/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2580 - acc: 0.4357 - val_loss: 1.2896 - val_acc: 0.4059\n",
      "Epoch 344/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2573 - acc: 0.4374 - val_loss: 1.2857 - val_acc: 0.4076\n",
      "Epoch 345/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2571 - acc: 0.4383 - val_loss: 1.2941 - val_acc: 0.4014\n",
      "Epoch 346/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2588 - acc: 0.4365 - val_loss: 1.2868 - val_acc: 0.4063\n",
      "Epoch 347/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2579 - acc: 0.4363 - val_loss: 1.2870 - val_acc: 0.4069\n",
      "Epoch 348/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2575 - acc: 0.4356 - val_loss: 1.2859 - val_acc: 0.4135\n",
      "Epoch 349/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2603 - acc: 0.4356 - val_loss: 1.2848 - val_acc: 0.4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2594 - acc: 0.4376 - val_loss: 1.2859 - val_acc: 0.4080\n",
      "Epoch 351/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2558 - acc: 0.4413 - val_loss: 1.2922 - val_acc: 0.4042\n",
      "Epoch 352/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2585 - acc: 0.4428 - val_loss: 1.2864 - val_acc: 0.4111\n",
      "Epoch 353/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2589 - acc: 0.4351 - val_loss: 1.2815 - val_acc: 0.4087\n",
      "Epoch 354/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2582 - acc: 0.4356 - val_loss: 1.2904 - val_acc: 0.4073\n",
      "Epoch 355/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2576 - acc: 0.4391 - val_loss: 1.2841 - val_acc: 0.4097\n",
      "Epoch 356/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2586 - acc: 0.4396 - val_loss: 1.2859 - val_acc: 0.4118\n",
      "Epoch 357/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2592 - acc: 0.4404 - val_loss: 1.2892 - val_acc: 0.4066\n",
      "Epoch 358/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2583 - acc: 0.4385 - val_loss: 1.2877 - val_acc: 0.4121\n",
      "Epoch 359/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2583 - acc: 0.4395 - val_loss: 1.2894 - val_acc: 0.4107\n",
      "Epoch 360/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2589 - acc: 0.4375 - val_loss: 1.2864 - val_acc: 0.4114\n",
      "Epoch 361/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2584 - acc: 0.4396 - val_loss: 1.2861 - val_acc: 0.4145\n",
      "Epoch 362/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2584 - acc: 0.4389 - val_loss: 1.2864 - val_acc: 0.4145\n",
      "Epoch 363/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2572 - acc: 0.4411 - val_loss: 1.2928 - val_acc: 0.4049\n",
      "Epoch 364/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2579 - acc: 0.4378 - val_loss: 1.2878 - val_acc: 0.4045\n",
      "Epoch 365/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2559 - acc: 0.4389 - val_loss: 1.2971 - val_acc: 0.4083\n",
      "Epoch 366/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2588 - acc: 0.4350 - val_loss: 1.2856 - val_acc: 0.4090\n",
      "Epoch 367/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2552 - acc: 0.4366 - val_loss: 1.2949 - val_acc: 0.4039\n",
      "Epoch 368/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2578 - acc: 0.4403 - val_loss: 1.2872 - val_acc: 0.4049\n",
      "Epoch 369/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2593 - acc: 0.4387 - val_loss: 1.2875 - val_acc: 0.4076\n",
      "Epoch 370/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2564 - acc: 0.4389 - val_loss: 1.2882 - val_acc: 0.4018\n",
      "Epoch 371/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2539 - acc: 0.4368 - val_loss: 1.2906 - val_acc: 0.4042\n",
      "Epoch 372/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2576 - acc: 0.4365 - val_loss: 1.2885 - val_acc: 0.4090\n",
      "Epoch 373/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2579 - acc: 0.4388 - val_loss: 1.2881 - val_acc: 0.4111\n",
      "Epoch 374/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2585 - acc: 0.4362 - val_loss: 1.2878 - val_acc: 0.4042\n",
      "Epoch 375/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2554 - acc: 0.4403 - val_loss: 1.2879 - val_acc: 0.4032\n",
      "Epoch 376/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2575 - acc: 0.4369 - val_loss: 1.2872 - val_acc: 0.4162\n",
      "Epoch 377/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2571 - acc: 0.4391 - val_loss: 1.2839 - val_acc: 0.4111\n",
      "Epoch 378/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2582 - acc: 0.4374 - val_loss: 1.2870 - val_acc: 0.4097\n",
      "Epoch 379/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2551 - acc: 0.4385 - val_loss: 1.2859 - val_acc: 0.4056\n",
      "Epoch 380/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2569 - acc: 0.4366 - val_loss: 1.2820 - val_acc: 0.4128\n",
      "Epoch 381/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2593 - acc: 0.4372 - val_loss: 1.2885 - val_acc: 0.4073\n",
      "Epoch 382/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2580 - acc: 0.4367 - val_loss: 1.2891 - val_acc: 0.4056\n",
      "Epoch 383/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2562 - acc: 0.4387 - val_loss: 1.2861 - val_acc: 0.4066\n",
      "Epoch 384/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2588 - acc: 0.4362 - val_loss: 1.2898 - val_acc: 0.4028\n",
      "Epoch 385/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2572 - acc: 0.4405 - val_loss: 1.2856 - val_acc: 0.4039\n",
      "Epoch 386/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2587 - acc: 0.4401 - val_loss: 1.2902 - val_acc: 0.4045\n",
      "Epoch 387/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2588 - acc: 0.4375 - val_loss: 1.2861 - val_acc: 0.4083\n",
      "Epoch 388/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2553 - acc: 0.4402 - val_loss: 1.2857 - val_acc: 0.4069\n",
      "Epoch 389/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2574 - acc: 0.4368 - val_loss: 1.2916 - val_acc: 0.4049\n",
      "Epoch 390/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2552 - acc: 0.4380 - val_loss: 1.2880 - val_acc: 0.4080\n",
      "Epoch 391/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2579 - acc: 0.4392 - val_loss: 1.2906 - val_acc: 0.4056\n",
      "Epoch 392/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2566 - acc: 0.4392 - val_loss: 1.2868 - val_acc: 0.4039\n",
      "Epoch 393/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2551 - acc: 0.4394 - val_loss: 1.2837 - val_acc: 0.4066\n",
      "Epoch 394/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2568 - acc: 0.4407 - val_loss: 1.2920 - val_acc: 0.4001\n",
      "Epoch 395/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2565 - acc: 0.4399 - val_loss: 1.2864 - val_acc: 0.4066\n",
      "Epoch 396/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2578 - acc: 0.4340 - val_loss: 1.2929 - val_acc: 0.4097\n",
      "Epoch 397/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2581 - acc: 0.4365 - val_loss: 1.2873 - val_acc: 0.4035\n",
      "Epoch 398/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2583 - acc: 0.4396 - val_loss: 1.2887 - val_acc: 0.4042\n",
      "Epoch 399/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2543 - acc: 0.4392 - val_loss: 1.2886 - val_acc: 0.4049\n",
      "Epoch 400/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2579 - acc: 0.4392 - val_loss: 1.2921 - val_acc: 0.3973\n",
      "Epoch 401/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2563 - acc: 0.4386 - val_loss: 1.2836 - val_acc: 0.4087\n",
      "Epoch 402/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2565 - acc: 0.4419 - val_loss: 1.2927 - val_acc: 0.4042\n",
      "Epoch 403/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2574 - acc: 0.4397 - val_loss: 1.2898 - val_acc: 0.4066\n",
      "Epoch 404/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2563 - acc: 0.4400 - val_loss: 1.2873 - val_acc: 0.4107\n",
      "Epoch 405/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2551 - acc: 0.4381 - val_loss: 1.2872 - val_acc: 0.4080\n",
      "Epoch 406/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2552 - acc: 0.4433 - val_loss: 1.2866 - val_acc: 0.4056\n",
      "Epoch 407/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2562 - acc: 0.4390 - val_loss: 1.2865 - val_acc: 0.4059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2574 - acc: 0.4395 - val_loss: 1.2884 - val_acc: 0.4100\n",
      "Epoch 409/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2573 - acc: 0.4369 - val_loss: 1.2883 - val_acc: 0.4035\n",
      "Epoch 410/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2545 - acc: 0.4400 - val_loss: 1.2863 - val_acc: 0.4066\n",
      "Epoch 411/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2541 - acc: 0.4385 - val_loss: 1.2879 - val_acc: 0.4045\n",
      "Epoch 412/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2554 - acc: 0.4407 - val_loss: 1.2891 - val_acc: 0.4049\n",
      "Epoch 413/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2553 - acc: 0.4392 - val_loss: 1.2919 - val_acc: 0.3997\n",
      "Epoch 414/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2572 - acc: 0.4402 - val_loss: 1.2820 - val_acc: 0.4128\n",
      "Epoch 415/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2555 - acc: 0.4402 - val_loss: 1.2853 - val_acc: 0.4045\n",
      "Epoch 416/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2552 - acc: 0.4389 - val_loss: 1.2884 - val_acc: 0.4052\n",
      "Epoch 417/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2547 - acc: 0.4409 - val_loss: 1.2911 - val_acc: 0.4008\n",
      "Epoch 418/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2539 - acc: 0.4407 - val_loss: 1.2895 - val_acc: 0.4076\n",
      "Epoch 419/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2545 - acc: 0.4417 - val_loss: 1.2956 - val_acc: 0.4066\n",
      "Epoch 420/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2577 - acc: 0.4380 - val_loss: 1.2873 - val_acc: 0.4056\n",
      "Epoch 421/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2575 - acc: 0.4375 - val_loss: 1.2917 - val_acc: 0.4021\n",
      "Epoch 422/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2545 - acc: 0.4372 - val_loss: 1.2872 - val_acc: 0.4059\n",
      "Epoch 423/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2572 - acc: 0.4415 - val_loss: 1.2880 - val_acc: 0.4063\n",
      "Epoch 424/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2553 - acc: 0.4408 - val_loss: 1.2872 - val_acc: 0.4107\n",
      "Epoch 425/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2532 - acc: 0.4406 - val_loss: 1.2955 - val_acc: 0.4021\n",
      "Epoch 426/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2526 - acc: 0.4423 - val_loss: 1.2856 - val_acc: 0.4066\n",
      "Epoch 427/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2561 - acc: 0.4406 - val_loss: 1.2842 - val_acc: 0.4045\n",
      "Epoch 428/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2555 - acc: 0.4395 - val_loss: 1.2903 - val_acc: 0.3973\n",
      "Epoch 429/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2553 - acc: 0.4392 - val_loss: 1.2825 - val_acc: 0.4066\n",
      "Epoch 430/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2560 - acc: 0.4386 - val_loss: 1.2839 - val_acc: 0.4039\n",
      "Epoch 431/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2568 - acc: 0.4344 - val_loss: 1.2878 - val_acc: 0.4008\n",
      "Epoch 432/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2557 - acc: 0.4373 - val_loss: 1.2939 - val_acc: 0.4014\n",
      "Epoch 433/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2570 - acc: 0.4373 - val_loss: 1.2920 - val_acc: 0.4018\n",
      "Epoch 434/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2559 - acc: 0.4405 - val_loss: 1.2877 - val_acc: 0.4056\n",
      "Epoch 435/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2549 - acc: 0.4394 - val_loss: 1.2904 - val_acc: 0.4066\n",
      "Epoch 436/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2567 - acc: 0.4375 - val_loss: 1.2898 - val_acc: 0.4042\n",
      "Epoch 437/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2552 - acc: 0.4415 - val_loss: 1.2951 - val_acc: 0.3977\n",
      "Epoch 438/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2591 - acc: 0.4356 - val_loss: 1.2829 - val_acc: 0.4035\n",
      "Epoch 439/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2552 - acc: 0.4373 - val_loss: 1.2867 - val_acc: 0.4107\n",
      "Epoch 440/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2540 - acc: 0.4406 - val_loss: 1.2822 - val_acc: 0.4052\n",
      "Epoch 441/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2551 - acc: 0.4402 - val_loss: 1.2891 - val_acc: 0.4087\n",
      "Epoch 442/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2534 - acc: 0.4384 - val_loss: 1.2871 - val_acc: 0.4011\n",
      "Epoch 443/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2526 - acc: 0.4402 - val_loss: 1.2899 - val_acc: 0.4063\n",
      "Epoch 444/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2527 - acc: 0.4438 - val_loss: 1.2860 - val_acc: 0.4028\n",
      "Epoch 445/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2537 - acc: 0.4397 - val_loss: 1.2855 - val_acc: 0.4052\n",
      "Epoch 446/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2546 - acc: 0.4375 - val_loss: 1.2875 - val_acc: 0.4035\n",
      "Epoch 447/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2549 - acc: 0.4382 - val_loss: 1.2893 - val_acc: 0.4032\n",
      "Epoch 448/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2553 - acc: 0.4396 - val_loss: 1.2884 - val_acc: 0.4021\n",
      "Epoch 449/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2546 - acc: 0.4392 - val_loss: 1.2865 - val_acc: 0.4028\n",
      "Epoch 450/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2521 - acc: 0.4424 - val_loss: 1.2850 - val_acc: 0.4073\n",
      "Epoch 451/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2525 - acc: 0.4415 - val_loss: 1.2942 - val_acc: 0.4025\n",
      "Epoch 452/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2556 - acc: 0.4384 - val_loss: 1.2858 - val_acc: 0.4128\n",
      "Epoch 453/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2564 - acc: 0.4392 - val_loss: 1.2881 - val_acc: 0.4090\n",
      "Epoch 454/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2517 - acc: 0.4441 - val_loss: 1.2867 - val_acc: 0.3987\n",
      "Epoch 455/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2551 - acc: 0.4410 - val_loss: 1.2942 - val_acc: 0.3973\n",
      "Epoch 456/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2566 - acc: 0.4367 - val_loss: 1.2865 - val_acc: 0.4032\n",
      "Epoch 457/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2561 - acc: 0.4341 - val_loss: 1.2917 - val_acc: 0.4014\n",
      "Epoch 458/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2545 - acc: 0.4389 - val_loss: 1.2872 - val_acc: 0.4059\n",
      "Epoch 459/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2554 - acc: 0.4404 - val_loss: 1.2843 - val_acc: 0.4028\n",
      "Epoch 460/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2549 - acc: 0.4403 - val_loss: 1.2831 - val_acc: 0.4035\n",
      "Epoch 461/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2546 - acc: 0.4387 - val_loss: 1.2856 - val_acc: 0.4008\n",
      "Epoch 462/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2557 - acc: 0.4414 - val_loss: 1.2967 - val_acc: 0.3990\n",
      "Epoch 463/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2516 - acc: 0.4434 - val_loss: 1.2855 - val_acc: 0.4100\n",
      "Epoch 464/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2576 - acc: 0.4353 - val_loss: 1.2899 - val_acc: 0.4094\n",
      "Epoch 465/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2546 - acc: 0.4377 - val_loss: 1.2816 - val_acc: 0.4100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2551 - acc: 0.4397 - val_loss: 1.2901 - val_acc: 0.4056\n",
      "Epoch 467/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2551 - acc: 0.4396 - val_loss: 1.2909 - val_acc: 0.4032\n",
      "Epoch 468/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2535 - acc: 0.4409 - val_loss: 1.2878 - val_acc: 0.4094\n",
      "Epoch 469/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2554 - acc: 0.4396 - val_loss: 1.2923 - val_acc: 0.4052\n",
      "Epoch 470/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2555 - acc: 0.4393 - val_loss: 1.2896 - val_acc: 0.4066\n",
      "Epoch 471/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2539 - acc: 0.4403 - val_loss: 1.2862 - val_acc: 0.4035\n",
      "Epoch 472/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2548 - acc: 0.4391 - val_loss: 1.2853 - val_acc: 0.4090\n",
      "Epoch 473/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2554 - acc: 0.4396 - val_loss: 1.2917 - val_acc: 0.3956\n",
      "Epoch 474/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2540 - acc: 0.4440 - val_loss: 1.2857 - val_acc: 0.4042\n",
      "Epoch 475/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2538 - acc: 0.4410 - val_loss: 1.2884 - val_acc: 0.4111\n",
      "Epoch 476/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2557 - acc: 0.4415 - val_loss: 1.2876 - val_acc: 0.4094\n",
      "Epoch 477/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2518 - acc: 0.4426 - val_loss: 1.2822 - val_acc: 0.4111\n",
      "Epoch 478/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2524 - acc: 0.4420 - val_loss: 1.2865 - val_acc: 0.4035\n",
      "Epoch 479/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2532 - acc: 0.4384 - val_loss: 1.2861 - val_acc: 0.4069\n",
      "Epoch 480/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2564 - acc: 0.4382 - val_loss: 1.2868 - val_acc: 0.4052\n",
      "Epoch 481/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2523 - acc: 0.4404 - val_loss: 1.2855 - val_acc: 0.4100\n",
      "Epoch 482/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2540 - acc: 0.4395 - val_loss: 1.2903 - val_acc: 0.4035\n",
      "Epoch 483/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2540 - acc: 0.4412 - val_loss: 1.2848 - val_acc: 0.4080\n",
      "Epoch 484/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2525 - acc: 0.4451 - val_loss: 1.2898 - val_acc: 0.4087\n",
      "Epoch 485/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2536 - acc: 0.4432 - val_loss: 1.2876 - val_acc: 0.4080\n",
      "Epoch 486/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2554 - acc: 0.4393 - val_loss: 1.2820 - val_acc: 0.4028\n",
      "Epoch 487/500\n",
      "26156/26156 [==============================] - 0s 11us/sample - loss: 1.2536 - acc: 0.4379 - val_loss: 1.2941 - val_acc: 0.4131\n",
      "Epoch 488/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2516 - acc: 0.4401 - val_loss: 1.2898 - val_acc: 0.4063\n",
      "Epoch 489/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2559 - acc: 0.4417 - val_loss: 1.2889 - val_acc: 0.4080\n",
      "Epoch 490/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2543 - acc: 0.4420 - val_loss: 1.2874 - val_acc: 0.4097\n",
      "Epoch 491/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2551 - acc: 0.4406 - val_loss: 1.2832 - val_acc: 0.4100\n",
      "Epoch 492/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2548 - acc: 0.4417 - val_loss: 1.2917 - val_acc: 0.4052\n",
      "Epoch 493/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2532 - acc: 0.4409 - val_loss: 1.2886 - val_acc: 0.4035\n",
      "Epoch 494/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2539 - acc: 0.4378 - val_loss: 1.2902 - val_acc: 0.4025\n",
      "Epoch 495/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2555 - acc: 0.4412 - val_loss: 1.2932 - val_acc: 0.4052\n",
      "Epoch 496/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2526 - acc: 0.4416 - val_loss: 1.2858 - val_acc: 0.4052\n",
      "Epoch 497/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2536 - acc: 0.4390 - val_loss: 1.2876 - val_acc: 0.4066\n",
      "Epoch 498/500\n",
      "26156/26156 [==============================] - 0s 13us/sample - loss: 1.2539 - acc: 0.4373 - val_loss: 1.2854 - val_acc: 0.4100\n",
      "Epoch 499/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2524 - acc: 0.4414 - val_loss: 1.2889 - val_acc: 0.4045\n",
      "Epoch 500/500\n",
      "26156/26156 [==============================] - 0s 12us/sample - loss: 1.2536 - acc: 0.4433 - val_loss: 1.2898 - val_acc: 0.4052\n"
     ]
    }
   ],
   "source": [
    "## Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "## Train model\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_data=(x_test, y_test), batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bb6fc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.4481      train_loss: 1.242\n",
      "val_acc: 0.4166        val_loss: 1.2924\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4YAAAFNCAYAAABcw3FTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACjrUlEQVR4nOzddZhT19bA4d8ah8FhcHcoFKfQUjegQu221N391nu/ttT11l2o3LbUoIq0hQo1SqHF3R0GG2aA8f39sc9JTjLJTDJMmAms93l4khzLzjCQrKy91xJjDEoppZRSSiml9l8JlT0ApZRSSimllFKVSwNDpZRSSimllNrPaWColFJKKaWUUvs5DQyVUkoppZRSaj+ngaFSSimllFJK7ec0MFRKKaWUUkqp/ZwGhkoppZRSSim1n9PAUKlKJCI/icg2EUmt7LEopZRS8UxEVojIMZU9DqXilQaGSlUSEWkNHAoY4OS9+LxJe+u5lFJKKaVUfNDAUKnKcwEwBXgHuNDdKCItRGSMiGSKyBYRedGz73IRmS8i2SIyT0R6O9uNiLT3HPeOiDzk3D9CRNaIyB0isgF4W0Tqisg3znNsc+4395xfT0TeFpF1zv4vnO1zROQkz3HJIrJZRHrG6GeklFJKlZuIpIrIs8772Trnfqqzr4Hz/rddRLaKyC8ikuDsu0NE1jrvtwtF5OjKfSVKxZ4GhkpVnguAD5w/x4tIIxFJBL4BVgKtgWbARwAi8i9ghHNeLWyWcUuEz9UYqAe0Aq7A/tt/23ncEtgNvOg5/n9AdeAAoCHwjLP9PeA8z3FDgfXGmBkRjkMppZTam/4DDAB6Aj2A/sD/OftuAdYAGUAj4G7AiEgn4DqgnzGmJnA8sGKvjlqpSqBTypSqBCIyCBuUfWKM2SwiS4FzsBnEpsBtxphC5/BfndvLgCeMMX85j5dE8ZTFwH3GmDzn8W5gtGc8DwM/OvebAEOA+saYbc4hPzu37wP3iEgtY8wO4HxsEKmUUkpVRecC1xtjNgGIyP3Aa8A9QAHQBGhljFkC/OIcUwSkAl1FJNMYs6IyBq7U3qYZQ6Uqx4XAd8aYzc7jD51tLYCVnqDQqwWwtJzPl2mMyXUfiEh1EXlNRFaKyA5gMlDHyVi2ALZ6gkIfY8w64DfgdBGpgw0gPyjnmJRSSqlYa4qdheNa6WwDeBL7Jet3IrJMRO4EcILEm7CzdDaJyEci0hSl9nEaGCq1l4lINeBM4HAR2eCs+7sZO8VlI9AyTIGY1UC7MJfdhZ366WoctN8EPb4F6AQcZIypBRzmDs95nnpO4BfKu9jppP8C/jDGrA1znFJKKVXZ1mFn6LhaOtswxmQbY24xxrQFTgL+7a4lNMZ8aIxxZ/cY4PG9O2yl9j4NDJXa+04BioCu2DUPPYEu2CkspwDrgcdEJF1E0kTkEOe8N4FbRaSPWO1FxH2zmwGcIyKJIjIYOLyMMdTETifdLiL1gPvcHcaY9cB44GWnSE2yiBzmOfcLoDdwI3bNoVJKKVVVJDvvnWkikgaMAv5PRDJEpAFwL3ZZBCJyovNeKsAO7HtzkYh0EpGjnCI1udj3y6LKeTlK7T0aGCq1910IvG2MWWWM2eD+wRZ/ORv7rWV7YBV2UfxZAMaYT4GHsdNOs7EBWj3nmjc6523Hrqf4oowxPAtUAzZj1zVOCNp/PnbtxQJgE3ZKDc443PWJbYAxkb9spZRSKubGYQM5908aMA2YBcwG/gYeco7tAEwEcoA/gJeNMT9h1xc+hn2P3IAtwnb3XnsFSlUSMSZ4hplSSpVORO4FOhpjzivzYKWUUkopVeVpVVKlVFScqaeXYrOKSimllFJqH6BTSZVSERORy7HFacYbYyZX9niUUkoppVTF0KmkSimllFJKKbWf04yhUkoppZRSSu3nNDBUSimllFJKqf3cflN8pkGDBqZ169aVPQyllFIxNn369M3GmIzKHke80PdHpZTaf5T2HrnfBIatW7dm2rRplT0MpZRSMSYiKyt7DHtCREYCJwKbjDHdwhxzBLYfaTKw2RhzuLN9MPAckAi8aYx5rKzn0/dHpZTaf5T2HqlTSZVSSqmq5R1gcLidIlIHeBk42RhzAPAvZ3si8BIwBOgKnC0iXWM9WKWUUvsGDQyVUkqpKsRpBbO1lEPOAcYYY1Y5x29ytvcHlhhjlhlj8oGPgGExHaxSSql9hgaGSimlVHzpCNQVkZ9EZLqIXOBsb4btM+pa42xTSimlyrTfrDFUSiml9hFJQB/gaKAa8IeITAEkxLEhmxWLyBXAFQAtW7aM0TCVUqpqKSgoYM2aNeTm5lb2UGIuLS2N5s2bk5ycHPE5GhgqpZRS8WUNtuDMTmCniEwGejjbW3iOaw6sC3UBY8zrwOsAffv2DRk8KqXUvmbNmjXUrFmT1q1bIxLqu7R9gzGGLVu2sGbNGtq0aRPxeTqVVCmllIovXwKHikiSiFQHDgLmA38BHUSkjYikAMOBrypxnEopVaXk5uZSv379fTooBBAR6tevH3VmVDOGSimlVBUiIqOAI4AGIrIGuA/blgJjzKvGmPkiMgGYBRRj21LMcc69DvgW265ipDFmbiW8BKWUqrL29aDQVZ7XGfOMoYgMFpGFIrJERO4s5bh+IlIkImd4tq0QkdkiMkNEpnm21xOR70VksXNbN9avQymllNobjDFnG2OaGGOSjTHNjTFvOQHhq55jnjTGdDXGdDPGPOvZPs4Y09EY084Y83ClvACllFJhbd++nZdffjnq84YOHcr27dsrfkAeMQ0MI+2p5Bz3OPZbzmBHGmN6GmP6erbdCUwyxnQAJjmPlVJKKaWUUqrKChcYFhUVlXreuHHjqFOnToxGZcU6YxhpT6XrgdHAphD7QhkGvOvcfxc4ZQ/HqZRSqpJk5xYwfWVpbftUVZZXWMSoqauYv35HZQ9FKaWqvDvvvJOlS5fSs2dP+vXrx5FHHsk555xD9+7dATjllFPo06cPBxxwAK+//rrvvNatW7N582ZWrFhBly5duPzyyznggAM47rjj2L17d4WMLdaBYZk9lUSkGXAq8ColGeA7p0/TFZ7tjYwx6wGc24ahnlxErhCRaSIyLTMzcw9ehlJKqVi55oO/Of2VP9iZV1jZQ1HlkF9YzF1jZvPbks2VPRSllKryHnvsMdq1a8eMGTN48sknmTp1Kg8//DDz5s0DYOTIkUyfPp1p06bx/PPPs2XLlhLXWLx4Mddeey1z586lTp06jB49ukLGFuviM5H0VHoWuMMYUxRikeQhxph1ItIQ+F5EFhhjJkf65FqOWymlqr5/Vm0HILegiPRUrYkWbxKc9+6iYn2bVUrFj/u/nsu8dRU706Fr01rcd9IBUZ3Tv3//gJYSzz//PJ9//jkAq1evZvHixdSvXz/gnDZt2tCzZ08A+vTpw4oVK/Zo3K5YZwwj6anUF/hIRFYAZwAvi8gpAMaYdc7tJuBz7NRUgI0i0gTAuY10CqpSSpVq5Zad9Hnwe1Zt2bXXnnPt9t2+2zcmL8OYiv2APXlRJht3hC9ZXVRsysz2/Lwok9Z3juWop35i+678Ch2fG1D0eWgi1334d4VeW8VeYoITGFbw761SSu0P0tPTffd/+uknJk6cyB9//MHMmTPp1atXyJYTqampvvuJiYkUFlbMjJtYfzXr66kErMX2VDrHe4Axxhcii8g7wDfGmC9EJB1IMMZkO/ePAx5wDv0KuBB4zLn9MsavQym1H5gwZz1XvW8Dk8//WcuNx3SI+hrGGNrcNY4bj+7Azcd2BGDd9t1MmLOB8we2Ijkx8Pu4qcu3cuZrf/DsWT15948V/LNqOz8vyuSdi/uRlLjn390ZY7hg5FQa10pjyt1Hhzym670TyCss5vNrDmb1tt20bZBOt2a1A67x+d9rAFi2eSf/rNrOkZ39M/iLiw23j57FeQNa0bNFHbJ2FzDiq7ncPbQLGTVTA55r045ccvIKaZtRgyWbsqlTPSUgoJi2Ytsev2a1d7kZw2LNGCql4ki0mb2KUrNmTbKzs0Puy8rKom7dulSvXp0FCxYwZcqUvTq2mGYMjTGFgNtTaT7wiTFmrohcJSJXlXF6I+BXEZkJTAXGGmMmOPseA44VkcXAsc5jpdQ+IGtXAa3vHMuXM9aSk1fIG5OXhf3AWVhUTOs7xzLy1+V7/LxfzljrCwoBkhIDp7aPn72e1neO5YVJiwO2/7ViK9d++DfFxYbtu/J5ftISAJ6btNhXjOOlH5fwwDfzGD9nA/mFxeQXFvvOn7suC4C/V21jd76tSPbrks3MWpu1x69p+sqt9HrwewA2hMkY7sovJM8Zz+78Im4Y9Q8nvvCrb//Hf62izV3j2LarwLft4nf+Cshqbt2Vz2fT13Day7/x14qt3DVmFp//s5YRXwe20Hv6u4X0f2QSR/33ZwCOeXoyfR+aGPDzqJaSuIevWu1tbsZQ40KllCpb/fr1OeSQQ+jWrRu33XZbwL7BgwdTWFjIgQceyD333MOAAQP26thivpjDGDMOGBe0LVShGYwxF3nuLwN6hDluCxD6q2+lVFzZlJ1L7WrJpCbZgGDVVjuF89WflzFl2VZGTV1FmwbpHNO1UcB53qmRD3wzj0sGtWFP/Lo4cCql+2G3sKiYJZk5XP2BDRpf+GEJ1x/tzyRe/f50Nufkc8GAVpz1euA3e78t2UyXJrVYuMF+M7htZz5HPvUTO/MLeeiUbsxYtZ3Fm3J8z+cNivILi7n3yzkc17Uxgzo0CDnmjTtyWbghm/5t6pGWnEhOXiFf/LOW96esJDFBmBu0duKJCQu4fXBnduUXsjk7nxb1qrEsc6dvf9bugoDjjTHcMXo2YKeSek1dvpUNO3L59yczeemc3oANDP716h++YxZuyGZzTh55hcW898cKXvt5mW/flzPWhnxN+0nf4X2K809F1xgqpVSEPvzww5DbU1NTGT9+fMh97jrCBg0aMGfOHN/2W2+9tcLGpav8lVKVZvXWXRz6xI9ceXhb7hrSJWBfUXExO5xAZVdBYG+fTTtyOeiRSTSrU823bXd+ESlJCUxdvpUmtdNo3cA/Z98Yw+ac/BLTGt19//1uEZuy8wK2PzZ+Aece1JLnJi7mTU9GstiTKSsoKvZNo7tg5NQS187MzuOkF35ltpP9y8kr9K0nvO7DfwKOzS8spronMMzJLeS9P1by3h8rWfHYCSWuDXDQI5MAaNsgnXcv6c/DY+czYe6GkMcCvPzTUm4f3Jmu94ZqGQsLNwZObflhQfjl294g+Kr3p4c8ZsmmHPo+NDHkvhs/mhFye7VkzRjGGxFBJPDfhlJKqfijgaFS+7mdeYUMfm4yw/u1ZNTUVYy/8VBqpiUDNmgKUS04LGMMZ70+hanLt/L7nUdRu1pyqVUm/15l15O99vMyduwu5NHTupPjtCxYtDGHGp5zP/5rFZ//s5abj+nIQ2PnA/6iLQBd7p1A+4Y1WLIph4Ft6zPqCjv9YuWWnQx57hd25RfxyZUD2ZlXyBcz1nLuQa3o06ouI76ay/+mrAw5vld/XhoQFAIUFhuGvfQbJ3ZvwifTVvsCyjzPdEjXa5OXBTxesXlniWNcH/y5KuDx5//4M2oXjJzK5EWZZNRMpWuTWlx0SGtuGOUPLJdt3smhT/wY9tpeHf8T+ptIgGcn+qfJbsrODftziaUXzu61159T7blEEc0YKqVUnNPAUKkqanNOHt/P28iwnk0pKja+YK0001duY2lmDmf2bcHLPy3hiQkLWfbIUBISwgd389bvYPXW3Tz57UIAZq3J4pD2DViwYQeDn/2FDy87iF4t67I0M4duzWozY/V2Lnt3GoO7NeL9Kat44exenNSjKQBz1+1g6nLbqPzgx34A4IKBrSgsNvRuWZcz+jQPeO5MT5Zu1NRV5BYU0atlHd+2v502BlOWbeFDJ3AKnq7ptcSZlpmdV0BeYRHPTlzMKz8t9e3/dNpqPp1ui6h8OSO4QHJJL/24NOT2mau3M3P19jLPD+Y+dyTGzl7vuz/ZmcaZmZ3Hz9mZJaZ1RiO/qGQAG0r/h2028uQeTflqZtk/K69fbj+STdm5nP7KHwHbj+nSkInzSy8i3TajRlTPpaqGhATRNYZKKRXnYt2uQilVTtd/+A93jZlN13u/pfuI7wL2rd2+O+QardNf+Z3bP5vFY+MX8MQEG+jtDpqGCXba4o5cO02zICjTVeAEDlOW2oaq57z5J13uncCJL/xK1q4CXvxhCZtz8nh/ig3U7hw9C4Dfl2zmnd9XlHiu9/5YyYd/ruLWT2fS+s6xtL5zLNnOc2cGTd/8/J+13Pvl3BLX+DAom1aWOWt30On/JgQEhRB5YPbUv0Iuby5TgxopIbef0L2Jb81isOBguTKMvKhv2H2Hd8wIu++Q9vVDbm9Rrzp9WtVj6SNDA7Y3r1s9ZEbw1F7NSE4Uzu7fosQ+FR8SdCqpUkrFPQ0MlYrS6Olrog5UpizbEjDt0bUzr7BEwQ+wUzLnrQ/fdPXkF37lxo9m8NA38/jvdwvZkVvArnx/D5tXf/YHRDvzCsnJK2TsrPW+SpKXvzeNA0d8x7rtu30Bomv2miyGPvcLI76eV+J5f1i4kYnzNwZs69q0FmADyM8iDLy6j/iOr2au8021TColo1mWe0/sWu5zwylvsFYrTFb3pXN7h51m98TpB5brubzOPaglAC3rVQ/YHrxeb8RJgT+ru4Z0JiUpgb6t63HegJYhr90mI51PrhwIwH0ndeXNC/ry7U2HcfEhrXnx7N6+484b0JJTejblw8sO8m1LTBAeOqWb73FaciIn9WgakBUef+OhPHNWTxY+OIRHT9vzn4WqHDqVVCml4p9OJVUqQnmFRSSIcMunMwE456DQH6SD5RYUMfz1KbRpkM6Ptx4RsO/Ip35iU3Ye3918GMZAo1qpPDJuPr8v3VKiRcO1H/7tq/64ZadtMO6uf3vhhyV0blwz5PP3dwqUuH689QjfVMSDH/uhxOt45/cVvusHu/njmSW2bdyRR9auksFtWbxr5BY+NIT563ewY3cB57z5Z9hzkhKE1g3SfVNGJ91yOO0yanDJoDZcP+ofvo5yyuOnVw3k+3kb+WfVNv5y+ufNf2AwYLN83umcAGNvGMQbk5dRMy055Pq7QR0a8PoFfTnm6Z992248uvReiAkJwn+GduHhcfOjGrtXn1Z16dGiDgc0rcXzkxbTuFYauQXFXDyoNYOf/cV3XHJS4HeBJ/VoypWHtwPgskFt+X3pFk7v3dw3rRggo0YqLepVL1EAJ7j/00OndA85tvMGtGJLTj7PTFzE8s32723U5QPIzi2kfnqKb5pzadOdVdWXkKCBoVJKxTsNDJWKUKf/m0DHRv71T4VFxSUakH8/byMv/riEMVcf7Js6OGuNrUiZmZ3HrDXbSU5MoHpKIpMXb/YVLjnumckApKcksjO/5NRPgLGz1vPMmcXkFobev2BD6Gapwc56LXDdV3D2M1xQGEqHhjVYvCmHHg98V/bBpUhMEF9D9al3H81JL/7Kxh15JY47tmsjXjmvD63vHAtATU9xmjaeKqRep/Rsyhee9YQD29bnjD7NObFHE1KTEunXuh7FxYZTXv6Nqw9v52sZ8dK5vcl89Q+mrtjqOzc9JYlnh/fCGFMiMPzm+kF0bFSTlKDgq37Q9NLOjWuW+Lu6/LC2jPxtOeuzcpn478NJSUzgsCdLFpP58dYjOPKpn5yxJHJs10Z8MWMdInBmXzsN87XzA6eFjrnmYFZs3sm8dTs4vXdz+reux7G+3zf/z691g3R+uOUIcguKAgPDEJVco3Vmv+Y8M3ERA9vaqadpyYmkafXRfUpiggT0tlRKKVUxatSoQU5Ozl55Lg0M1X6vx/3f0btlHd6+uH+Zxy7a6P+H+cA388jOLeSZs3r6tl39/nQKiw2j/17D0Z0bUlBkeH2yndaZk1fIyS/+Vur1wwWFro7/N54jOoVf8+U6q28LPp62OuS+aAK/0rx0Tm+a1EnjtJd/j+j49y7pjwEuDNHWwathrTRqpCaxEX9g2LVJLQ5sXpvzBrQC4OVze/Pw2PnUqe4Puk7v3YznJy3mhqPaY7BZVIBnh/fyBYat61fnhAObcHrQVNGEBOGr6waVGMsnVw1kfdZu8guLWbIpx9cCQ0To17ouR3dpxGPjFwD4Aluv+07qytn9bUbWrZjarmGNkEH8Oxf3Z+zs9bTLSEdEWPTQEJIThVlrsnjy24XcdnyngOA3LTmRO4Z0Jr+omOMPaBz259m7ZV16t6zLac6szw6NavLhZQcx8rfl1Ewr+RaQlpzIxH8f7guQywrgxt1wKMmJpWf7mtSuxuwRxwVUmVX7lgQRijQwVEqpuKbv0iqurNm2i/rpqQGNwIO9+vNSpi7fyiOndmfJppwSzcGLi03AtLWs3QX8uDD6Ko/v/WEzRpcf2pba1ZO54K0/KXSmUt3+2Sya1E5jfVbuHjXsPqxjBpt25AYEEj85Yz2yU0aJcackJpBRM5U7hnQOGxiGmu5Vt3oy26KYDtqvdV1OOLCJr1CN6+vrBpGanMBxz0zmtuM7cckhbfhu3gbmrdvBYU4Rk4n/Poxjnp5c6vX7t6nH0sydtG9Yg805eXx13SEB2dmh3ZswtHuTgHNa1U/3FTtJTBAGtqvvy4hN/PfhZOcW0Ktl3Yhfo6tJ7Wq+63t9etXBgF1X2DBMVu3iQ9r47r97SX/GzVrPeQNacWyXRtz08YyAYzs1rkknz3RgN/PYo0Ud3ves22vTIJ3lm3eSlpxIk9rVePncPlG/poPbN+Dg9g3C7m/fMPLKoO4a07JEUlVXxa8EESIseKuUUvu1O+64g1atWnHNNdcAMGLECESEyZMns23bNgoKCnjooYcYNmzYXh+bBoYqrgx6/MeAHnWhuBmcAY/atXXu2qideYXc99VcPpu+hpEX9SUtKTHgw3GXeybw+gV9aFI7zcnQdCa3oIiuTWqVaLDuNfT5X2jbIJ1lQT3q1mflArAnX6K3rFeNA5vVDplhevCUbgx59hey8/xFZ0ZdcRB9WtULOO7Cga244vB2/LlsC59MW82UZVuDL0W3ZrVpVCvNtkMooxXCbcd38hU7SU5M4IWze5G1u4AuTWrSvbnNmnnXow3r2YxhPZv5HrdvWJPRVx/MjtwCLn77r5DPMeLkAzinfyvf9SLlrfx5cDv/3200gU60Qq01bZeRztLMwN+HZnWqcflhbQEY1rMpN308g27NIguqvF4/vw/HPjOZ1GStHaaqjsQESqyLVkopVdLw4cO56aabfIHhJ598woQJE7j55pupVasWmzdvZsCAAZx88slR9ZKuCBoYqirBGMPa7btpXrd62Kbqbqbrj2Vb2LQjl6WZOxnYzq5ZuvGjf6hdLZn7Tz6gxHm5BUUUFRsOuO9b37ZL3pkGwOTbjvRt211QxLUf/E23ZrX5fekWvp1rq2/aMuyhx92zRR1mrN5eIiiMxJfXHsKstVnc88Uc37YW9aqxequ/eumdQ7pQbAz10lN44BtbJfSGo9pzZr8WNK9bnVuP78R9X83lsI4Z9GlZl54tAjNi7TLSuX+YrQp5Wu/mHNu1ka/1xYx7j2Xe+h2c88afNK9bjUdPO5CXflxSZmB4aq9mAVM43R6G0ejTqi7GGJIThduO71Rif2pSYtRBYVXyzfWHkh+i4b1LRBh7wyCa160e9phwWtVPZ0Dbetx2fOc9GaJSFSpRRNtVKKXiy/g7YcPsir1m4+4w5LFSD+nVqxebNm1i3bp1ZGZmUrduXZo0acLNN9/M5MmTSUhIYO3atWzcuJHGjcMvFYkFDQxVlfDZ9DXc9tksHjylG/d8MYcPLz+Ivq3qkZKUwO9LN9OzRZ2AzNvto2fx08JMfr7tCDJqpvqalY8LqiIJ8PrkZTz9/aKQzxtc4GNHbiG/O/37XKV9Cd6qfnVmBDU6j6Qh+PEHNKJHizr0aFEHgL+Wb6VdRg16t6rDhDkb+MApCOOuybpkUBtfYHjzsR19gXOjWmmADV5vPCaw+uWc+48v0QaiZloytx3fibnrsqhTPYWBbevz8KndfBm9yw5tw/qs3XRrWptN2Xl8Mm01X1x7CA1qpJJXWMTijTk0rVOt1NcWKRFh8cNDyz4wDlVLSSx1ujPAAU3LF/imJCXw0RUDy3WuUrEiusZQKaUidsYZZ/DZZ5+xYcMGhg8fzgcffEBmZibTp08nOTmZ1q1bk5ubu9fHpYGhqhLc4Op9Z93es98vZuqKrdw+uBNPTFjIsJ5NA/rV7XKKtIz8dXnAVMrNOSULq4QLCktzeMcM1mftDig24zq7f0tGTV1FteREjunSyBeUAhzaoQHPn92LW47ryOFP/sQJBzZh7Kz1PHJqdxZs2MHgbo05540/6dDQv5bs/AGtON8pqmKvkeELDL0SnXLw3mxqRk2budsWoqBMuEIf1x7Z3ndfRDj3IP9zpyYlBrQduMHTaiE1KTFkgRWl1H4ufxf3FDzHih1DgJ6VPRqllIpMGZm9WBo+fDiXX345mzdv5ueff+aTTz6hYcOGJCcn8+OPP7JyZcmWWHuDBoZqr9qdX8S2XfnUrZ5CQgIs3phDp8Y1fYUp3HVTbouAJybYsvlfzlhHsqf4iJsIe/ePivmHc0yXhnRvVodnJtogsnpKIu9e0p+Bj/4AwMWHtKZhzTQen7CAWmlJnNKzKecNaEXf1vX4Z9V2Rv62nDP6NPc1K29VP923zu6lcwKfa9TlA+jbuvQiKB9fMYD0oMDul9uP9LW3cLVpYNfOHVdKVUqllIopU8Tgop8Yk9e17GOVUkpxwAEHkJ2dTbNmzWjSpAnnnnsuJ510En379qVnz5507lw5y0U0MFQVJregiKzdBTSqlUZ2bgE1UpNKrBW86v3pvjVs9dJT2Loznz6t6jLTyRhu2xW+lcJn09f47m8K6nHXun51VmzZFdV4+7Sqy/SVtqn5VYe3o2/repzaqxmHPfkjh3bICMi4nXhgU3o4a95O79OMhjXTfPua17VTK9OSEyJq0u2uiyzNQW1LHtO0TrUS0zjrpacw5/7jqa494ZRSlUWcL+2MliVVSqlIzZ7tX9/YoEED/vjjj5DH7a0ehgBa1k5VmKvfn85Bj0xi5urtdB/xHWM96/2ydhdQWFQcUNhkqzP9cfrKbb42D97CK6VZtnmnrz8cwH0nlSw607dVXY7p0ogXz+nF73ce5dv+/qUH8fV1g/jfpf6+hbWq2Yxly/rVmf/AYM7u3yKg+XefVnVJSkzg6iPaBQSFAOmpNihz2xrsbTVSkyIKSJVSKjac/380MFRKqbimGUNVqiWbctiUnRtQ+j8ct6fesJdsE/env1/EiQc2JbegiB73f0ejWqF7vZVXw5qpZNRMpXndahzUNrBFw3c3H0ZGjVTqpvurZ2bUTCUzO4/qqSUrXtby9Fhzi4ZEWiH49N7N2Z1fxNkh2hYopdQ+TzOGSim1T9CMoSrVMU//zDlv/Ikxhu278jn8yR+ZvSYronOXZe7k+Gcm88OCTQBsDJr+Ga0mtQMzdYkJwu93HsWnVw6kekoSyx4ZSq+WdXjyjAPp2KhmQFAIcGzXRgDUrlay0XataqG/I/nvv3ow7oZDSx1XUmICFx3ShtQknc6plNoPaWColFL7BA0MVUS27MxnyrKtrNyyi8cnLODGj/5h/vodvv23fDIz5HkLN2ZzzQd/R/Qcb13YN+Dx9Ue1D3jc02nt4K71KywqJjkxgSSnKE1CgvD5NYfwr74tQl7/3hO78vEVA2iXUbLZebUwa/RO79Ocrk2jb0KulFLlJSIjRWSTiMwJs/8IEckSkRnOn3s9+1aIyGxn+7S9M2A3MNR2FUqpqs/sJ/9Xled1amCowtq0w98/pe9DE5m+0lYK/XXJZr6csY4hz/3C0f/9iW078xn9ty0M899/9Yj4+j1b1OG9S/zr/AZ4Cq489a8e3HJcJ/q39k8RffCUblwwsBVvXNCX4w9oxAUHt47q9aQlJ5Yo6jL2hkHcf/IBJYrkKKVUJXoHGFzGMb8YY3o6fx4I2neks71vyDMrmhMYGs0YKqWquLS0NLZs2bLPB4fGGLZs2UJaWlrZB3voGkMV0oQ567nq/cBM3xu/LC9x3NLMnXw/byNge/id3qc5XZrUQgSGPPeL77hOjWqycGN2wLlfXHtIwGNve4bTetmG66+c15s+D00EoEGNVB4Y1g2A186vmM87BzStXe5G40opFQvGmMki0rqyxxEx54s10cBQKVXFNW/enDVr1pCZmVn2wXEuLS2N5s2bR3WOBob7CWMMb/5ie+3lFxXzxuRl3DGkc0BvQIDZa7K46v3prN0eWXVQgNtHzwLgqM4NAXxTL2fceyw9H/iewztm8NzwnuTkFdK8bnVa3zmWNg3Sfee3y0hn3fbcgGu6VTbr16jYgjVKqb3MGJj8FPS5EGo0rOzR7EsGishMYB1wqzFmrrPdAN+JiAFeM8a8HvORiFCM6BpDpVSVl5ycTJs2bSp7GFVWzANDERkMPAckAm8aYx4Lc1w/YApwljHmMxFpAbwHNAaKgdeNMc85x44ALgfccP9uY8y4mL6QOLI+azc784po39CupTPGMG72Bh4eN5/Za7MoKjaMnb2eQR0acEQn+0Hto6mr+Hjaav5Ztb3Ua998TEdSkhJ4fMKCEvtqBDVkr1M9hQ8uO4juzWtTKy2ZOtVtMZgZ9x5LSpI/IP32psMoLaFfLz2F3IKiCF65UqrKWTMNfnwIVk+B80ZX9mj2FX8DrYwxOSIyFPgC6ODsO8QYs05EGgLfi8gCY8zk4AuIyBXAFQAtW+55RWWjgaFSSsW9mK4xFJFE4CVgCNAVOFtEuoY57nHgW8/mQuAWY0wXYABwbdC5z3jWV+zXQeGm7FzGe3oGDnz0B455+mff45d+XMK1H9ppobPXZpFXaIOs5Zt3ctm705i3bgd3jpldZlAI0KJeNa4+oh3XHNGOZnWqcaoz5RMIGdwd0r5BQCsIsAFjdU+PwKTEBF/msmOjkoVhptx1NDPuPa7MsSmlqqDiQnubt/ca9O7rjDE7jDE5zv1xQLKINHAer3NuNwGfA/3DXON1Y0xfY0zfjIyMPR8TCVp8Riml4lysM4b9gSXGmGUAIvIRMAyYF3Tc9cBooJ+7wRizHljv3M8WkflAsxDn7pd25xexK7+Q+jVSOeu1KSzfvJM59x8fkLUb9uKvPHb6gXznrAEEGwwu37wTgPu/tj/KifM3EkpqUgIvntObJrXTWLV1F9/N3cBhHe0HiNsHd+b2wZ3ZkVvA5/+sBaiQrN7n1xxCdm5hwDZvdlEpFWe0lUGFE5HGwEZjjBGR/tgvebeISDqQ4LxnpgPHAcGFaWJCp5IqpVT8i3Vg2AxY7Xm8BjjIe4CINANOBY7CExgGHdMa6AX86dl8nYhcAEzDZha3Vdywq75/vfY7c9buYMVjJ/gCvU07ckmrV913zMw1WQEFYKLRrVkt/jO0KwPb1Xce12Zo9yYljquVlswRnTL4eVEmJ/doWq7n8kpPTQooQqOUinMaGEZNREYBRwANRGQNcB+QDGCMeRU4A7haRAqB3cBwJ0hsBHzuVFlOAj40xkzYG2M2koBd9aGUUipexfoTeKgeAMFzTZ4F7jDGFIVqGSAiNbDZxJuMMW7jvFeAB51rPQj8F7gkxLkVuoaishUXG19Rljlrd5TYP3fdDu5wCsGUxyHt6zNl2VYm/ftwWnuKw5TlnYtDzlRSSilfxcrQk81VKMaYs8vY/yLwYojty4DIewZVIINoVVKllIpzsZ6jtwbwdhtvjq2g5tUX+EhEVmC/BX1ZRE4BEJFkbFD4gTFmjHuCMWajMabI2KZJb7CX1lBUpqzdBbS9exzv/BbYMqL1nWN9968f9Q9/rbCJ03AN2+unpwQ8PuFAfxbwriFdWPrI0KiCQqWqlG0rYPH3lT0KFcAJDDVo2KfpGkOllIp/sQ4M/wI6iEgbEUkBhgNfeQ8wxrQxxrQ2xrQGPgOuMcZ8ITZ9+BYw3xjztPccEfHOaTwVmBPLF1EVzF9vM4Qjvp4XEAyG8+OtR4TcPu3/juHPu4/mpXN6c/vgTrx0Tm+uOrwdAF2b1Kqw8aowigpg19aS23NK6acz70sYUdsGPfuS3dvgx0eguAIrzr7YHz44o+KuV167ttq/63BW/ApzxoTfH63d26Awv+KuF8qUV2Hz4nKc6AQLGjTs0wzax1AppeJdTKeSGmMKReQ6bLXRRGCkMWauiFzl7H+1lNMPAc4HZovIDGeb25biCRHpiX0vWgFcGZtXUDmKiw2/LtnMoPYNmLJ8Czvzivhx4aaIzr3h6A50bFSDxrXT+Pq6QTSpk0aN1CR+WriJutVTEBEa1UoLyBTeOaQztx/fyTdNdb81bSQkpUHPc2L3HF9eC7M+hvu2+6fYzf4MRl8Kl02C5n1LnjP7U3u7bgbUbV1y/4Y5UL89JKfFaNBBiotgw2xo2nPPrjPhbpj5ITQ+ELqcGP35mYvgjxfgxGchwcmQF+Xt2ZgqyhNtoOspcOa7ofe/c4K97XZaxTzf462h7ZFwwRcVc71gRYUw4Q5IqwN3rozuXDfw37HO/qnlWYv846PQuBt0OanChqoqh5EERNcYKqVUXIt5lQ8nkBsXtC1kQGiMuchz/1dCr1HEGHN+BQ6xypk4fyNX/G86txzbkf9+v6jM46f+52j6PzwJgPMGtKRhTRsgdG9e23fM4G4lC8d47fdBIcDUN6B6/dgGhrM+trfFhZDotPFY+Zu9XfdP6MAwMcV/TrAd6+HVQ6D3hXDy8xU/3lB+exYmPQCXToQWTr2o3Cx47TA4YyQ061P6+YX58Oog2GGr2YZ8XZH46GzYsgQOvgEadCj7+L3FDYTmfVH2sdtX259Di4Ng/tfQcTAkpZR9XijLfgy/77fnYfWf0P0M6DIMEhJg/Sz7u9Wwc9nXdjNBudujH5f797tzEzzdBYaPgs5DbUb1Z6et7Yis6K+rqhTbx1CzwkopFc+0D0AVc9eY2Vzxv+kAjAxaTxjKST2a0rBmGkO6NaZXyzq+oFB5ZK2Bv98r+7idmVCwK3bjmPel/36RZ9pfkvN3VrA78PicTfDXm5DgBJDeqYkLJ8Da6ZDt9K9c90/J51s4AUZfZoO2irTBmbm93ZM5WvWnner646Nln799FWxeCPl72Ndu93Z7mxDi+61IP6Dm76r4D7OFUWQtn+sBI4+H5T/DJ+fDDw/a7Qsn2OnDORHMFChtyqrr+3tgwTfw6UUw9XW77bVD4eWDIHtD+PP++cCOIy87cPv8r23WOBLBgf+X19rbLUsiO1/FBYNmDJVSKt5pYFjFjJq6ynd/267wH/guOaQNAM3rVgPg5XN7M+bqg2M7uHj13inw1fWBAdKyn22G0FVcBLu2lAzOKoox8MkF/sfuh/ntq/zl/IMDio/Ph7G3eDJrnt+HUWfBG0f5g6vUmpC7wwaI+bv8x8z+FMbeWrGvxc1gFoVY0yZipwtOuDv82sHC3JLnlIf79xkqMIokC7llKTzSxJ/FrSjBr680xvkZ7Xa67bjrSKe8ZG83zg193raV8O1//NN6SxP8xcDWpYGPJz8V/tzJT9rbLE/XobG3wMfn2azv9lWhz/MK/rtwX7P3tUUS3KoqTaeSKqVU/NPAsJIZYxg1dRVbd+ZTWBT5m+pVR7Sld8s6XDiwNQAiQqh2H/u9JRNhi1Mww5sZeu9kGHerv+jLrq12ulz+ztiMw83suYoKbAD3bHf4w6k6XxgUlO5wCvgmhsgYuvKcwDClBrzYF14/Aj48M/CYnUFZp+wN/qxfeSQmhR8PwBdX28Bmtaft6K6tsPZvez84AJZy/jfkBspugJq90b/vrWNt4Ad26uryySXPX/aTvV1Rvl6fYUUTGPp4Knfm5fjH6/7d79xi15i6PrvY/t6MuxXeOLL0Sz/TPfDxgrHw0bn+xzUbhT/Xzcb+9Jh/219v+u8/2x3G3wG/Pmsfr5nmz+SC/QLms6BOQoX59me/ab5/255mj1Wls+0qdCqpUkrFMw0MK8Ftn87k02n2G/ifFmVy15jZ3PvlHI59xv/h9diu/g9rtx3fqcQ1GtZMY8w1h9C4tk4dLdX7p3sehPjQ8voR9tYNngp22ymaK36t2HFsCyrYUVxQMuMWHDC5hVTcD+du5sX74esjp91Zag3IcQKj4EAnOIB7roddl7h9lZ0mOKK2P7uXvwv+/l/p0yvdqa3eDKbvZyv+rKs34PvfKTaAMSZEgZg9/ELD/Tm+1M+/bd0/8OPD9v7398C7J9k1dV5bl9nbem337Pm9Zn5k1w2Gs2a6/RPMzaIZA9Pf8W93/17eOgZeP9y/3Q2+IpnOmReUMdyx1k4r9T23gblf2PWqrp1b4IEG/i9VFo0Pf/0/X4WJ99mA782jYZSnBd9H55Rcl1i4G94bZn9WvjFqYBjvdCqpUkrFPw0MK8Gn09dw22ezuO7Dv7n47b8A+GbWepZv9merLh3UxhcQ7thdwIvn9PLtu3NIBMUilA14vEJNbdyxxt66a7kKdtkpmm7VyD3xxtHwWCt7PzgTWZRfcopd8PjcQNEN0twA6LkQ/auTqgVd3xO0lQhAnYzWTM8USneq4Pf3wlfXwdIf7M9v9OWQuRB+f8F/rG8qaYHTJiHP06PO+F9XUYE/gFk/097u3gZZa0uO3ysvu+zMrTeIdl9r8JTJbSvg7aE2cHGf28v9O5892r7WXVvtdNyJ90NBObJ+u7fB51fCyOPsYwnRS/TNo+yfYO5rMMX+nxXYzPaEu/xBrPs74r7+8mZbvbavhE8vtFnW/F3w/X2wcFxQ4B8B9+e7Zqq9zSxjHan7bw80Y7gPMKLFZ5RSKt7FvCqpCmQ8b5zfzFof8pjJtx1Jy/rVfYHijtwCTjywKYe0a0CRMTSokbpXxho3tq+CcbfBMfeXXmGxtH55Ozfb24r8gLp2mv9+QXBgWFgyYHMfF+TCNzd5Mi1uYOiuSwzRLiAhKEDwZm1CrQUE+PEh//3MRbYVhjt91Q3MZn8Cc8fYYK//FZCUGji19fHW0PpQ6Hep/1puYPiu04JiRBak1IT8bPj6Blu4xMsNKlf8CgvG2WmoabXhzjDr17atDMyUhWtRsTYoMxccRO1y/s43OWvdcjbB/K/g16ehRkMYcHXo67qWT7ZTJY++x7leUH9KSXCO+QmOvrf0a/kCXVOyX+WUl/33f37CVmB1px17p+sC/PaczYBG0/7hn/ftbdZqmP62rTpbHm5gWFxo1w96p76Wxf19G3+n/fs88ZnyjUFVGpsx1MBQKaXimQaGe9mu/JLByZGdMvhxob/Becv61QEY1rMpvy3ZzPVH2VL8ddPLWcZ+X/ess4Zqxzq4qpT1YqUVJAlehwc2eHPX0+Vk2gCi7RH28aQH7PS3oU9ENsbgDNimuf7+hL7ncwK4xd/CzFElr1FcFP4b+eCgZ8n3/vu5WTYLetzD0Gpg6PPdIMkN0rzXc39ua/+2r9vNzLlVJVf8Aq0HuQMpGYAXF9niOPnZJYNC8GemvFna3Cy7Xu3zK+HyHyGtFqz4Deq0gOcODDy/KD+y4iVu8LVqCtRq5v8ywCXi74eYtYYyvesEX25gGDxlsrjAf8zsz+DUUtq2utVwTXHpLSHc9g7J6aH3f+8EoOVt//Dt3aG3J6WVvXZytycwfuVgaDUo/LHB3KqnkVY6VVWOEUGKdSqpUkrFM51Kupfl5AUGJyJw2aGh1zhVT0nixXN607ROtZD792lbl8OMEMFRaZKr2bYUW8O0+fjLqUL69/8Ctxfk2lYVwXI2+oOJ/51i10W5Qc8v/4Wpr9n7T3e10/2Ki+z2HUGZ4Hlf2oIsXp9cUDJIcgOw4MqoSyba26L88O00TCkfyLatsNmztwfDa4eHPiYv264RK+0b/7cHw6rf/Rm2vz3N23/ytKkIDsB3rLWBYTjhgro3j7bB5xo73Zp3hvq/BPCa/zVMHBH++i43azvyeHi2m53q6PXhmTbwBX/WLmeTnWa6YKx9POYK+3juF/7zip2CMW+EmCLq2r4S3h4Sfv+EO+2tKbbTbzscF9lrKUtFtSqJpKBOcKC9MoJ1uonO7Ifv/g/mjLbnJOu66XikGUOllIp/mjHcS7bk5PH3qu18/k9gJmL5o4Fr2T687CD/g4LdtoVC7eZ7Y4hVyxtH2QxEj+E2et62Emo2sc2/83LsB97azQLP2b3dtqWo3QJunFnymr8+AwecZtfQeT0cpirjSwfZLNeILNjoVPHM32krgLrWz7KBz5SX7fS9SQ/AjA/hes80Rm+bitL4ppKGCf7ydtg1cCHPjXA92PoZobePv922LWjqrGUtV2VNbGCTuSBw23f/Z/sWhuOOPbWWfY3BSsuUgi3WUqtZ+P2uEus8g6ageqdwrp9l1/q50yGnvAKdT/C3tvj0Qv+x395VcZmurcttxrBumz27TlEBfHgWLJ2052NKTAk/HdmrtH6I4aTVsl/KbJzjr17qrS6r4oYRQUr7gkoppVSVp4HhXnL8s5PZnFP2h6uD2zfwP/joHKcISAU3KN9Tq6fa/mbDR/mnWlY0d1qaKYb83f7pg3evgw/OgFV/wH3bA3vgucFH1urwTcbdKouRyPc29RbA2KDN2+z7tUP9992MUGkfkIc+ZVsMhOILDMP0Ulz8HXQdFnqfW5xkT+zc5M88BhdqiVTw+jiwGdPSuFNJk6uFDgyL8souRrOjjII2YLN+CRH+vmatgtcO84yxlPWpf5YyRTRabo/Bmo2jPzcx1R/sThxRMUEhRB4Yjr8t+mun1iqZrU8IUbRHxQHRjKFSSsU5nUq6F4z5e02JoPD5s3vx6x3+/mO/3H4kP956ROCJS3+wt3tS6c0Y+w38iNp2bVVFGHO5DVKyImhuXR6LvvXfLyoIDJSW/2KDQrANvovCrBsMl/EqbwDlflj9byeYNrL0Y/Nz4MtrQ+9r2KXktnNHQ8OudkpkcVH4jOHWZeGzj8FFSMrLDQzLOwUxkobnwdyMYbhKoF/dAI+3Kt94vBZ8Y393y8MU2RYYZWkcYqpraVLCTLGtXj/0lwBJpUyz9E7BdHtjVgS32FAspNUqua0iKq2qvU7bVSilVPzTd+AYmjBnAzvzCrn/63kB2+8e2pmTezSled3qvm0t6lWnTYMwBSUinSYYbMVvcH8df1XDKa/Y2yUTy87ilMbtY1dUCL+/aCta7qnFE23wuvL3wAbtxYVBU/48QfKKyUFZPY9wGUO36mYobTwZouDiHt4Pq788Ff4aLrfSY7BQLQwSk2GT8zvy+wuwq5RsXai1kBXJzTKVVgClNOEqhJZm/O327z64355r99bSCwdVtEYhgrvVf/p7XpamxUFlH+PVoH3o7XVbQYOg/qV1WsGQx8Nfq7Sg0XeNlpGPzZUQw8AwNURgqNMR45IR0cBQKaXinAaGMTJ//Q6uen86B9z3LVm7AwO7zo09H4YKcstenxTJNC6vHets/zm399ymwMCU90+PfN1bKO50vJ2b4Lv/2Kmdu7fDZ5cGluzfsS58ILZ9lb+PHPgbbgdPy9swGz6/yv/YG9DWaRU4rdPLLZASrLT1S+2P8d/3/swXfVcxWYzbl4fuDZfoqTY78T7brqEsNcox1TAabsaw5cGxfZ6qqEbD0ve3DFPZFSILzrx2bQm9vU4rOPyOwL/n3O12jWx6RuhzQn3pEKzLydGNDwJ/P73uWgsH3xD99bySQxTW0sAwLhkSEO1jqJRScU0DwxjZkBU4Le7V83qz+OEhjL/xUA7b8Q18ONzuGHM5vDoIVpUyFTBcYGgMzP3cP50yLwcWjrcVMmd/AovG2+3V3XWLxvYJcy37uXyFHtx1hZudTGFRgc1GzvkM/nzNtjXYvBie7mL/uE3OwT7f011tdcmnOvi3pznN6IN7wX18nm2H4Jo5yr6epr3tlM2ZHwUef8VPgMBfYaZ75pTyeqvV89/3BnAf/qtiAsNqdZ3KnwRmJyOdqlfHM53y1oVw7md7PqZw3DWGrQ8p/bhwax73luoNyj4mXGuHcNx1qwOvC71/T4Mhr9PfCh2s1W5u/5119FQnLSq0Uy9vWQjdzih5jillHSRA7wugx9mB25r1KXuMSWECw9QaZQfRZQm15lODi7hkRKuSKqVUvNPAMEbmrvNPi2tWpxpHdGpIcmICXZrUss3L3aBt/lf2dmQp5enDTSWd9wV8ehH88YLN8DzaDEYN9wdsLjfImfcl/PmKf/t7J9sWDGALc4y+3E7pcwttFBXaQKYgN7D4hvthzp1Cmr3OX9Rl2wp440h4sa//eHdq6Ma58NnFgYVC3PWDbqXP4AxKqKCpQQf7AXnZT/Djw4H7GnWz0+UWji15HpQeGFavF37fngSG7Y6yAYAIpDjTh+t3gCY9nGtL+HO9kpzS/n0usreRFlIpj41OlrlZX9to/urfQx+XvoeBwZ468emyjwk3XTOcA06FI+6GI++GY0aU3J+eAc37ldx+2O3RZfer1YUW/eGMt0vuc3/v3d+7FgPgYud3OiERTnm55DllTTlvfGDJtiFne75YqRbm97+037NoM6TBdCrpPkRI0L87pZSKaxoYxkDW7gJem+wvcjLmmoNJSw4xzevnoOboC8fDX2+VPC7Uh82dW2xQCJC1NnDKZvDU0dLWZ7kB3Ufn2Cwj+IufvH44PJRh2zm4peTBv+bI24Jg2U/2dlZQBg/8hVFeORhW/ha47+HGNqh1nzN47G4w5FWrWfgiJwlJpX+QLa1iaPX6/vvBmZX8nPDnlaXVIdDdyfC0HAhnjITjH/ZP/Yv4S3YngHTbl5QnMOx1XmTHudUxk1JtNrfRAaE/xDfoUHJbqONioUYjf5uKigySk9LgiDsgJR0G3VyyKnCLftDn4pLntTvK/2/Vm1X0Tv1s0tN/382MJSbByS9CUqh+pc7f+YH/8rcSAfv34g1OOxxXdouRhKSSgWGNhnD3ejjtTTjpWWeMPYLOKyWjHWoqaHABnovGhT/fnSngpcFFXLIZQ/27U0qpeKaBYQws3JBNdm4hj53WncdP706jog12amWw4GzXqOEw9t8lp1ItnVSymIq3F59I+HVAEL7aI9igMbgxtftcbu8+sNlJN6hyP4R7X1O4Yi+R2L0tfOAV6nXVahI+MBTxBzWhFBdA/TAZpBpOP8N+l4XOFHnVbe2/f2iY9hMub3ArAt1Otx+o3WxQpB+E3cyvW8nSm0094u6yzx/8OLQaFNlzuZL9BZJ84+3t6eHX9gj/fTcYqla39GuWt0efd9rjsJfg1kU2eLODg2umwB0rynftSNV2ire4AWBvz1rdxBR/1q5eW//2azzTxL1Zae+/897nw+VO4R9vYOVmk0NNr/ROoz33U3/2/ZxPQ489ITGwB6crpboNPN3f/+7/8u87/3P41zuhrwehg8Z2R9nbA06F25ba6chX/Wq/bOkU2Lc1ZFVSbXAfl4y2q1BKqbingWEF+2nhJq798G8Aerasw1n9WsJzPfxTK18aUPZF1k4PfPz1jfDTY/7HmxbAQu+38FJ6n7Wysl1Ptgt8HC7z4GYz3dYNWasjf463h4bf91wPmPp6mJ0hplmm1Cw9C3rU/5U+lnCBS41GcPM8GPJk2VmvhgfY27Pe9wQnYYTLZtVqYm9LW2PoDTrdtaSpzod790N5au3Awjmu4Nc54CroeTbcPLfkGrVzR/vveytXegMc93V4A8PUmv4piO7zuT+7QTeHfk1uxjMUd2pi2yPt1MxzR8Mpr9jAd4gnw+4Gie4XByK2FUi1ujaw96rQQj3OB183CPMGzolJ/oAxJd2O9/IfIN2TiQ74dxr0ITqjMxxyI5z9sWdjKYHhyc+HHps3s+iVVjv8ekGwFVVvmg0HX+/f1qwPZHQsmUV0hepj6n6B0LArpDvBa+PucOqrlHjNHY733x/2ks2o/uvd8GNUVZeuMVRKqbingWEF+mz6Gi56+y8ys232LKNG0DTIR5pD5vyyL/Tm0TAqaCpj9nr//ZeDSuJPfS10tUuXt3hLJL67J3Sj8i1LbNawPNP2gqeQRqpmo5LbUqpDRoh+gK5QQZLXjvU2mHK50xGT0qB2M0hICD1FLoD7ASiC9YHhfl4nvwgnvwBNe4Y/9+h7/Pd9GUMnEHUD9KQU/9rF9Ax/xmbw43DvNmh/bGCBk9rN4fQ34b7t/m0dPD+z1k5hnJQa/g/23ufzBgOpNeGKH+HM9/xBUmIS3LsVjr4v/OsKp9NQG1gcfjsc9R87rp7n2KmdzT3rVt2A0JeN9fw9DH3KP023/xVOQOI45CZ72/vCkgGI+zvRKkQl1tOdL0XcAK1gp731/p4kJPsz54nJcNCVJYu7eLPDwcFeQiIc+4D9HXT51raG+MAdrvBLtTr++93/ZSuZnvBf6HxS4HFX/Bz4WKRkO4uEoLWOwUJOM5WgW4/6ni+h7t0KzT0/nwOHw5U/21YdKu4YSUB0GrBSSsU1DQwryKotu7j105mkJCUwsK3NENStHvTtfLiee6EsDFqXk54BW5cHtm7weqUC2wrMHWOzeKG2/7cTLPux4p6rLPkhmr0nV4cLv4ZLJ4Y+x1sQo/OJJfcnJMJdnqmoV/1q10EleP45iNgpdLVbhH4O90O9SOjiMUM9vQ4TQqwvBfsB3p2KeFJw9ieEojBTSRNT/UFZUYF/3ZaIfU3nfQZn/S/wWqHG3e10e9vqYPvzPffTwGPcANc7vTc53U6r7ToscMpsQmL4ojrhtjfpYafw3rctdHDm5Y7BmzH0Xt8NZPpeGjh90/27qN0CDjjFv715P/s7MSILajUt+XxdT7GVZN0gs9f5NjPX73LPmJL9f0eJIdbGQlBgGMGH6NKmkgIc/4g/Q+q20fBmoE9/E/71tj3G+/udnlH6FxIu37WccRx+J7Q5HE59LXC/N/NH4CkBjrrXfz/430Wo7KOKGwYhQTOGSikV1/SduIK88vMSAPILi3nnkn5s3ZlPQkKE1SYj8fvztlVDrBucR6vNYbB8cuyu7xal6X+Ff7ppcnWokWH/hOINDId/YCutBgj68FK9Xui2DAecav88UN9OXT3xGTsV8IBTbRXXReNtE/LgKrDX/22nYI5zpoFGkmHtcyF8HdQGITgodXs2uhkhNyuW5A0M8/1TO92WE5Fyp+cmVwtsp+FyP8h7s0TeYKPMLGsZrozi9yg4MAyXuQ0uXhRuXWdpU7HBBi0Xfu1/XLOx0xrFe0yyP5sbbnpxaVNJQ2l7pP29b9Y79P6B1/rvn/tZ+L6IXv+eX/bfVVptWxTK/d11f24tD4Ij7/If5/4uBMxYMIHneIWayjr4sdDBuIovWnxGKaXinmYMK0hBkf9DXmpSIk1qptpsV1kl5IN5g5rgPmoVFRS60+kqQrjMSEXJzYJ67WDok/5tKZ51XaGmsgWX0A9ec+irBhnh2K/6DYa9DH0vgf6X2+mVvS+AO1fbVgjBDcfrt7OZngPPcsYY4fcvbvZp2Mvwn402wAS4eLxdd1bkTFPM6Gxv3UAuKdX/MynK92fIgntClsVdwxhuzaMbiIbL+IWqIBv6QiU33b2+5LbSuGN0nzOjU9BTOM8R/LvgFljxTpGFiqmEmZBsf0+PfSB0YA2BvQYj6dfXeaj9PWvRv+xjU2tENg2zVtOyCwRd/qOd5uz+HH23QW8ZbpbP+/+c+7OMtMXLgKsrvx+m2mNGEoiixLJSSqkqSAPDCpCZncdn09cEbvz2bnikSWAbCVfNEN+O121jS8a70/kA2h1ZsQN1NehYcdcKVx20ouxYWzLg8DYsP/0Nm7XzCj4+eDqp+8H1+mlw4Tdlj6FhZ+h1buA2EX9FxR7n+HsLermBW6SB4QlP2amMvc61lRnd7Eqrg6HTYLtOrO2R/uIzbqCYlOpvddByoJ3mmJ4BB54Z2fP6xut8uA/XnsDNGBYX2WIwHYJ6b/raLUSRKXefyxvsR8L9O06uZqtwnjc66AAJPM7V9xI47Q3/39fd6+y/x7Kq0EYiMdkG5YfcGD549mYMW0ZQiApCV+6MtfrtAiuuukGeBE3/bNrb/q4d4cki+oLsCpwxoeKAkBDJlx1KKaWqrJgHhiIyWEQWisgSEbmzlOP6iUiRiJxR1rkiUk9EvheRxc5tGV9/x9ZLPy4J3LBhjr+RvLflg+vEZ0q2YUipYUvGux+++18ZvuF0sODMYig9z8P3Qa1aXZsRaHxgZNcvTWltMqJRWsYoOIPlnQZ3wKlw3dTA/SWabgd9QHU/vNRpCW0OjWqYISUkOD/fIG4QUFE99vpdBhd84X/c+EBbXfSUV+0YrvoNhn9os0a3LQks9BEJN+sTbrydnVYD1eraYjDnBrVFKC1jeOVkmwmFwKDp3/P8mdFoeH/vOh5XMgMYPKZ0p1BLQqINmN1/ZynpcMv8ivkSprTqsi73d3fYy7aibawc/yic9FwFXjBMxjCtlv1d807FdjPxEWeQVTARGSkim0QkxBsIiMgRIpIlIjOcP/d69kX0nlvRjGi7CqWUincxDQxFJBF4CRgCdAXOFpGuYY57HPg2wnPvBCYZYzoAk5zHlaZWmv+D9IC29eBVz4ekdf+UPKFZnxAZDof7obxBh8iDroPCFKQJuG6C/3op6XbNkrehe7C0OpE9d/AUvDNGln58/ytCbw/OGHmD1hJBdBnZpeAPpIW7g64Tgw8voXqv+TKGYYrP7KnEZDjjLZvRBGjcbc+yS+54wxUBOfo+uGVh+LWdpa1by+gcWGG2fnv7O1ajYfQBLJQdbA+8xt66XxLc8A/csTL654mEGyyV1gg+McX+uz/tDTj8Dltp1c38xsLAa0Jnscsr0mmhYNuUHHwD9Lk49P4LvvIXr1HhvAMMLuOYX4wxPZ0/D0Dk77mxoWsMlVIq3sU6Y9gfWGKMWWaMyQc+AkItJrkeGA1sivDcYYBba/5d4JQYjD0ixhimrrBruV4dfgBv/6tt4AGTnwx83LS3/WAdnNVykyju9K32x4QvYHH8I4E93eq0CN24OuD6iZ7A0Dm2tP57udtLv57LBBftKGP6mLe5+VkfhD/Ou6YweK1ccinjhpKBmG+apTN1LxbTnUKt2TroSnvbIsIpg5XtkBvtbbhMckKiLboSTmnBWkISAW0MrptWvmb0xz1kq7KGm6rpOvo+247D/V1IrRHYxqEiNXfW/5WWMfy/TXDZJNuK4si7yx5/VeOrjhrBB//UGnDcg+Eb1bc9HHoMr7ix7YOMMZOBKBcJA5G/51Y4IwlalVQppeJcrAPDZoCnCzprnG0+ItIMOBV4lUClndvIGLMewLkN09Ar9kb+toIpy+z79+C/r6LacyHW7yWl2RLvN82xPd+g5FodV9Nedp1ZvTbhP8gOvNYfdLhCfSj3FsBo1tufCXIDwj2pIumuzQuu5tj+6NLP81Yl7BiixL3L+wE0b0fgvlDjvv5vG2yE0rAznP+5vyVELHpthQoM2xxm/y5D9WKsStwvCjoca8dbPcIpzCWUEuwEB+vh2nyU5eDr4e41ZR9X3uuXxzkfw8UTSp86uTfHEwul9VNUlWWgiMwUkfEicoCzrcz33JgR0YyhUkrFuVgHhqE+CQV/sngWuMOYiFJPUX0qEZErRGSaiEzLzIxNm4evZqz1P1j1R+iDrvgZLvzKZvZcjQ6w2cHS1hl5m7CXtR4w+IP3GW/bSpauXueXLPSRHEHBj+Am2L6xOcGEN8jqNNSWuT9vTOCxwz/03/cGxMEZlhYH+e97+xcGXy9UprN+Ozv91nXMCNub0NXuKNuMHUqfQltekfwsq6J/L4CbQy5jioF9NKioVgdaDazsUewd2sC8qvgbaGWM6QG8AHzhbI/4fbOi3x8NmjFUSql4F+vAcA3gbcbWHAgu09kX+EhEVgBnAC+LyCllnLtRRJoAOLfeKag+xpjXjTF9jTF9MzLCrIvaA1m7Cpi3fkfonW6xi5YD/WvAvJLTbDn4cA3UIbBH3GUT4dzRtldZKG7A5WZ/6rcPXIsnAg272PvuNNYeZ4d/blfTnnCgZ9pXo262mbUbCHnj+TOdJurBAV+qZ92bKbbHXfZDyee6aKz/vjsNrf8V0CQoKI4kCBt0c8nehOkNbOP54KIpFSFes0G1mpTduiBS9ZxpwmWteY3Xn9X+zNf/UT/4VwXGmB3GmBzn/jggWUQaENl7rnuNin1/dIrPGP0dUUqpuBXrBvd/AR1EpA2wFhgOnOM9wBjjW3QmIu8A3xhjvhCRpFLO/Qq4EHjMuf0yxq8jpK9nraOgyPDOxf3o0qQWPO3Zeea7MOZKOOb+CK9WxoflpFTocEzgtjaHQftj7X03Y5hWG/JzoDDXc8wx/jGt/MMW/IDIsxzDXoRZH9n7V/9mb7etsLfeqaS+oiVBr8UbyJli6Hpy6OfxBpStDoHT3yrZagL2rNph/8vLf25ZOg2FJj1jd/2qrno9OxU1HP28GL+iWWOoYk5EGgMbjTFGRPpjv+TdAmynjPfc2A0qAcFQbCBRv/tRSqm4FNPA0BhTKCLXYauNJgIjjTFzReQqZ3/wusIyz3V2PwZ8IiKXAquAf8XydYSzPms3iQnCYR0ySMgPyhzWbAI3z47gKmV8Wj7mfqjdPPS+C7/230+tCdnroctJ8Oer/vL93mOq1bUNsyNRrS7s3mbvh1q/6GYoI/mgWLOxDfRW/hZ5xkEEup8Rfl9VdPaoyh5BnKiif38qPF1juFeJyCjgCKCBiKwB7gOSwfe+eQZwtYgUAruB4cam6kp734z1qEnAUGwMifpvXCml4lKsM4buNJdxQdtCBoTGmIvKOtfZvgUoo8pJ7E2av4k61ZJJSBDYEBQEllUlNFKDborsuHM+gTmfwaG32uqStZqW7/kkwa5NbHWwv31BqEDMLVDS9xL44cHQ12p5sG1fUauJXVO58reSVUzrtArMOl42qeTPUu0jNKiIX27GUP8O9wZjTKnz/I0xLwIvhtkX8n0z5nxTSff6MyullKogMQ8M91WbsnNZsCHbvyEnaJljLHuUhVKvDRx2m71f3qAQoOsw2zC8LCnpcO82GzR2PgF2rC15jCTYoNC9DyUzjDfODHzcvK/9o/YNB98AC74J3FZVM74qPF1jqMokCFCsvyNKKRW3NDAsp3Xb7Rq+03o5lcDX/BV4QHCfwnAyuthqnMc9XIGj20vc4jgNu/gL2wAhM0MDr7VVW7ufGbg9miBhyBOweVHUw1SV6LgH7R/Al3WKplm6qhqOGQE7M0tfl3zDDCjM21sjUlWOZgyVUireaWBYTpt22MDwokNa26mQU162O9ocBssnRx7wJKfBpd/FZpDRaDnQBm4dSuktGC3vz6BOS7hy8p5dL7h3o4ovbY+AfpfDof+u7JGoaDXuBleGaV3jcqvSqv2TCGAwOmVcKaXilgaG5bQp234z3rBmGuza6t9x7mgoLqikUZVDn4vh7/fgkgmQuwPSapV9TlkynOxh30v2/Fpq35GYBCc8VdmjUErFgrjFZyp7IEoppcpLA8Ny2pSdhwg0qJECmz3NgZNSgJRKG1fUTnrW/oHSg8LWh/rbXpSlRkbpbQuUUkrtY8RpV6GRoVJKxSsNDMspMzuX+ukpJJlCeHtIZQ8n9i76puxjlFJK7Z/EFp/RuFAppeKXVoEoh+zcAibO30RGzTQYfxvkbrc7jrqnUsellFJKVQpfuwqNDJVSKl5pYFgOd4yeRWZ2HilJCbD8F7sxMRUOu7VyB6aUUkpVCncqaWWPQymlVHlpYFgOM1ZtB6B/8+qwdandmJRaeQNSSimlKpPThkYzhkopFb90jWE0stbC1mXUrp7Cpuw87qg5obJHpJRSSlU+ERIo1oyhUkrFMQ0Mo/HSQZCfzYqij7nw4NYk7f6hskeklFJKVQFu8RmNDJVSKl5pYBiN/GwAigt2c2jRVPjnDf8+fTNUSim1v3KLz1T2OJRSSpWbBobl8F7KYxz0z4Kgrfp2qJRSav8k2sdQKaXinhafKYeDEoKDQqWUUmr/ZSQBAV1jqJRScUwDwz115nuQVA2Of6SyR6KUUkpVDhFEDMUaGSqlVNzSqaR7qusw+0cppZTaT4muMVRKqbinGcM98a93KnsESimlVBWgawyVUireRRwYishoETlBRDSYdB1wamWPQCmllKp8IrrGUCml4lw0Qd4rwDnAYhF5TEQ6x2hMccEglT0EpZRSqkrwTSXVjKFSSsWtiANDY8xEY8y5QG9gBfC9iPwuIheLSHKsBlgVTacLcsvCyh6GUkopVSUYEpyppJU9EqWUUuUV1bRQEakPXARcBvwDPIcNFL+v8JFVYesSm0HNRpU9DKWUUqpKEBESNGOolFJxLeKqpCIyBugM/A84yRiz3tn1sYhMi8XgqqrExMTKHoJSSilVdYiAViVVSqm4Fk27iheNMT+E2mGM6VtB44kLiYna5UMppZRyCW7xGQ0NlVIqXkUzlbSLiNRxH4hIXRG5pqyTRGSwiCwUkSUicmeI/cNEZJaIzBCRaSIyyNneydnm/tkhIjc5+0aIyFrPvqFRvI49lp9ca28+nVJKKVW1OcVniosreyBKKaXKK5rA8HJjzHb3gTFmG3B5aSeISCLwEjAE6AqcLSJdgw6bBPQwxvQELgHedK6/0BjT09neB9gFfO457xl3vzFmXBSvo3ycb0HzSeKHhhfG/OmUUkqpuCEJToN7zRgqpVS8iiYwTBARX48GJ+hLKeOc/sASY8wyY0w+8BEwzHuAMSbH+Ferp0PId5WjgaXGmJVRjLdiOUN8O+F00qqnV9owlFJKqSrHV3ymsgeilFKqvKIJDL8FPhGRo0XkKGAUMKGMc5oBqz2P1zjbAojIqSKyABiLzRoGG+48n9d1zhTUkSJSN9IXUW6mCIDcQkN6iq4xVEoppfycqaQaGSqlVNyKJjC8A/gBuBq4FjsF9PYyzgnVBb7Eu4Yx5nNjTGfgFODBgAuIpAAnA596Nr8CtAN6AuuB/4Z8cpErnHWL0zIzM8sYahmKbWCYVyTUSNPAUCmlVGw4X3huEpE5ZRzXT0SKROQMz7YVIjLbXbcf+9E6z5tgi89oXKiUUvEr4gjHGFOMDcheieL6a4AWnsfNgXWlPMdkEWknIg2MMZudzUOAv40xGz3H+e6LyBvAN2Gu9zrwOkDfvn337O3K2BX1RSRQI1UDQ6WUUjHzDvAi8F64A5zlHI9jZ/MEO9LzHrqX2HYVmjFUSqn4FXHGUEQ6iMhnIjJPRJa5f8o47S+gg4i0cTJ/w4Gvgq7b3l27KCK9sesWt3gOOZugaaQi0sTz8FSg1G9VK4QzlbQY0cBQKaVUzBhjJgNbyzjsemA0sCn2I4qAuO0qKnsgSimlyiuaqaRvY7OFhcCR2G8y/1faCcaYQuA67Dea84FPjDFzReQqEbnKOex0YI6IzMBWMD3LLUYjItWBY4ExQZd+wpkqM8sZy81RvI7yKXYDwwSdSqqUUioiInKjiNQS6y0R+VtEjtvDazbDfin6aojdBvhORKaLyBWlXKPilloA4lQlDV0/TimlVDyIJsKpZoyZJCLiVAcdISK/APeVdpLTSmJc0LZXPfcfx06HCXXuLqB+iO3nRzHuiqFTSZVSSkXvEmPMcyJyPJABXIz9ovW7Pbjms8AdxpgiT7Fw1yHGmHUi0hD4XkQWOBnIABW61AJ8VUk1Y6iUUvErmggnV0QSgMUich2wFmgYm2FVQU5gWIxQL72sLh1KKaUU4C/CNhR42xgzU0JEc1HqC3zkXKYBMFRECo0xXxhj1gEYYzaJyOfYtlElAsOKJm5VUo0MlVIqbkUzlfQmoDpwA7bh/HnA/tPp3TOVtG51DQyVUkpFZLqIfIcNDL8VkZpA8Z5c0BjTxhjT2hjTGvgMuMYY84WIpDvXR0TSgePYG2vw7RM6De6VUkrFq4gyhk71szONMbcBOdipMPsXz1RSzRgqpZSK0KXY1krLjDG7RKQeZbyHisgo4AiggYiswS7ZSIbApRghNAI+dzKJScCHxpiy+g1XCPEVn9HQUCml4lVEgaGzjqGPs75w//xf36lKmiCJVE9JrOTBKKWUihMDgRnGmJ0ich7QG3iutBOMMWdHenFjzEWe+8uAHuUc556RBMBoH0OllIpj0Uwl/Qf4UkTOF5HT3D+xGliV40wlTUpOYs+XhyillNpPvALsEpEewO3ASkrpTxi3JIEEDQyVUiquRVN8ph62v+BRnm2Gkq0k9k1OxlASNFuolFIqYoXGGCMiw4DnjDFvicg+tz5fBFt8RiNDpZSKWxEHhsaY/W9doZfzZpeYGE2SVSml1H4uW0TuAs4HDnXW7CdX8phiIEEDQ6WUinMRB4Yi8jYhOtcaYy6p0BFVVcVuxlB7GCqllIrYWcA52H6GG0SkJfBkJY+pwrnFZzQsVEqp+BVNlPON534acCqwrmKHU4W5xWcSNTBUSikVGScY/ADoJyInAlONMfvgGkMhQQz7a306pZTaF0QzlXS097FTTntihY+oqnLaVSQm6FRSpZRSkRGRM7EZwp+wze5fEJHbjDGfVerAKpiIfW8sLtLAUCml4tWepL86AC0raiBVXrGbMdTiM0oppSL2H6CfMWYTgIhkYL9U3acCQ5xq3driXiml4lc0awyzCVw+sAG4o8JHVFXpVFKllFLRS3CDQscWomsVFRfcNk7FzuwapZRS8SeaqaQ1YzmQKs95s0vQ4jNKKaUiN0FEvgVGOY/PAsZV4nhiw+3vW6yBoVJKxauIv7UUkVNFpLbncR0ROSUmo6qKnDc7bVehlFIqUsaY24DXgQOBHsDrxph9braNmzHU4jNKKRW/okl/3WeM+dx9YIzZLiL3AV9U+KiqImcqaWLSPth+SimlVMw4xdtGl3lgHLPtGdE+hkopFceiCQxDpcr2n3mVvqqk+89LVkopVT4h1uX7dgHGGFNrLw8pttyMoU4lVUqpuBVNlDNNRJ4GXsK+2V0PTI/JqKqiYjdjqFNJlVJKlS7SdfkiUtcYsy3W44k5rUqqlFJxL5oo53ogH/gY+ATYDVwbi0FVSU7GULSPoVJKqYozqbIHUBFEi88opVTci6Yq6U7gzhiOpWpzA0PRwFAppVSFkcoeQEXQdhVKKRX/oqlK+r2I1PE8ruuU4N5P2OkxGhgqpZSqQPvE3EutSqqUUvEvmiingTFmu/vAWRPRsMJHVFU5b3ZGA0OllFIqgFuVVONCpZSKX9FEOcUi0tJ9ICKt2Ee+6YyI826XIPvErB+llFJVwz7xpuJ+GDBOoTallFLxJ5qqpP8BfhWRn53HhwFXVPyQqipnKqkWn1FKKVUGEalX2n5jzFbn7tF7YTgx53tv1JShUkrFrWiKz0wQkd7AAOw3nDcbYzaXdZ6IDAaeAxKBN40xjwXtHwY8CBQDhcBNxphfnX0rgGygCCg0xvR1ttfDVkdtDawAzox5uW/3zU4zhkoppco2HfuNYqg3DQO0hYAAMa5p8RmllIp/0XZrLwI2AWlAVxHBGDM53MFiFx28BBwLrAH+EpGvjDHzPIdNAr4yxhgRORDbCqOzZ/+RIQLQO4FJxpjHRORO5/EdUb6W6GhVUqWUUhEyxrSp7DHsTYLb4L6SB6KUUqrcoqlKehkwGfgWuN+5HVHGaf2BJcaYZcaYfOAjYJj3AGNMjvGXMUsnsnWLw4B3nfvvAqdEcM4ecquSasZQKaVUZMQ6T0TucR63FJH+lT2uiuZOJTVoZKiUUvEqmvTXjUA/YKUx5kigF5BZxjnNgNWex2ucbQFE5FQRWQCMBS7x7DLAdyIyXUS86xkbGWPWAzi3sa+OqhlDpZRS0XsZGAic4zzOxs6k2bc4741GU4ZKKRW3oolyco0xuQAikmqMWQB0KuOccGsrAjcY87kxpjM28/egZ9chxpjewBDgWhE5LIrxIiJXiMg0EZmWmVlWDFsG3xpDDQyVUkpF7CBjzLVALvhaPaVU7pAqnm8yTbEGhkopFa+iiXLWOA3uvwC+F5EvgXVlnQO08DxuXto5znrFdiLSwHm8zrndBHyOnZoKsFFEmgA4t5vCXO91Y0xfY0zfjIyMMoZaumJfxlCnkiqllIpYgbPe3gCISAbse/MtxZcxrOSBKKWUKreIA0NjzKnGmO3GmBHAPcBbeNb2iUjdEKf9BXQQkTYikgIMB77yHiAi7cWJtpyqpynAFhFJF5GazvZ04DhgjnPaV8CFzv0LgS8jfR3lZZxvQbVdhVJKqSg8j/1is6GIPAz8CjxSuUOqeO6XpjqVVCml4le0VUkBMMb8HGLzJKB30HGFInIdtlBNIjDSGDNXRK5y9r8KnA5cICIFwG7gLKdCaSPgc+fNJgn40Bgzwbn0Y8AnInIpsAr4V3leRzSKjSERbXCvlFIqcsaYD0RkOrZfoQCnGGPml3aOiIwETgQ2GWO6lXJcP2AK9n3zM2dbqS2iYsWtSlqsKUOllIpb5QoMwwgZMRljxgHjgra96rn/OPB4iPOWAT3CXHMLe7kpsO9bUM0YKqWUKkNQg/tNwCjvvjL6F74DvAi8V8r1E7Hvnd8GbSurRVRsJLoN7jVjqJRS8aoiA8N9+2tCZyppghafUUopVTZvg/uWwDbnfh3sTJewfQ6NMZNFpHUZ178eGI2tFu7ytYgCEBG3RVTMA0Nfxe7iffujgFJK7cs0yomQb3qMTiVVSilVBmNMG2NMW2xG7yRjTANjTH3sFNExe3JtEWkGnAq8GrQrohZRseCfSqoZQ6WUilcVGRju0xGTKS4CNGOolFIqKv2cJRUAGGPGA4fv4TWfBe4wxhQFbY+oRRRUcDsnvBW7NWOolFLxqsyppEHrJErwrJPYq2v+9jajfQyVUkpFb7OI/B/wPjZqOg/YsofX7At85ARjDYChIlJIFC2ijDGvA68D9O3bd4+jOTcw1OIzSikVvyJZY+hdJxHMAG0hIEDcJ7mBoSTs04lRpZRSFets4D5sywqAyc62cjPG+NYnisg7wDfGmC9EJAmnRRSwFtsi6pw9ea6IuYXZNDBUSqm4VWZg6H0D2p8V61RSpZRSUXK+NL1RRGoBxcaYnLLOEZFRwBFAAxFZgw0sk53rBa8r9D5XyBZRe/4qyuZrcF8UPLtVKaVUvIi4KqnThP5coI0x5kERaQk0NsZMjdnoqhB/xlADQ6WUUpERke7YthP1nMebgQuNMXPCnWOMiTijaIy5KOhxiRZRe0OiM5umsFiLzyilVLyKJsp5GRiIf1pKNrZf0v7BDQy1KqlSSqnIvQb82xjTyhjTCrgFZ23fvkQS7PfMhYWFlTwSpZRS5RVNH8ODjDG9ReQfAGPMNhFJidG4qhzjfAuqGUOllFJRSDfG/Og+MMb8JCLplTmgmEhIBDQwVEqpeBZNYFggIok4tahFJAPYb+aM+KaS6hpDpZRSkVsmIvcA/3Menwcsr8TxxIbYwLCosKCSB6KUUqq8oolynsdWVWsoIg8DvwKPxGRUVZDbLkqnkiqllIrCJUAGMBrb2L4BcFFlDigmEtzAUDOGSikVryLOGBpjPhCR6dh+hQKcYoyZH7ORVTGaMVRKKVUO7bC9BROw77lHA0cBB1bmoCqcu8awSDOGSikVr6JtcL8JGOXdt6/3L3S5gWGCrjFUSikVuQ+AW4E57MvLL3xTSbVdhVJKxatoG9y3BLY59+sAq4D9os+hr/iMTiVVSikVuUxjzNeVPYiYc6eSFulUUqWUilcRN7gXkVeBr5weSYjIEOCY2A6v6ig2GhgqpZSK2n0i8iYwCchzNxpjxlTekGLACQyLdSqpUkrFrWiqkvYzxlzlPjDGjBeRB2MwpqrJnUqamFjJA1FKKRVHLgY6A8n4p5IabCGafYezxrBYp5IqpVTciiYw3Cwi/we8j31TOw/YEpNRVUH+qaS6xlAppVTEehhjulf2IGLOXWNYrBlDpZSKV9FEOWdjS25/DnwBNHS27Rf8xWd0KqlSSqmITRGRrpU9iJjzTSXVjKFSSsWraNpVbAVuFJFaQLExJid2w6p63D6GaMZQKaVU5AYBF4rIcuwaQwGMMWYfa1dhA0OjawyVUipuRRwYikh34D2gnvN4M3ChMWZOjMZWtdiEIQkaGCqllIrc4MoewF4hbsZQq5IqpVS8imaN4WvAv40xPwKIyBHA68DBFT+sqse4VUm1j6FSSqkIGWNWVvYY9gq3+EyxTiVVSql4FU2Uk+4GhQDGmJ+A9AofURXlBoYJ2q5CKaWUCuSbSqoZQ6WUilfRZAyXicg9wP+cx+cByyt+SFWTW3xG+xgqpZRSQUSLzyilVLyLJmN4CbYq6Whs/6UGwEVlnSQig0VkoYgsEZE7Q+wfJiKzRGSGiEwTkUHO9hYi8qOIzBeRuSJyo+ecESKy1jlnhogMjeJ1lI/briJB+xgqpZRSAdz3xmLNGCqlVLyKJmPYDmiBDSaTgKOBo4CwldVEJBF4CTgWWAP8JSJfGWPmeQ6bBHxljDEiciDwCbYZcCFwizHmbxGpCUwXke895z5jjHkqivHvETdjmKhrDJVSSqlAbmBoiiguNtraSSml4lA0geEHwK3AHKA4wnP6A0uMMcsAROQjYBjgCwyD2l6k49T/NMasB9Y797NFZD7QzHvu3uSuMUTf7JRSSqlATvGZBIrJLyomTWfXKKVU3Ikm/ZVpjPnaGLPcGLPS/VPGOc2A1Z7Ha5xtAUTkVBFZAIzFTlkN3t8a6AX86dl8nTMFdaSI1A315CJyhTM9dVpmZmYZQy2dryppVD8ypZRSaj/grDFMopi8wki/O1ZKKVWVRBPl3Ccib4rI2SJymvunjHNCpddMiQ3GfG6M6QycAjwYcAGRGth1jTcZY3Y4m1/BTm3tic0q/jfUkxtjXjfG9DXG9M3IyChjqGVwppLq9BillFIqiDdjqIGhUkrFpWimkl6MXfuXjH8qqcEWoglnDXZdoqs5sC7cwcaYySLSTkQaGGM2i0gyNij8wBgzxnPcRve+iLwBfBPF6ygfJzB0vxVVSimllCPBzRgWkV+kgaFSSsWjaALDHsaY7lFe/y+gg4i0AdYCw4FzvAeISHtgqVN8pjeQAmwR2xfiLWC+MebpoHOaOGsQAU7FrnuMLV+De80YKqWUUgHETkBK1IyhUkrFrWgCwyki0jWoomipjDGFInId8C2QCIw0xswVkauc/a8CpwMXiEgBsBs4ywkSBwHnA7NFZIZzybuNMeOAJ0SkJzZjuQK4MorXUT5uH8OQs2OVUkqp/ZgzlTSRInILtJehUkrFo2gCw0HAhSKyHMjDrh80xpiw7SqwB4wDxgVte9Vz/3Hg8RDn/UroNYoYY86PYtwVwjhLIzVjqJRSSgVxppImYti+q6CSB6OUUqo8ogkMB8dsFPHAFFNshDCxqlJKKbX/cjKGSRSyZWdeJQ9GKaVUeUQcGEbQmmIfZyhGEI0LlVJKqUCJyZikNGoU7mbrzvzKHo1SSqly0KZ8EZJig9EVhkoppWLM6c+7SURCFlYTkWFOH98ZTq/eQZ59K0Rktrtv740aqFaX2uxkS44GhkopFY80MIyQoRgDiKYMlVJKxdY7lL58YxK2UnhP4BLgzaD9Rxpjehpj+sZmeKFJWh0aJGnGUCml4pUGhpEyBkOCZgyVUkrFlDFmMrC1lP05xrjNdUkHTLhj96pqdaifuEsDQ6WUilMaGEbKGCdjWNkDUUoptb8TkVNFZAEwFps1dBngOxGZLiJX7NVBpdWhruzU4jNKKRWnNDCMmLvGUCNDpZRSlcsY87kxpjNwCvCgZ9chxpjewBDgWhE5LNT5InKFsz5xWmZmZsUMKrUm6ehUUqWUilcaGEbKaFVSpZRSVYsz7bSdiDRwHq9zbjcBnwP9w5z3ujGmrzGmb0ZGRsUMJrUG1TQwVEqpuKWBYaRMMUazhUoppSqZiLQXpxKaiPQGUoAtIpIuIjWd7enAcUDIyqYxkZJOarENDIuLq8ayR6WUUpGLpsH9/k0zhkoppfYCERkFHAE0EJE1wH1AMoAx5lXgdOACESkAdgNnGWOMiDQCPndixiTgQ2PMhL028JSaJBfnIaaI7bsLqJeesteeWiml1J7TwDBixaBrDJVSSsWYMebsMvY/DjweYvsyoEesxlWmlHQAqpNHZnaeBoZKKRVndCpppLQqqVJKKRVeag0A0tnN2FnrKnkwSimloqWBYcQMxSRoYKiUUkqFkmIDw96Nk5i2clslD0YppVS0NDCMlJsx1KmkSimlVEnV6gLQvV4xCzZkV/JglFJKRUsDw0g5VUk1Y6iUUkqFUKMRAK1Tc9i6M5/cgqJKHpBSSqloaGAYMacqaWUPQymllKqKnMCwceIOANZn5VbmaJRSSkVJA8NIGWciqUaGSimlVEnV64Ek0lCyAFi+OaeSB6SUUioaGhhGyuljiOYMlVJKqZISEiE9g0aJWaQkJfDH0i2VPSKllFJR0MAwQjtqd+SX4gM1Y6iUUkqFU6MhSbsyaZ9RgyWbNGOolFLxRAPDCC1rcy63Flyl+UKllFIqnBqNIGcjLetV58eFmezKL6zsESmllIqQBoYRss0qQDRlqJRSSoVWpwVsWUbreqkA/LBgUyUPSCmlVKQ0MIyQsXGhZgyVUkqpcFoPgrwsbuhip5Gu3rq7kgeklFIqUjEPDEVksIgsFJElInJniP3DRGSWiMwQkWkiMqisc0Wknoh8LyKLndu6sX4dvsBQI0OllFIqtDZHAFB99S/UrZ7Mqq27KnU4SimlIhfTwFBEEoGXgCFAV+BsEekadNgkoIcxpidwCfBmBOfeCUwyxnRwzi8RcFY0Jy7UToZKKaVUOOn1ofGBsOxHOjeuxZcz1pJXqI3ulVIqHsQ6Y9gfWGKMWWaMyQc+AoZ5DzDG5Bjj5uNIxx+DlXbuMOBd5/67wCmxewm+cQKaMVRKKaVK1fkEWPkbJzTNZld+EV/8s7ayR6SUUioCsQ4MmwGrPY/XONsCiMipIrIAGIvNGpZ1biNjzHoA57ZhBY+7BFP2IUoppZQ64FQAzm2eSa20JF7+aSkFRcWVPCillFJliXVgGCq/ViLGMsZ8bozpjM38PRjNuaU+ucgVzrrFaZmZmdGcGvaZNWOolFJKlaJeW0hIQjYv4v9O7MrKLbu0OqlSSsWBWAeGa4AWnsfNgXXhDjbGTAbaiUiDMs7dKCJNAJzbkO84xpjXjTF9jTF9MzIyyv8q0HYVSimlVEQSk6G4EH59htOaZdGoViof/7W67POUUkpVqlgHhn8BHUSkjYikAMOBr7wHiEh7caItEekNpABbyjj3K+BC5/6FwJcxfh3arkIppZSKVIfjAEhaMZnTezfnhwWb6Hbft9rwXimlqrCYBobGmELgOuBbYD7wiTFmrohcJSJXOYedDswRkRnYKqRnGSvkuc45jwHHishi4FjncUz5qpJqZKiUUkqV7l9OfbiJI7hq4aUIxeTkFbIsc2fljksppVRYSbF+AmPMOGBc0LZXPfcfBx6P9Fxn+xbg6Iodaen8GUONDJVSSqlSpVSH1NqQl0WtbXOoQw7bqKWtK5RSqgqLeYP7fYV/jWElD0QppZSKB/0v992tKzkAbNtZUFmjUUopVQYNDCOkawyVUkqpKDTv57tbl2wAHhk3v7JGo5RSqgwaGEbI1ydDI0OllFKqbHVa+u6+1X0eAMs278QY7QyslFJVkQaGkXLeyHSNoVJKKRWBhl18d+ss+pS7+tuPHH8u31pZI1JKKVUKDQwjpFVJlVJKqSiIwH82QJ1WAFw5azgXpf/BsxMXVfLAlFJKhaKBYYR0jaFSSikVpeRq0O8y38MRRS+wcNkK7hozi6JinVKqlFJViQaGEXLXRIimDJVSSsWQiIwUkU0iMifM/mEiMktEZojINBEZ5Nk3WEQWisgSEblz7426FAdfH/BwTMp99Pj7Hk579ju+nbuhkgallFIqmAaGEfJNJa3UUSillNoPvAMMLmX/JKCHMaYncAnwJoCIJAIvAUOArsDZItI1piONhAicOxqO/D8A2iRsZHjST5y/7UVmfXgPvy/ZXMkDjFBhPvzyNBTmVfZIlFIqJjQwjJBvKqlGhkoppWLIGDMZCFuhxRiTY/ylPdPxf3fZH1hijFlmjMkHPgKGxXSwkepwDBx+Gwy41rfpjMTJ3Jb8Cee9+YfdkLnI/qmqpr0Fk+6HP16q7JEotW/avBiydRZBZdLAMEL+jKFGhkoppSqXiJwqIguAsdisIUAzYLXnsDXOtqqjMLfEpnpks2DDDnipn/1TVeXZXozk5wRuXzgBRtSGHev3/piUqupG1IYJd0V27It94b+dYjueypC11v4cFk6o7JGUSQPDCBmtPqOUUqqKMMZ8bozpDJwCPOhsDvUOFbLCi4hc4axPnJaZmRmjUYYw6CbofGLAprdTHmfws78EHrc3eh1mb4Rv/wNFhZEd7/scEPTRadpb9nbDLHv793vw1vEVM0alorHoWxuEVDVTXq7sEVSudf/Y27/frdxxREADwyjpVFKllFJVhTPttJ2INMBmCFt4djcH1oU573VjTF9jTN+MjIy9MFJHnZYw/AM4/S0Y9G8AuiesYFjCr75Dtn92A9xfB767p+T5eTn+zF1xUfj1fpsWwP9Og/ydUFxs/wT75mb440VY/nPg9o1zYeL9IYLToGoDuVn+sXh9dT2snhJ6XNHaGwGy2jvWToc/X4vd9Y2BD8+Et46N3XNEK9a/vxvnwYaQNbqqmFIqlezaCgVBMynycmDOmJiPKhQNDCOkCUOllFJVgYi0F6dEtoj0BlKALcBfQAcRaSMiKcBw4KvKG2kpup8BR98LJ/wXIwk8l+LPKNSZ43yr/vvz8NNj8M8HsMIJHJ/qAI+2sIHe013goYb+axbmQVGBvT/uVlg6CVb9AZ9fCU+0hvxdsG2F/3h3Suji72yWpagAdm+Dt4fAr0/b+/+8758iGvwh97GW8GSH8K/RHUuJ7YVQsLvUHw9gP/TeXwcWf28fr54a2XnxYO10m62NNHBY/Zf9+yuv9bMqf/3qG0fB+NvD75/9GXx9Y/mv735JssPJGJaVCV8yKXCK566tob9AMQZmflT6715xEUx+CnZvD9we/G9g+yrI2VTy/Dmj4asbSh9vKK8MhFcPif68vBz45MLIp38X5sPOzfb/g/IEu6UVKnmiDXxwRuC2r2+Ezy62X1IB5O6A0ZfDzi3RP3eUNDCMkEHbVSillIo9ERkF/AF0EpE1InKpiFwlIlc5h5wOzBGRGdgqpGcZqxC4DvgWmA98YoyZWwkvITIi0O8yZMA14Y/56VH48hp45wRYMhEKdgHGTk3L2WiP+ep6u37noYbwRDv7AXWFMzV1+rsw+xOb3XukCTzXAzIXwrSR9sMswJ+v2g+X398Lj7e2xwJsXQZfXgtPd7bZxyUT/eNyPyQXej4sm2JYPjnwmKJC+Pxq/wc8sB/4Hm5c9s9n1e/2dsFY2LHOZoLcD8/FxbD0h4rNyGRvhEXfVdz1SvPW8TZbG0mF16y18NYxMPbf4Y8pKoDv74PNS0Lvf+1Q//rVMVfC60eW/pxblgYGQrM+hVV/ln7Oj49GluUp2A2jL4NxTpCYm2V/Z0dfCtPfsR/+H2sJK34LfP5fni7jup7Aef7X8GB9G/x5FRf5A8b3T/NP8dyxzgYovz0bePzOzfDzE/bLlZ8eDf/cy36CHx6ECUEdcoLXFD/b3X65E+yzSwKnWYYKgIoKbIAUypzR9mcIsPbvsqfTzvvC/pn0QOD2lb/b/0u2rbD/tuZ9ZX9eT3eBJ9vZ/w/cKePBcjLtNHL332RuFmStcXaG+XfqBuLu/1czP4aF4yFzgX28eZH9QuGXp+z/Y8F/PzGggWGENGOolFJqbzDGnG2MaWKMSTbGNDfGvGWMedUY86qz/3FjzAHGmJ7GmIHGmF89544zxnQ0xrQzxjxcea8iCgffAMnVoctJbEloEP6490/333fX7ID9MObKy7IfUF3zQyRMX+pvp5Gumerftnsb/PVm4HGTn/TfXzoJ1k5ztj8RGNgtdoKpLUvh3ZP82wt2w6a5MPND+8E6eEzLf7GBTHGx/cCbl20/EI+9xU4tcz/AJyb7p6yu+9t+eP39efjfqTbLVJqHm9jMnKu4KHRWCODDf9k/e5KZcxXk2iyLa+mPgX9P7gflggiey82AzRxlM42hzPzIfmieGsFUzVkf2Z9jOAW74YXe8PlVNmACGHMZjDzO3v/7fzaLHeznx2zQHywvx/8lBNiAYfan/rFOHBH4O7txtj3GDbJ2rLfPP+l+G/ysdL4w+P0FG8Tk73KyyZ6f5cfn2dv3T7N/3z89ZoOUt4fCQxmBmb2iQn8gsvSHwLGPHAw/PWLvh8r0udwgeuty+4HZ/R3avir8OaV5sm3JLw3G/hseaxH6y4TPLvH/DN84Ep7pCh+da7/c8SrMt9PLMxfaxzM/DPxyxf17XfqD/ZLnk/NtgL3L01Inf6cN2rM3Bl776xvtl1RfXgdPtrfB/TMH2Ocs9mRvd221v68jasMDdQOv8fkVMGq4/+/yl6ft77z773zTvMjXRJdTUkyvvg/xzQ7WyFAppZSqODUbwR0rISGR3yaMp+2U/9AtYUXp58wpIyCKRFF+6Y8XRVlB8Lv/BD4u3O3PcCSm2uBgw2z//nedIjwND7ABJEDfS2w2s2lv/3hW/m4zQABbltiprq4xl0FGJ2jYxWbMupwEdVpA7eb2A2/BLpuZO975juCzS+wHzRtmwM5NtpDOuNvg5Ofth3qA7PVQt439kNr3Emh1cMnXuu4fSEiCxt1D/ywebgR1W8ONM+3j/51ib3tfYG/dD8r5O6F6vdDXcO30fCh/4yjbE9MU2fWqq6ZA34thl5thKuNDWrgM6/R37N9Pv0v9QbibVbp0YuCxX11nb3udG/pa/3zg32cMPNoMep3v3+9mpAHeOLpk8OQ+//aVNrAZf4d/nxv8jMiymTyAMZfDgm/gvNGhxzP23zD9bVj5m3/t6+Ot/Ps/uQAOOMXeLy6046nT0j7esth/XFKavS0qgDV/Bf5eZDtTMgt322A0OMAsj7wcSEr1P57zub19qKF9/aHs8nT5WfCNvR3uCeLfP82fnXMt/QFaD7J/VzPet9u+udnXd7WEnZttwFi3tf13NPtTmyleNN7ud6/hesizhnvBN/5xBRtR23/f/R0wzpc4buC9ZCLMHQMHnhn6GhVAA8MI+TOGGhkqpZRSFSopBYCThpzA/J6HcfWLT7GbVN5JeSL6a105GRp1sx+qv74Jhj4BDbva9Xp7U/4uf9YnuRq8c6J/eqjXJs80U3dNVmEuFDv3N5ZRXOOPF22l1ykv2T9gPzjnhZh2N+8Le5u1Cp7v5d/etBek1LDnZK2BtDr2A+/sT0N/CH/9CHt77zZICDP5zJ2O5/2wbox/zSQEZrlW/wULx0GtprD6Tzj5RUhOg+yg+kkfnB74uEkP/1TdojxbeOj90+HySVCzcWAw6C0W9OuzMPA6WPmrf21fj7Nh7ueB139naOD4vb68FuZ/A3es8Gy7BjoPhWp1/c/3z//8+72ZNzcL7eWue8vNCvw78irM9//9uoHGom9DHzv9bXsbLtO0cKz9A3ZN7rPdbcDf/8rA49xx//Qo/PJfu0b40Fvs7/n6GXbf+pmhnwPCT7P1/n54LRpvM/ktDoIW/aHRAf7AtjAvMGj0nRP0ZU5xkS1Ok9HJ/l4HB4UA25bbLF/w79mcMIH2Fme68rYV9mc+5vLQx+2JnU6laPf3Z7fnZ9Tu6Ip/Pg8NDCPkX2NYyQNRSiml9lEiQpcmNSnodDJ/zPe3ZPy6aAAnJdoPhYtaDafjyo/sjub9bACxZKLNbuVut4EFQIMOcPHY0E/U4xw7jQxs5uu6vyA9w07xGner3db+mPBZw0sn2nVvpXlloP9+qA+kobjZsewNdspqJGZ9bP94jajtq/oK2Gmu9dr6H3uL8ID9AO1+MH7vZBsYhuOdIvpCb7j2T7tWragQOgRVxJz9aeAH56w1drqqa8Ns+6EdbJC1eaF/X/0OcMQdZRcIecOzXnD6uzb7B3bKcF6OzS66Rl/qvz/xPvu74h1f7vaSBWK8meSF4/z3H27iD2znfRl4zrMH2qyb9+eRmGKv9eerpb+e8beVvh9gZIh2KFNfL/0cX1Y1Ahtm+zOjroVjbfGVX/5rH096wP77+/WZyDKE3mm2n1/t//cXzpfX+u/XbR34O7t1uf27CvbF1YGPF423fw48q+S/EdeurSWDQrABYyjeaci7t4U+pqJsX1lyW3r9mD6lmP2kFHLfvn3NtGkhvpmJ0Es/LuHJbxey4MHBpCUnVuDIlFJKVSQRmW6M6VvZ44gXe/r+GCvPTVzMhb8czpiiQ3mw8DzqkMOAtvWZsCyPCRe1oVPeXOh4PFSrE9kFC/Psn6zVULuFXa9UpyUM/zD8lMicTJul+Pg8aNDJBi7N+tpslDcwcPW/MrJ1bpXh8DvtOjiAE54OLObSYkD4FhudTwycjpe5yF/IJViLg2y2zzXoZhs4uIY8WTLwOWMkIDa7mxdmimCspNYOfM6r/wgM6GMhMdVmNlX00uqEDgj3RJeTQ69FrqrCTaONQmnvkVp8JkqaMVRKKaVi74KBrbivy1ganvkMh3VsxDZqMX5ZAYYEbp+4HXqcFXlQCHbqWVotOyUtrZb9gHXT7PBBIUCNDLtu77rpcMVPcNcauNjJGl3yLXQ/0/ZkPPkFuHOVnbZ60bjAa7QYYIvrxFq3M0rf7waFAH+8FLivtL6LC76xGUVj7Jq+4GxjwHWCKndOezvw8ff3ljzns0tsNmlvB4VQ8jnHXBH759wbQWFCDCYEnvhM2ccEa9i1Ysdw7ANlH1OWlp7Av26byILCSKdvnvNpyW1H/qfktipMA8MIuZlVXWOolFJKxV7d9BSeG96LEw9syjsXB2aoZq7J4s1flrHXZj01aA8p1SG1pn9tU5MD4fQ3bE/G3hdAmlM8omEXGwzWdKa0XvAF/Gc9/GeDf4pm2yPgvDFwzAg47Y3Qz9nBM12wSc+S+90CIWCnxp7xFrR3pi7WbmnXgIWzdWno7dXCFIJ5oJ4tmT/y+MCpoGUJzu5423vsTQ06RXbcxtllHwNQs0n5xtHmsPKdV60eHHw9DLi25L7bltrfJ697PAV7hj7lvx9JwDjoZv9975Tinuf5758ftA4znI6DAx8f9xD0Oi/0sa7+QcF5+2Pg4vFw33bocyE0PjD0eV1OhsOCs9FBX0z0ONuO/abZcPbH0LRnWa/A/js66dmyjwO7rrTjkMBtkgAXfg3DXoJLgtrBRBI09r3UzkQ49XW4vAKK+pRBA8MIldabUimllFKxIyJ8ePlBnNyjqW/bQ2Pnc+2Hf9P6zrG889tycvIK+WdVjNf8RKJ6Pbj0W7h5Dty+3BaeAXt76C32/gGnQvuj7YfwA8+Eu0Oscep4PFz+I9zwD5z9EQx+DFoNsvuOvtfucw26yd662ahhL/ifK1KNu8Oti+CCMBmUHx6K7npe9dv77x84vOT+2i2hXjsbBED4ipCl6XwipNYKve+cjwIfXzsVug6z93t6qosmpdm1qmW5ZQEMc3oANoti1vqZ78FBV0OH4/zbbl9ug7eUmnBRiDWxQ56AO5bboMrNkGd09u9Pb2D3Ne9vr9Pn4sAPq/0v9/8u1A/RQ/DU1+Fiz1raI//PZr4u+Q6um2bHdO1ftkDU/22yx7YOE+B2GgpdT7FZ9FuX2MDniLvt+sqj7rHBrfdLjjtXl7xGdc8aukbdbbXVVgf7X9PJLwQef9ht9phhL9rAz6vbaXDzPHu/QSc49VX777BOS+g02P7OlOWQm+3xZ74HxznVfb0ZxENvgRpO+5pqdewXSODPlkqC/UKg13nQ8iD7BdEZb8P1f8Pht9ufT63mcPXv9t/1hV/7A9qEJDjxaTsTocdZ0KxP2ePdQ7rGMELPT1rM098vYsnDQ0hK1HhaKaWqKl1jGJ2qusYwnIUbsnnwm3ksy8xhXVZuif3T/u8YGtQIUbGwKigqsAU8el8ACUH1CrLW2L5nYD8ctj605LfRO7fYKpOD/m2rgbol7t11R5uX2P6LJ79gP8h7S+BD+DV0p74GPYb7x/jRuXYt5qZ5oV9HtzNsy5DbltrppZsX2mBh42wb4Iy5zB7XapD9MHz0vbYJ+qYFMOCqwHG1ORwu+NK+1vUz4bXDbCAy62Obpbxni213seIX2/Yhc4H9QJ+QZIu7fHqRzWxdMt5OS/VWk2x1iG3TcO9W+/MuKoBtK20GOH+nLU5To6Hta5eYDPXbOT9Pz/gkwbYNuPwHe3xydWjRzxbFmXS/rWz606M2a9dxMDzbzZ539scw6qzAn5t3fVjw353rnRMDixXdNNufHd693Va6HfwoPN469Pmhrm+MbXVx4HB4dZD/C4TEFLgns/TxhLP6LxsIrfnLX/Ql3LnG+H+Xi4tsj8CWA2yQ9vqRgQVdTnvDZt8/PNNm1L0ZTO/1po20gV+1uiX3j6ht13Le41RSLS62zx/872nbSnjOyUDWb2+Dv52b7c/f7WMa/Jp2b4PFE+3v+Jn/g64nwxNtbXGfWxZCQjL88YLNYL5xpP0SIiPCjLWrYLftldrtdGcNbsUq7T0y5oGhiAwGngMSgTeNMY8F7T8XcJu05ABXG2NmikgnwFtCqC1wrzHmWREZAVwOOL/N3G2MCZrUH2hP3/iem7iYZyYuYukjQ0lM0LShUkpVVRoYRifeAkPXwg3ZHP/s5JD7HjylGyd0b0K99BQWb8xmaeZOBndrHPLYKmXRd7BjTWRZK4AJd9k1k+Gm5712WGALgRFZtrVDzkb7wT5zgV1D6AYHXksm2rYPbQ6zH+S9LvnWfrAPJyfTBmRuf7xg87+xAdmmeTZzF+rDvTE2IAsOoEsz5gobUJ70nA2sazS0AVxGx8ivAfB8bzvd9rrp9hppYTKRoSz6zgblbY/wB1vnfGpbOhzuqXjqtmkI7uOYvxMe8WfGuX156F6Pi761U0xbhCkE9OuztjJv5xMCt2dvsAFm1mpb7bNBB/92Y6BWOabJjqhtpzGfV47+ooV5tlrr461tH8UzRtqAKC/btlApz1S9DbPtlwV1WpR97OLv4YMzbOGkSz1TPfN32TYRtZuXPMcY++/KnYo6/xtb5faaPyGxgtZ3bl0GtZqFbsuxhyotMBSRRGARcCywBvgLONsYM89zzMHAfGPMNhEZAowwxhwU4jprgYOMMSudwDDHGPMUEdrTN75nJy7i2YmLWfbIUBI0MFRKqSpLA8PoxGtgCPC/KSu554vwff6O69qI7+ZtBODKw9py19Aue2toVUNuFnxyISz70fZ3bNIjuvO3r7LT3NxehW6gc900f0BRlWRvtG0+jn9kzz5QF+bZzFbKHhYNijYL5/rtefj+nvAZs6rGmxHcE6un2qm54XpjxsLW5fB8T9vS4rQyWn7sI0p7j4x1H8P+wBJjzDJnIB8BwwBfYGiM8XZ7nQKECM05GlhqjAnR0GPv0DWGSimlVNVy/oBWnD+gFcs376RF3Wpk7S7gvT9W8tykxQC+oBDgtcnLSgSGBUXFJO/Ly0PSattiG8aU78O2t8CNl3cdWFVSsxGc8N89v05FZWnO/shm4qJ1yA32T7yoqA/HLfpXzHWiUa+NncoczVrRfVisA8NmgHdl6RrgoDDHAlwKjA+xfTgwKmjbdSJyATANuMUYE9MV525eVTQyVEoppaqUNg3SAahfI5Wbj+3I2u27+Wz6mhLHfT9vI1/8s5YZq7dzWMcGfDZ9DZP+fQQt6++FdhKVJdTaqvI6+Hr4/QV/BVZVuk5Dyj5GVb7gqq77sVgHhqH+Jwo5d1VEjsQGhoOCtqcAJwN3eTa/AjzoXOtB4L9AiQn5InIFcAVAy5ZhvvWK1H5SpEcppZSKd3cO6UyzOtUY3r8Fj41fwPB+Lbn4nalc/p5/yuyoqfZ768OetNU9R10+gBVbdtKrZR3aZ9TQQnOhHPsgHD0iunV/Sqm4Eev/9dYA3pWfzYESNZlF5EDgTWCYMWZL0O4hwN/GGN98EGPMRmNMkTGmGHgDO2W1BGPM68aYvsaYvhkZGXv0Qgw6jVQppZSKBw2czGGT2tV4bngvBrarzyvnlSz1fsNR/jYKZ78xhbvGzGbws7/Q/j/jefLbBQHHZmbn8cKkxezMK4z5+KsskYorrqGUqnJi/a/7L6CDiLTBFo8ZDpzjPUBEWgJjgPONMYtCXONsgqaRikgTY8x65+GpQPiV5xXEmNDpT6WUUkpVfUd2asjyR4fyzaz19Gtdj0a1UhER3puyku27Ckoc/9KPS5k0fxO9W9Xlwz9X+bY3rJXKWf38s5CWb95JbkERXZpEUblSKaWqoJgGhsaYQhG5DvgW265ipDFmrohc5ex/FbgXqA+87KzfK3Qr5YhIdWxF0yuDLv2EiPTEJvJWhNhf8a8Fo+sLlVJKqTgmIpzUo2nAtu9uOoxtuwowGMbNWs/zPyyhZb3q1KqWxJy1O1iwITvg+HGzN7B2224uGdSGOtVTOPKpnwC0nZVSKu7FfD6A019wXNC2Vz33LwMuC3PuLmzQGLz9/AoeZpk0Y6iUUkrtexrWSqNhrTQAtubk8/wPSzitdzNuOqYjH/65irs/nx1w/M+LMvl5USbP/7CEIZ7eiO3uHsfPtx3Bqz8vo1fLOpzZtwVfzVxHgxopPPntQm46piOHd9yzZS1KKRVLOlE8QrrGUCmllNq3Hdy+Ae9e0p+D29nvpM85qCWt6lena5NafDxtNT8vzOSPZf5SCOPnBLYiuGHUP8xck8Woqav4c9lWRv/tr4x666cz+eX2I3n7txVceHArfliwiXGz13PD0R1ITUr0VVZVSqnKooFhhGzGUCNDpZRSal8WnNU7pH0DAK46vB2XDWpDTl4hvR/8nuTEBAa1b0Dtasn0bFmHe7+cy8w1/kbm3qAQbPGaEV/N5aO/VvP4BH9hm3GzbXC54rETYvWSlFIqIhoYRsigc0mVUkqp/VlSYgJ1qqcwe8TxJCYIacn+tg0Ht2vAMU//DMDNx3TkmYmLqFs9mW2ewjYf/bW6xDVdRcWGYmP4dclmflu8mdN6N6dr01psys4lo0aq1jlQSsWcBoaR0rhQKaWUUkB6asmPT+0b1mD5o0MxBrbuyufDqSt56Zze9G1djzcmL+PhcfNLvWa7uwPKMfDmr8s5vGMGPy/K5OZjOtKpcU2uen86tw/uRPdmtamWnMjGHXn0aVWXxrXT+HrmOpITExjsWfeolFLR0MAwQrrGUCmllFKlERFEbB/FP+8+xrf98sPacvlhbfnin7VMWbaFvMJiZqzeziWHtGbKsq2Mnb0+4DpNaqexPiuXnxdlAvDMRH83rycmLCzxvC+e04vrR/0DwJWHt6VPy7rUSE3ix4WbmLF6O59edTD5hcVs3JFLi3rVQ4598LOTObB5be45sSs1UpM0Q6nUfkgDwwgZY3SNoVJKKaXK7ZRezTilV7OAbWf1a8m/j+tIu4wajJu9npVbdnH1Ee2YMGc9n0xbw91DO3PM05NLve51H/7ju//az8tK7G9951jf/fE3HkqHhjVYtnknxkCr+tXJ2l3Agg3ZLNiQzSfT1nDfSV25+JA2Ja6zPms3SQkJZNRMBez0V2MMSYkJUf0clFJVkwaGETJGM4ZKKaWUqlgpSQm0y6gBwNDuTXzbB3drwuBu9vGnVw3k7d+Wc+KBTZm5ZnvI4C9SQ577JeBx92a1mbd+R8C2p75dyENj53P5oW05f2ArDnnsBxrXSqOw2LA5J4+Z9x3H/PU7eHTcfGauyeLti/rRsn51UpMSaF7Xn5GcsmwL9dNTePOX5Yw4+QCqpSSilKq6NDCMkEHXGCqllFJq7+vXuh79WtcDbPDYpFYafVvXo6ComAe/mcffq7bTv009ju7ckEfHL+Cv/xxD9ZRExvyzlnu+mFPqtWevzSqxbWd+EQCv/ryUV39eCsCGHbm+/cc/Mzng8cXv/OW7/8W1h9C4Vhpbd+Yz/PUp/tfQph51qiVzVOeGJCSU/ESVW1DEt3M3cNKBTX1fxIeazjriq7n8tmQz3//78FJfl1IqehoYRshmDDU0VEoppVTlusgzzfPV8/rQ/5FJXHtkew7vmMGlg9r4pnaeP6AV5w9oRU5eIQ99M48xf69l0i2Hk5ggFBUbDn3iR2pXSyZrd0G4pwrJGxQGO+Wl30Juv/XTmb77PVvU4cZjOtCqXnUMkJNbyCs/LWXC3A0s3ZTD27+t4KJDWnPLcZ1KXOed31eU2Ja1uwARqJ6cyNUf/M2/+jTnuAMak1tQxOacvIAsZnls3JFLo1ppe3QNpeKBGGMqewx7Rd++fc20adPKff79X8/ls2lrmH3/8RU4KqWUUhVNRKYbY/pW9jjixZ6+P6r4lbW7gF35heQWFHPkUz8BMOryAZz9xpSA+y+d05vDO2XwyLj5TJizga0780tcq21GOssyd5bY3rBmKpuy88o1vqHdGzN7bRYt6lbnuqPaM399Ng9+Mw+wLUEuGNiKwmJDv4cnlnqdn287guZ1qwesh/x96WZuGDWD0VcPpFX9dACKiw0JCcKUZVu4YORUJt58OPM37ODK/03nP0O7cPwBjUlOEprUrsbcdVns2F3IwHb1y/XawsktKApog6JURSvtPVIDwwiN+Gouo/9ew+wRGhgqpVRVFu+BoYiMBE4ENhljuoXYfy5wh/MwB7jaGDPT2bcCyAaKgMJIfg4aGKpgE+asJ6+wmGE9m7Erv5DqKf4JZgs3ZPPFjLXcfExH3vx1GU9MWMh3Nx9Gx0Y1+W7uBq7433QATujehCsOa0unxjXJzi2k2BiOeuon3zTVypCalMAjp3bnjV+WsWBDNgDPDe/JsJ7NmLsuixOe/5W2GenUrZ7C9JXbwl5n0i2Hc/R/bc/K2SOOIyevkOWZOxnQtn6JabLfz9vIQ2Pn8dEVA2hSu1qp43PHMPKivvRpWY/dBUU0rp1GQVExyZ4CP8YYPpu+hpN6NA0ZRI6bvZ62Gel0blwr4p+N2n9oYEjFBIZj/l7DLA0MlVKqStsHAsPDsAHfe2ECw4OB+caYbSIyBBhhjDnI2bcC6GuM2Rzp82lgqPaEN3AsLrYBy8k9QwcsG7JyGfDoJFrWq07d9BRmrt4esL9To5os3JgdsO2Cga2oUz2F5yctjmg8L5/bm2s++Lt8L2YPHdOlEZcd2oYODWtQv0Yqxhja3j0OY+Cx07ojYteILtmUw4HN65DoBJE/L8qkS+Oa/LBgE3eOmU2/1nX5a4UNTB8cdgD3fDmXdhnpPDe8F92a1ebnRZlcOHIqDWum8ufdR/syqW9e2JekRKHT/00gJTGBRQ8PIbegiPPe/JNrjmxHn1b1qF0tmYKiYkZNXcX2XQV0bFTDV+TIGFNi2dQvizNpWDONTo1r7t0fpoqZ0t4jdY1hhEL9Y1FKKaUqmjFmsoi0LmX/756HU4DmMR+UUmF4s4kJCcKZ/VqEPbZx7TT+uOso0lOTqJmaxJ/Lt/L0d4to0yCdj6et5pHTulM9JZHnJi5mwtwNDO/XggeG2e9GWtevzoYduZw/oBUH/n97dx5fVX3mcfzzZCcLgRDWhLBIFFHZB1TQEVFcK9pqta6d6thp1dZO2xEG0dpOte3U1mndl7Zate4oxaXgSlFQEVkVEMOSsAZZJCIhJM/8cY/xJvcGArkhMef7fr3uK+f87rnnnvPkhofn/n7nd26aTrx+jZ557Tj9qO6kpyRRuaeGcQO6Mv2DjQk/54a8/OFGXv4w8n7nDiukU3Za7XFOeGYRANc9vah2+8y0ZMYe3pW/L1hXZz9fFIUAk59bAsDH5Z9x5h9n8a0RRezYFbkmdNOOSvpMfKF22yv/OpdR/fIB2F1dA0BJ+WfMXb2V7/wl8uXPwp+N47n567gh2C/AyltOp3xHJSNufoVvDi/kzIE9GN0vnzeWl9dOLPT+5JPpkJla5//CNTXO7urIMOTR/fL53/MGsaB0G/2755CeUveLgc0VlSzfuIP7ZpbweVU1lxzdmzMGfjkL7/rtn++1R7VyTzWpSUlxJy6K9sCslfxi2gc88d1jGNEnb6/bRnN3Srd8TlGnpl2PeiBqaiIfkn2d28GgHsNGuuG5xUxdsI75N4xL4FGJiEiifdV7DAGCwnBavB7Detv9BOjv7lcE6yuBrUQm077H3e/d13upx1BaWlV1DbM+2syY/l1q1//46gouH9WH3MzUuNunJBnj73iThWXbOXtwD64+sZhenTJJTU5i06e72LSjkiMLctlVVc367btYubmCR+as4ewhBZxxVHd2V9fwzLy1/PeUSKH2xk9P4Im5pby+rJxrTzqU4b068vjcUn714tI67909N4P12xuefKe+Ew7rzOvLypsQnQOTnpLECYd1pk9+du3Msvtj8pkDaq/njJbbLpXenTKp3FND99wMXotzbheOLOKbw3uSk5HCrdOXMX/NNtbFiVnPvHbkZ6czqLADf3lrFf916mEc168zX7t9Fp2y0nj2qlFkpiWTkZrMoJumM6JPHo9cMZLnF61n+YYdXHvSocz8qJzbX13BPZcM458fbebax+fX7v/Zq0bRMTO19hrSXVXVPDxnNecMKSA1JYn2GZHP1h2vreC2l5dTVe3M+NHxFHfN4adPLqB3fhZXjemHu7Ojcg/tM1KpqXHmrdmKmXH9s4u5++KhdMnJoGRzBUf0yMXdWbNlZ+17QqRXPSUpibSU+Pf7POz6FznmkE5MOv1wirvm1B5rekoSZsa8NVtZWLqtzqRTTaGhpDQ98U1+djHTFq7jfRWGIiKtWlgKQzMbA9wJjHb3T4K2Hu6+zsy6ADOAa9w95u7oZnYlcCVAUVHRsNWrVzfDWYg0r42f7uL9NVtrh0IeiF+/tJQjerTnzIE94j6/bMMODuuWwwOzVpKfncYZR3WnvKKSx94p5ftjDiEtOYnn5q+rLUiOP7QzZVt2UrI5MhFPyc2ns6K8gnG/j/kzbNCU7x9L1/YZnHX7m2yuqKR/txxuOusIzo+6/UdYXTiyiEffXhPTfv7wnkx5f21tT2m0p793DNMWrufPb64CoKBDO9Zu+zzu/u+/dDiji/PpP/klAG75+lGs3fo5t7+2Yp/H9vT3juEbd80G4NF/H8l9M0so7prDvTNLGNE7j/suHc78sm2M7pdPjTvTl2ykQ2YqF93/du0+7r54GEcV5nLK72dSUbmHK4/vy70zI/ctXXnL6QkZvajCkKYXhtc/u4gXFm1g3uSTE3hUIiKSaGEoDM1sIDAFOM3dlzewzc+ACnf/7d7eSz2GIk1TU+M8O38tpx7ZjXapyZgZM5eXs6uqmnFHdAOg94TnAZh2zWgO6ZzNknXbGVjYgTdXbGZgYS7JScZdb3zMd0b1qb01RumWnTw9r4wfnFiMGfSZ+AJ98rM4a1APLj+uD1lpKdw4dTEPz1nDxNP6s2zDDr4xrJBDOmdz5+sr2LaziqlRw1S/fWxv/vLWKq4e048ad+58ff97Er8w4bT+Mb2pAGnJSXGLs/o656RTfoCz1QJkp6dQUbnngF/fkgYV5tIzL5NpC9fv1+uW3HQKWelNvwpQhSFNT3yTpizipcUbeE+FoYhIq9bWC0MzKwJeBS6Nvt7QzLKAJHffESzPAH7u7i/t7b1UGIo0vzkln/Duyi1cM7b4gPdRtnUneVlpda7r3Jf3Vm/lyIL27N5TQ05G3WG523dWccPUxfTo0I6++Vn89KmFACz9xan0n/wS+dlp3HPJcKYv2cA5QwtITU7iqffKWL/tc35//mB+/OQCTjq8Kz95cgE7d1fzg7HFZKcnc/MLS+nfLad25tdoh3dvz3eP78vZQwr45fMfsKB0O++s2gLAjV8bwE1/jwxfrX996M3nHFU77BdgwY3j+KSiklNum0lV9Ze1TG67yDk29t6c3z2+L28sL497rK3NL885kotG9mryfjT5TAI4oLlnRESkuZnZ34ATgHwzKwNuBFIB3P1u4AagE3BnMKzoi9tSdAWmBG0pwKP7KgpF5OA4um8nju7btHseFnbc/4lRhvXqCBAzGQxAbmYq/3fBkNr1yj01bNu5m4zUZB69YiS987Po0aFd7T4Arju1f+3y7745GICivExeW7qJa8YWs6uqmhF9OjG4ZwcuuHc2c0q28PwPRnPGH2YB8OIPj6t9/aQzBgDw6tKNvLd6K98+tjdFeZmMLs4nPSUZd+fRd9bgHhlC+rsZy9hcsZtBPTuQ2y6V3HapLP+f03CHRWu3k5+TTl5mGp/t3sPS9Tv42d+XsGJTBace0Y2u7dNZtHY7eVnptRMEARzSJZsfnXwo/Se/xI9PPpRDumRzYv8upCUn8ebHm1lQuo07XvuY3543iLdXfsJDs1czul8+s1Zs5pfnHMmkKYtr99U+I4VPd9XtxRzdL5+/Xj6CeWu28o27ZnPS4V34l9553BL0tp45sDt5WWk8NDsynL9vflbtMOTLjunF+CEFfP3OyPd/k6Ys5txhhXF/l4miHsNGmvjMImZ8sJG515+UwKMSEZFEaws9hgeTegxFpDlUVddQXeNkpCbz3Py1dGufwcgmFMfuzqe79pCekhT3dij1Pf7uGq57ehELbhxX25NYU+P8Y8kG5pR8woOzVzNn4li65WbsdT81NU5SkrFjVxVT3l/LxSN78X7pVoYWdWTtts8Z/evXuPW8QXx9aAG3Tl/OWYN7ULplJ/27t6egQ7vaY//Tm6s4e3APOmWn19n/nuoa7vvnSi46uoj2GamUbtnJ/f8sYfKZA0hJTuK437xK6ZbINZFf3DO0KTSUlEQUhgt5+cNNvDtJhaGISGumwnD/qDAUkbDZVVXN5orKA+qFjbevxhSqTTF31RbOvXs2d1w4tM5tPg6EhpImwNUnFnPZsb1b+jBERERERKQJMlKTE1IUfrGv5nZUYS5Tvn8sh3VrWm/hvqgwbKRIV3DDN94UERERERFJtPSUZIYUddz3hk0U/06LIiIiIiIiEhrNXhia2almtszMVpjZhDjPX2RmC4PHW2Y2KOq5VWa2yMzmm9ncqPY8M5thZh8FP5u/hBYREREREWmjmrUwNLNk4A7gNGAA8C0zG1Bvs5XAv7r7QOAXwL31nh/j7oPrXSQ5AXjF3YuBV4J1EREREREROQDN3WM4Aljh7iXuvht4DBgfvYG7v+XuW4PVOUBhI/Y7HngwWH4QODsxhysiIiIiIhI+zV0YFgClUetlQVtDLgdejFp3YLqZvWdmV0a1d3X39QDBzy4JOl4REREREZHQae5ZSS1OW9wbJ5rZGCKF4eio5lHuvs7MugAzzGypu89s9JtHiskrAYqKihp/1CIiIiIiIiHS3D2GZUDPqPVCYF39jcxsIHA/MN7dP/mi3d3XBT83AVOIDE0F2Ghm3YPXdgc2xXtzd7/X3Ye7+/DOnTsn4HRERERERETanuYuDN8Fis2sj5mlARcAU6M3MLMi4BngEndfHtWeZWY5XywD44DFwdNTgcuC5cuA55r1LERERERERNqwZh1K6u57zOxq4B9AMvAnd19iZv8RPH83cAPQCbjTzAD2BDOQdgWmBG0pwKPu/lKw618BT5jZ5cAa4LzmPA8REREREZG2rLmvMcTdXwBeqNd2d9TyFcAVcV5XAgyq3x489wkwNrFHKiIiIiIiEk7mHncumDbHzMqB1U3cTT6wOQGH05YoJvEpLrEUk1iKSaxExKSXu+vC8kZKUH4EfZ7jUUxiKSaxFJP4FJdYzZojQ1MYJoKZzQ2GuUpAMYlPcYmlmMRSTGIpJl9d+t3FUkxiKSaxFJP4FJdYzR2T5p58RkRERERERFo5FYYiIiIiIiIhp8Jw/9zb0gfQCikm8SkusRSTWIpJLMXkq0u/u1iKSSzFJJZiEp/iEqtZY6JrDEVEREREREJOPYYiIiIiIiIhp8KwkczsVDNbZmYrzGxCSx/PwWJmPc3sNTP70MyWmNkPg/Y8M5thZh8FPztGvWZiEKdlZnZKyx198zKzZDN738ymBeuhjomZdTCzp8xsafB5OUYxsR8FfzeLzexvZpYRxpiY2Z/MbJOZLY5q2+84mNkwM1sUPPcHM7ODfS4SS/lR+bE+5cdYypGxlCNbYX50dz328QCSgY+BvkAasAAY0NLHdZDOvTswNFjOAZYDA4DfABOC9gnAr4PlAUF80oE+QdySW/o8mik2/wk8CkwL1kMdE+BB4IpgOQ3oEOaYAAXASqBdsP4E8O0wxgQ4HhgKLI5q2+84AO8AxwAGvAic1tLnFvaH8qPyYwOxUX6MjYlyZN14KEd668uP6jFsnBHACncvcffdwGPA+BY+poPC3de7+7xgeQfwIZE/5vFE/pEj+Hl2sDweeMzdK919JbCCSPzaFDMrBM4A7o9qDm1MzKw9kX/cHgBw993uvo0QxySQArQzsxQgE1hHCGPi7jOBLfWa9ysOZtYdaO/usz2SBR+Keo20HOVHlB+jKT/GUo5sUOhzZGvLjyoMG6cAKI1aLwvaQsXMegNDgLeBru6+HiLJEegSbBaWWN0G/BdQE9UW5pj0BcqBPwfDh+43syxCHBN3Xwv8FlgDrAe2u/t0QhyTevY3DgXBcv12aVlh+9zGpfxYx20oP9anHFmPcuRetVh+VGHYOPHG6YZqOlczywaeBq5190/3tmmctjYVKzM7E9jk7u819iVx2tpUTIh86zcUuMvdhwCfERn+0JA2H5PgmoDxRIZ79ACyzOzivb0kTlubikkjNRQHxad1Cv3vRfnxS8qPDVKOrEc58oA0e35UYdg4ZUDPqPVCIt3doWBmqUSS3iPu/kzQvDHouib4uSloD0OsRgFnmdkqIsOmTjSzhwl3TMqAMnd/O1h/ikgSDHNMTgJWunu5u1cBzwDHEu6YRNvfOJQFy/XbpWWF7XNbh/JjDOXH+JQjYylHNqzF8qMKw8Z5Fyg2sz5mlgZcAExt4WM6KIJZjR4APnT330U9NRW4LFi+DHguqv0CM0s3sz5AMZELYtsMd5/o7oXu3pvIZ+FVd7+YcMdkA1BqZocFTWOBDwhxTIgMjznazDKDv6OxRK5BCnNMou1XHILhNDvM7OggnpdGvUZajvKj8mMt5cf4lCPjUo5sWMvlxwOdRSdsD+B0IjOOfQxMaunjOYjnPZpId/RCYH7wOB3oBLwCfBT8zIt6zaQgTsto47MGAifw5axroY4JMBiYG3xWngU6KibcBCwFFgN/JTKTWOhiAvyNyDUkVUS+2bz8QOIADA9i+TFwO2AtfW56KD8qPzYYH+XHuvFQjoyNSehzZGvLjxbsTEREREREREJKQ0lFRERERERCToWhiIiIiIhIyKkwFBERERERCTkVhiIiIiIiIiGnwlBERERERCTkVBiKhJiZnWBm01r6OERERFob5UgJGxWGIiIiIiIiIafCUOQrwMwuNrN3zGy+md1jZslmVmFmt5rZPDN7xcw6B9sONrM5ZrbQzKaYWcegvZ+ZvWxmC4LXHBLsPtvMnjKzpWb2iJlZi52oiIjIflKOFEkMFYYirZyZHQ6cD4xy98FANXARkAXMc/ehwBvAjcFLHgKuc/eBwKKo9keAO9x9EHAssD5oHwJcCwwA+gKjmvmUREREEkI5UiRxUlr6AERkn8YCw4B3gy8q2wGbgBrg8WCbh4FnzCwX6ODubwTtDwJPmlkOUODuUwDcfRdAsL933L0sWJ8P9AZmNftZiYiINJ1ypEiCqDAUaf0MeNDdJ9ZpNJtcbzvfxz4aUhm1XI3+XRARka8O5UiRBNFQUpHW7xXgXDPrAmBmeWbWi8jf77nBNhcCs9x9O7DVzI4L2i8B3nD3T4EyMzs72Ee6mWUezJMQERFpBsqRIgmibz1EWjl3/8DMrgemm1kSUAVcBXwGHGFm7wHbiVxjAXAZcHeQ1EqAfwvaLwHuMbOfB/s47yCehoiISMIpR4okjrnvrWddRForM6tw9+yWPg4REZHWRjlSZP9pKKmIiIiIiEjIqcdQREREREQk5NRjKCIiIiIiEnIqDEVEREREREJOhaGIiIiIiEjIqTAUEREREREJORWGIiIiIiIiIafCUEREREREJOT+H3DQpE3vZxtaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plotting accuracy/loss graph\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss'] #get_loss(history.history['loss'])\n",
    "val_loss = history.history['val_loss'] #get_loss(history.history['val_loss'])\n",
    "print('train_acc:', round(acc[-1], 4), \"    \", 'train_loss:', round(loss[-1], 4))\n",
    "print('val_acc:', round(val_acc[-1], 4), \"      \", 'val_loss:', round(val_loss[-1], 4))\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "## Accuracy plot\n",
    "plt.subplot(1, 2, 1) \n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('model_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "## Loss plot\n",
    "plt.subplot(1, 2, 2) \n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('model_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034e1cb",
   "metadata": {},
   "source": [
    " # Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38f899cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydotplus\n",
      "  Downloading pydotplus-2.0.2.tar.gz (278 kB)\n",
      "\u001b[K     |████████████████████████████████| 278 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.1 in /Users/sanikakatekar/miniforge3/envs/san_tf/lib/python3.9/site-packages (from pydotplus) (3.0.4)\n",
      "Building wheels for collected packages: pydotplus\n",
      "  Building wheel for pydotplus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24576 sha256=d97f2f025c192db00dfd9a5fd9be34dfca1c1034ce03594682685f74919b8254\n",
      "  Stored in directory: /Users/sanikakatekar/Library/Caches/pip/wheels/89/e5/de/6966007cf223872eedfbebbe0e074534e72e9128c8fd4b55eb\n",
      "Successfully built pydotplus\n",
      "Installing collected packages: pydotplus\n",
      "Successfully installed pydotplus-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7110df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3f92c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996176785441199"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create decision tree classifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(x_train,y_train).score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7180d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['wordsPerSentence', 'realWordRatio', 'avgWordLength','nounRatio', 'verbRatio', 'adjectiveRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "#The below code has been directly taken from this article for te purpose of visualization: https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = features,class_names=['0','1','2','3','4'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('PlayTennis.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2f9ea",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4da512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing age with 0 values\n",
    "data.drop(data.index[data['age'] == 0], inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['age']:\n",
    "    if i in range(1,10):\n",
    "        print(\"True\")\n",
    "        data['age'] = data['age'].replace([i],1)\n",
    "    else: data['age'] = data['age'].replace([i],2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_split(data):\n",
    "    for i in data['age']:\n",
    "        if i in range(1,10):\n",
    "            data['age'] = data['age'].replace([i],1)\n",
    "        elif i in range(10,20):\n",
    "            data['age'] = data['age'].replace([i],2)            \n",
    "        elif i in range(20,30):\n",
    "            data['age'] = data['age'].replace([i],3)            \n",
    "        elif i in range(30,40):\n",
    "            data['age'] = data['age'].replace([i],4)        \n",
    "        elif i in range(40,50):\n",
    "            data['age'] = data['age'].replace([i],5)        \n",
    "        elif i in range(50,60):\n",
    "            data['age'] = data['age'].replace([i],6)\n",
    "        elif i in range(60,70):\n",
    "            data['age'] = data['age'].replace([i],7)\n",
    "        elif i in range(70,80):\n",
    "            data['age'] = data['age'].replace([i],8)            \n",
    "        elif i in range(80,90):\n",
    "            data['age'] = data['age'].replace([i],9)            \n",
    "        else: \n",
    "            data['age'] = data['age'].replace([i],10)  \n",
    "            \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b36209",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = age_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf99bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d06c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.iloc[:,1:7].astype(float)\n",
    "Y = data1.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c46ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization of data\n",
    "X = preprocessing.scale(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.unique() #to find the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33 , random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58146d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dense(87, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1326c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neural_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "## Train model\n",
    "history = model.fit(x_train, y_train, epochs=1200, validation_data=(x_test, y_test),\n",
    "                    batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim= 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19740171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "inp= Input(shape=()) #input shape\n",
    "emb= Embedding(max_features + 1, embedding_dim),\n",
    "y = GlobalAveragePooling2D()(emb)\n",
    "x1 = Dense(16, activation = 'relu')(inp)\n",
    "x2 = Dense(32, activation = 'relu')(x1)\n",
    "x3 = Dropout(0.1)(x2)\n",
    "x4 = Dense(64, activation = 'relu')(x3)\n",
    "model_output = Dense(87, activation = 'softmax')(x4) #input number of classes\n",
    "model = Model(inputs = inp, outputs = model_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f316483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam')\n",
    "              #metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923ad73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
