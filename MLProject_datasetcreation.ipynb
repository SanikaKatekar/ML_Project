{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Creation file for 'Age Classification of Children using Dyadic Speech Data' file.\n",
        "All functions in this file are tested on Bates.zip file. "
      ],
      "metadata": {
        "id": "6wY0hYPyGRmZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UhMHHUl8w1jm"
      },
      "outputs": [],
      "source": [
        "#Import Necessary packages\n",
        "#Helpful link for reference, using the CHILDESCorpusReader functions: \n",
        "# https://www.nltk.org/howto/childes.html\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus.reader import CHILDESCorpusReader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Corpus data in by going to Jupyter terminal, and using line \n",
        "# \"wget https://childes.talkbank.org/data-xml/Eng-NA/\"\n",
        "# add desired zip file to load in at the end of the filepath (i.e.) wget https://childes.talkbank.org/data-xml/Eng-NA/Bates.zip\n",
        "# then unzip the zip file (i.e. unzip Bates.zip)\n",
        "# Corpus file will be in the same pwd as terminal- load it into python with below line\n",
        "# (for loading in all corpus- can either write each line individually or put all files \n",
        "#  into a folder and loop through them? Might be easiest for naming conventions to\n",
        "# load them separately and make an array of them all once loaded in\n"
      ],
      "metadata": {
        "id": "Fu5XEefyxPwb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#small dataset\n",
        "#currently testing only on Bates.zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/Bates.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Bates')\n",
        "# with zipfile.ZipFile('/content/Bernstein.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/Bernstein')\n",
        "# with zipfile.ZipFile('/content/Bliss.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/Bliss')\n",
        "# with zipfile.ZipFile('/content/Bloom.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/Bloom')\n",
        "# with zipfile.ZipFile('/content/Bohannon.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/Bohannon')\n",
        "# with zipfile.ZipFile('/content/Braunwald.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/Braunwald')\n"
      ],
      "metadata": {
        "id": "By4TDTNN2rbx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Full dataset\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/Bates.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Bates')\n",
        "with zipfile.ZipFile('/content/Bernstein.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Bernstein')\n",
        "with zipfile.ZipFile('/content/Bliss.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Bliss')\n",
        "with zipfile.ZipFile('/content/Bloom.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Bloom')\n",
        "with zipfile.ZipFile('/content/Bohannon.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Bohannon')\n",
        "with zipfile.ZipFile('/content/Braunwald.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Braunwald')\n",
        "with zipfile.ZipFile('/content/Brent.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Brent')\n",
        "with zipfile.ZipFile('/content/Brown.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Brown')\n",
        "with zipfile.ZipFile('/content/Clark.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Clark')\n",
        "with zipfile.ZipFile('/content/Demetras1.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Demetras1')\n",
        "with zipfile.ZipFile('/content/Demetras2.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Demetras2')\n",
        "with zipfile.ZipFile('/content/Evans.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Evans')\n",
        "with zipfile.ZipFile('/content/Feldman.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Feldman')\n",
        "with zipfile.ZipFile('/content/Garvey.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Garvey')\n",
        "with zipfile.ZipFile('/content/Gathercole.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Gathercole')\n",
        "with zipfile.ZipFile('/content/Gelman.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Gelman')\n",
        "with zipfile.ZipFile('/content/Gleason.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Gleason')\n",
        "with zipfile.ZipFile('/content/Gopnik.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Gopnik')\n",
        "with zipfile.ZipFile('/content/HSLLD.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/HSLLD')\n",
        "with zipfile.ZipFile('/content/Haggerty.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Haggerty')\n",
        "with zipfile.ZipFile('/content/Hall.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Hall')\n",
        "with zipfile.ZipFile('/content/Higginson.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Higginson')\n",
        "with zipfile.ZipFile('/content/Kuczaj.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Kuczaj')\n",
        "with zipfile.ZipFile('/content/MacWhinney.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/MacWhinney')\n",
        "with zipfile.ZipFile('/content/McCune.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/McCune')\n",
        "with zipfile.ZipFile('/content/McMillan.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/McMillan')\n",
        "with zipfile.ZipFile('/content/Morisset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Morisset')\n",
        "with zipfile.ZipFile('/content/Nelson.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Nelson')\n",
        "with zipfile.ZipFile('/content/NewEngland.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/NewEngland')\n",
        "with zipfile.ZipFile('/content/NewmanRatner.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/NewmanRatner')\n",
        "with zipfile.ZipFile('/content/Peters.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Peters')\n",
        "with zipfile.ZipFile('/content/PetersonMcCabe.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/PetersonMcCabe')\n",
        "with zipfile.ZipFile('/content/Post.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Post')\n",
        "with zipfile.ZipFile('/content/Rollins.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Rollins')\n",
        "with zipfile.ZipFile('/content/Sachs.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Sachs')\n",
        "with zipfile.ZipFile('/content/Sawyer.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Sawyer')\n",
        "with zipfile.ZipFile('/content/Snow.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Snow')\n",
        "with zipfile.ZipFile('/content/Soderstrom.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Soderstrom')\n",
        "with zipfile.ZipFile('/content/Sprott.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Sprott')\n",
        "with zipfile.ZipFile('/content/Suppes.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Suppes')\n",
        "with zipfile.ZipFile('/content/Tardif.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Tardif')\n",
        "with zipfile.ZipFile('/content/Valian.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Valian')\n",
        "with zipfile.ZipFile('/content/VanHouten.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/VanHouten')\n",
        "with zipfile.ZipFile('/content/VanKleeck.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/VanKleeck')\n",
        "with zipfile.ZipFile('/content/Warren.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Warren')\n",
        "with zipfile.ZipFile('/content/Weist.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Weist')"
      ],
      "metadata": {
        "id": "P11KlrmHB-4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Small Dataset add to Corpora \n",
        "Corpora = []\n",
        "Corpora.append(CHILDESCorpusReader('/content/Bates', '.*.xml'))\n",
        "#Corpora.append(CHILDESCorpusReader('/content/Bernstein', '.*.xml'))\n",
        "#Corpora.append(CHILDESCorpusReader('/content/Bliss', '.*.xml'))\n",
        "#Corpora.append(CHILDESCorpusReader('/content/Bloom', '.*.xml'))\n",
        "#Corpora.append(CHILDESCorpusReader('/content/Braunwald', '.*.xml'))\n"
      ],
      "metadata": {
        "id": "AzF9rS-2GUzZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function used for converting the age string given by CorpusReader to int\n",
        "def ageToInt(ageString):\n",
        "  count = 0\n",
        "  year = 0\n",
        "  month = 0\n",
        "  for letter in ageString:\n",
        "    if(letter == 'Y'):\n",
        "      year = (ord(ageString[count - 1])-48)\n",
        "    if(letter == 'M'):\n",
        "      month = (ord(ageString[count - 1])-48)\n",
        "      month += (10 * (ord(ageString[count - 2])-48))\n",
        "\n",
        "    count+= 1\n",
        "  age = month + (year*12)\n",
        "  return age\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "KFIEmHReH6_K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize array for holding arrays of sentences by age of child\n",
        "sentencesByAge = []\n",
        "for i in range(100):\n",
        "    sentencesByAge.append([])\n",
        "\n",
        "#Define an ageSorter Function for dividing a corpus into the sentencesbyage array\n",
        "def ageSorter(corpus):\n",
        "  count = 0\n",
        "  for transcript in corpus.fileids():\n",
        "     age = ageToInt(corpus.participants(corpus.fileids())[count]['CHI']['age'])\n",
        "     #print(age)\n",
        "     for sentence in corpus.sents(corpus.fileids()[count]):\n",
        "       sentencesByAge[age].append(sentence)\n",
        "     count+= 1\n",
        "\n",
        "#Sort all the Corpora using the function\n",
        "for corpus in Corpora:\n",
        "  ageSorter(corpus)"
      ],
      "metadata": {
        "id": "UlMhoBm-HDdc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for paritioning data into samples of a given number of sentences\n",
        "samplesByAge = []\n",
        "for i in range(100):\n",
        "    samplesByAge.append([])\n",
        "\n",
        "def sampleCreator(numberOfSentences):\n",
        "  count2 = 0\n",
        "  for group in sentencesByAge:\n",
        "    count = 0\n",
        "    while (count < (len(group) - numberOfSentences)):\n",
        "      sample = []\n",
        "      for sentence in range(numberOfSentences):\n",
        "        sample.append(group[count])\n",
        "        count+=1\n",
        "      samplesByAge[count2].append(sample)\n",
        "    count2+=1\n",
        "      \n"
      ],
      "metadata": {
        "id": "aqJbA1v2PTNL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleCreator(20)"
      ],
      "metadata": {
        "id": "WcUMDgZ0XYY3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for returning words per sentence for sample\n",
        "def wordsPerSentence(sample):\n",
        "  wordsCount = 0\n",
        "  for sentences in sample:\n",
        "    for words in sentences:\n",
        "      wordsCount+=1\n",
        "  return (wordsCount/len(sample))"
      ],
      "metadata": {
        "id": "y3LRN259b6qu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for creating attribute array for each sample (corresponding positions\n",
        "#in both the samplesByAge and the new sampleAttributesByAge array)\n",
        "#attribute array currently: ['avgSentenceLength, avgWordLength,  ]\n",
        "sampleAttributesByAge = []\n",
        "for i in range(100):\n",
        "    sampleAttributesByAge.append([])\n"
      ],
      "metadata": {
        "id": "GKeTtttBcl3F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eq8Ovj3zeyLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check age of child in a given file transcript\n",
        "Bates = CHILDESCorpusReader('/content/Bates', '.*.xml')\n",
        "age = Bates.participants(Bates.fileids())[9]['CHI']['age']\n",
        "\n",
        "#to load sentences for a given child\n",
        "sentences = Bates.sents(Bates.fileids()[0])\n"
      ],
      "metadata": {
        "id": "qvQvZ0NZxa9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff2a90f-2d29-43c2-d0fe-580bc3074c26"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<function CHILDESCorpusReader._get_participants.<locals>.dictOfDicts at 0x7fe6f1497b80>, {})\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMXv7XXuDeaL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}